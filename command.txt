2025.1.2 Thu DCKA v.8 for Rocky Linux 9

[root@docker1 ~]# dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo
Adding repo from: https://download.docker.com/linux/centos/docker-ce.repo
[root@docker1 ~]#
[root@docker1 ~]# ls -l /etc/yum.repos.d/
total 24
-rw-r--r--  1 root root 1919 Jan  2 14:43 docker-ce.repo
-rw-r--r--. 1 root root 6610 Nov  1 11:27 rocky-addons.repo
-rw-r--r--. 1 root root 1165 Nov  1 11:27 rocky-devel.repo
-rw-r--r--. 1 root root 2387 Nov  1 11:27 rocky-extras.repo
-rw-r--r--. 1 root root 3417 Nov  1 11:27 rocky.repo
[root@docker1 ~]#
[root@docker1 ~]# cat /etc/yum.repos.d/docker-ce.repo
[docker-ce-stable]
name=Docker CE Stable - $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/stable
enabled=1
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-stable-debuginfo]
name=Docker CE Stable - Debuginfo $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/stable
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-stable-source]
name=Docker CE Stable - Sources
baseurl=https://download.docker.com/linux/centos/$releasever/source/stable
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-test]
name=Docker CE Test - $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/test
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-test-debuginfo]
name=Docker CE Test - Debuginfo $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/test
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-test-source]
name=Docker CE Test - Sources
baseurl=https://download.docker.com/linux/centos/$releasever/source/test
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-nightly]
name=Docker CE Nightly - $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/nightly
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-nightly-debuginfo]
name=Docker CE Nightly - Debuginfo $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/nightly
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-nightly-source]
name=Docker CE Nightly - Sources
baseurl=https://download.docker.com/linux/centos/$releasever/source/nightly
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg
[root@docker1 ~]#
[root@docker1 ~]# dnf install docker-ce -y
...【略】...

Complete!
[root@docker1 ~]#

[root@docker1 ~]# systemctl start docker
[root@docker1 ~]# systemctl enable docker
[root@docker1 ~]# systemctl status docker
...【略】...

[root@docker1 ~]# docker version
Client: Docker Engine - Community
 Version:           27.4.1
 API version:       1.47
 Go version:        go1.22.10
 Git commit:        b9d17ea
 Built:             Tue Dec 17 15:47:23 2024
 OS/Arch:           linux/amd64
 Context:           default

Server: Docker Engine - Community
 Engine:
  Version:          27.4.1
  API version:      1.47 (minimum version 1.24)
  Go version:       go1.22.10
  Git commit:       c710b88
  Built:            Tue Dec 17 15:45:36 2024
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.7.24
  GitCommit:        88bf19b2105c8b17560993bee28a01ddc2f97182
 runc:
  Version:          1.2.2
  GitCommit:        v1.2.2-0-g7cb3632
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
[root@docker1 ~]#

[root@docker1 ~]# docker pull rockylinux:9
9: Pulling from library/rockylinux
446f83f14b23: Pull complete
Digest: sha256:d7be1c094cc5845ee815d4632fe377514ee6ebcf8efaed6892889657e5ddaaa6
Status: Downloaded newer image for rockylinux:9
docker.io/library/rockylinux:9
[root@docker1 ~]#
[root@docker1 ~]# docker images
REPOSITORY   TAG       IMAGE ID       CREATED         SIZE
rockylinux   9         9cc24f05f309   13 months ago   176MB
[root@docker1 ~]# docker history rockylinux:9
IMAGE          CREATED         CREATED BY                      SIZE      COMMENT
9cc24f05f309   13 months ago   CMD ["/bin/bash"]               0B        buildkit.dockerfile.v0
<missing>      13 months ago   ADD layer.tar.xz / # buildkit   176MB     buildkit.dockerfile.v0
[root@docker1 ~]#

[root@docker1 ~]# wget http://10.0.1.248/k8s/scripts/check_docker_pull_r        ate_limit.sh

[root@docker1 ~]# wget http://10.0.1.248/k8s/scripts/check_docker_pull_rate_limit-freeaccount.sh

[root@docker1 ~]# wget http://10.0.1.248/k8s/scripts/prepare_private_registry.sh

[root@docker2 ~]# dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo
Adding repo from: https://download.docker.com/linux/centos/docker-ce.repo
[root@docker2 ~]#




#
# docker 使用自建的私庫 private registry
#

[root@docker2 ~]# vi /etc/docker/daemon.json
[root@docker2 ~]# cat /etc/docker/daemon.json
{
  "live-restore": true,
  "group": "dockerroot",
  "insecure-registries": ["10.0.1.248:5000","192.168.66.248:5000","192.168.66.51:5000","docker1.training.lab:5000"]
}
[root@docker2 ~]# systemctl restart docker

[root@docker2 ~]# docker pull 10.0.1.248:5000/nginx
Using default tag: latest
latest: Pulling from nginx
6f28985ad184: Pull complete
29f7ebf60efd: Pull complete
879a7c160ac6: Pull complete
de58cd48a671: Pull complete
be704f37b5f4: Pull complete
158aac73782c: Pull complete
Digest: sha256:48d56bae87c65ca642b0a1d13c3dc97c4430994991e5531ff123f77cdf975fae
Status: Downloaded newer image for 192.168.66.248:5000/nginx:latest
192.168.66.248:5000/nginx:latest
[root@docker2 ~]# docker pull docker1.training.lab:5000/httpd
Using default tag: latest
latest: Pulling from httpd
68ced04f60ab: Pull complete
35d35f1e0dc9: Pull complete
8a918bf0ae55: Pull complete
d7b9f2dbc195: Pull complete
d56c468bde81: Pull complete
Digest: sha256:d3df077ec2ddbe0a62279c672b9c792055b96f6d22ed1e45371bcd70393730f9
Status: Downloaded newer image for docker1.training.lab:5000/httpd:latest
docker1.training.lab:5000/httpd:latest
[root@docker2 ~]#

[root@docker2 ~]# docker pull 192.168.66.51:5000/mysql
Using default tag: latest
latest: Pulling from mysql
80369df48736: Pull complete
e8f52315cb10: Pull complete
cf2189b391fc: Pull complete
cc98f645c682: Pull complete
27a27ac83f74: Pull complete
fa1f04453414: Pull complete
d45bf7d22d33: Pull complete
3dbac26e409c: Pull complete
9017140fb8c1: Pull complete
b76dda2673ae: Pull complete
bea9eb46d12a: Pull complete
e1f050a38d0f: Pull complete
Digest: sha256:0491ecfc011cdebbd6c9bc2f5cd8fd0bd43f6e9b96caae96fb404eb00381068d
Status: Downloaded newer image for 192.168.66.51:5000/mysql:latest
192.168.66.51:5000/mysql:latest
[root@docker2 ~]#

[root@docker2 ~]# docker pull docker1.training.lab:5000/mysql:5.6
5.6: Pulling from mysql
b5887238bf65: Pull complete
b9f043a334d3: Pull complete
cc55a8e93ff2: Pull complete
3d3042318a3b: Pull complete
5b63d16ff885: Pull complete
0405a1c9e5b1: Pull complete
b584aa6803f3: Pull complete
a856a26a656f: Pull complete
4236a5b5e008: Pull complete
6d096a6038d1: Pull complete
238a14ee30c5: Pull complete
Digest: sha256:2f3887574424f301fc51b59025b73e3c67f19872f5184d761a679e915cb8302d
Status: Downloaded newer image for docker1.training.lab:5000/mysql:5.6
docker1.training.lab:5000/mysql:5.6
[root@docker2 ~]#

[root@docker2 ~]# docker run -itd -e MYSQL_ROOT_PASSWORD=container 192.168.66.51:5000/mysql:5.6
Unable to find image '192.168.66.51:5000/mysql:5.6' locally
5.6: Pulling from mysql
Digest: sha256:2f3887574424f301fc51b59025b73e3c67f19872f5184d761a679e915cb8302d
Status: Downloaded newer image for 192.168.66.51:5000/mysql:5.6
a28f39cbe62098aa286231ded0384d6663cb459793fd5dff0a2c162031b585d7
[root@docker2 ~]#

[root@docker2 ~]# docker run -itd --name mysql-2 -e MYSQL_ROOT_PASSWORD=container 192.168.66.51:5000/mysql:5.5
Unable to find image '192.168.66.51:5000/mysql:5.5' locally
5.5: Pulling from mysql
743f2d6c1f65: Pull complete
3f0c413ee255: Pull complete
aef1ef8f1aac: Pull complete
f9ee573e34cb: Pull complete
3f237e01f153: Pull complete
03da1e065b16: Pull complete
04087a801070: Pull complete
7efd5395ab31: Pull complete
1b5cc03aaac8: Pull complete
2b7adaec9998: Pull complete
385b8f96a9ba: Pull complete
Digest: sha256:c9c671d0c959183154313d6830d46f9a00d5937f97415c15ebd3c6844f6f1467
Status: Downloaded newer image for 192.168.66.51:5000/mysql:5.5
4ba163c7227065f5e529f7fdff236383ac466def19af92985293efd92ebceb02
[root@docker2 ~]#


[root@docker2 ~]# docker logs mysql-2
Initializing database
250204  4:16:03 [Note] Ignoring --secure-file-priv value as server is running with --bootstrap.
250204  4:16:03 [Note] /usr/local/mysql/bin/mysqld (mysqld 5.5.62) starting as process 67 ...
/usr/local/mysql/bin/mysqld: Out of memory (Needed 4294967168 bytes)
250204  4:16:03 [Note] Ignoring --secure-file-priv value as server is running with --bootstrap.
250204  4:16:03 [Note] /usr/local/mysql/bin/mysqld (mysqld 5.5.62) starting as process 73 ...
/usr/local/mysql/bin/mysqld: Out of memory (Needed 4294967168 bytes)

PLEASE REMEMBER TO SET A PASSWORD FOR THE MySQL root USER !
To do so, start the server, then issue the following commands:

/usr/local/mysql/bin/mysqladmin -u root password 'new-password'
/usr/local/mysql/bin/mysqladmin -u root -h  password 'new-password'

Alternatively you can run:
/usr/local/mysql/bin/mysql_secure_installation

which will also give you the option of removing the test
databases and anonymous user created by default.  This is
strongly recommended for production servers.

See the manual for more instructions.

Please report any problems at http://bugs.mysql.com/

Database initialized
250204  4:16:03 [Note] --secure-file-priv is set to NULL. Operations related to importing and exporting data are disabled
250204  4:16:03 [Note] mysqld (mysqld 5.5.62) starting as process 83 ...
mysqld: Out of memory (Needed 4294967168 bytes)
250204  4:16:03 [Warning] Changed limits: max_open_files: 64  max_connections: 151  table_cache: 400
MySQL init process in progress...
250204  4:16:03 [Note] Plugin 'FEDERATED' is disabled.
250204  4:16:03 InnoDB: The InnoDB memory heap is disabled
250204  4:16:03 InnoDB: Mutexes and rw_locks use GCC atomic builtins
250204  4:16:03 InnoDB: Compressed tables use zlib 1.2.11
250204  4:16:03 InnoDB: Using Linux native AIO
250204  4:16:03 InnoDB: Initializing buffer pool, size = 128.0M
250204  4:16:03 InnoDB: Completed initialization of buffer pool
InnoDB: The first specified data file ./ibdata1 did not exist:
InnoDB: a new database to be created!
250204  4:16:03  InnoDB: Setting file ./ibdata1 size to 10 MB
InnoDB: Database physically writes the file full: wait...
250204  4:16:03  InnoDB: Log file ./ib_logfile0 did not exist: new to be created
InnoDB: Setting log file ./ib_logfile0 size to 5 MB
InnoDB: Database physically writes the file full: wait...
250204  4:16:03  InnoDB: Log file ./ib_logfile1 did not exist: new to be created
InnoDB: Setting log file ./ib_logfile1 size to 5 MB
InnoDB: Database physically writes the file full: wait...
InnoDB: Doublewrite buffer not found: creating new
InnoDB: Doublewrite buffer created
InnoDB: 127 rollback segment(s) active.
InnoDB: Creating foreign key constraint system tables
InnoDB: Foreign key constraint system tables created
250204  4:16:03  InnoDB: Waiting for the background threads to start
MySQL init process in progress...
250204  4:16:04 InnoDB: 5.5.62 started; log sequence number 0
250204  4:16:04 [Warning] 'user' entry 'root@4ba163c72270' ignored in --skip-name-resolve mode.
250204  4:16:04 [Warning] 'user' entry '@4ba163c72270' ignored in --skip-name-resolve mode.
250204  4:16:04 [Warning] 'proxies_priv' entry '@ root@4ba163c72270' ignored in --skip-name-resolve mode.
250204  4:16:04 [Note] Event Scheduler: Loaded 0 events
250204  4:16:04 [Note] mysqld: ready for connections.
Version: '5.5.62'  socket: '/tmp/mysql.sock'  port: 0  MySQL Community Server (GPL)
Warning: Unable to load '/usr/share/zoneinfo/iso3166.tab' as time zone. Skipping it.
Warning: Unable to load '/usr/share/zoneinfo/leap-seconds.list' as time zone. Skipping it.
Warning: Unable to load '/usr/share/zoneinfo/zone.tab' as time zone. Skipping it.
Warning: Unable to load '/usr/share/zoneinfo/zone1970.tab' as time zone. Skipping it.
250204  4:16:09 [Warning] 'proxies_priv' entry '@ root@4ba163c72270' ignored in --skip-name-resolve mode.

250204  4:16:09 [Note] mysqld: Normal shutdown

250204  4:16:09 [Note] Event Scheduler: Purging the queue. 0 events
250204  4:16:09  InnoDB: Starting shutdown...
250204  4:16:10  InnoDB: Shutdown completed; log sequence number 1595675
250204  4:16:10 [Note] mysqld: Shutdown complete


MySQL init process done. Ready for start up.

250204  4:16:10 [Note] --secure-file-priv is set to NULL. Operations related to importing and exporting data are disabled
250204  4:16:10 [Note] mysqld (mysqld 5.5.62) starting as process 1 ...
mysqld: Out of memory (Needed 4294967168 bytes)
250204  4:16:10 [Warning] Changed limits: max_open_files: 64  max_connections: 151  table_cache: 400
250204  4:16:10 [Note] Plugin 'FEDERATED' is disabled.
250204  4:16:10 InnoDB: The InnoDB memory heap is disabled
250204  4:16:10 InnoDB: Mutexes and rw_locks use GCC atomic builtins
250204  4:16:10 InnoDB: Compressed tables use zlib 1.2.11
250204  4:16:10 InnoDB: Using Linux native AIO
250204  4:16:10 InnoDB: Initializing buffer pool, size = 128.0M
250204  4:16:10 InnoDB: Completed initialization of buffer pool
250204  4:16:10 InnoDB: highest supported file format is Barracuda.
250204  4:16:10  InnoDB: Waiting for the background threads to start
250204  4:16:11 InnoDB: 5.5.62 started; log sequence number 1595675
250204  4:16:11 [Note] Server hostname (bind-address): '0.0.0.0'; port: 3306
250204  4:16:11 [Note]   - '0.0.0.0' resolves to '0.0.0.0';
250204  4:16:11 [Note] Server socket created on IP: '0.0.0.0'.
250204  4:16:11 [Warning] 'proxies_priv' entry '@ root@4ba163c72270' ignored in --skip-name-resolve mode.
250204  4:16:11 [Note] Event Scheduler: Loaded 0 events
250204  4:16:11 [Note] mysqld: ready for connections.
Version: '5.5.62'  socket: '/tmp/mysql.sock'  port: 3306  MySQL Community Server (GPL)
[root@docker2 ~]#


[root@docker2 ~]# docker inspect mysql-2
[
    {
        "Id": "4ba163c7227065f5e529f7fdff236383ac466def19af92985293efd92ebceb02",
        "Created": "2025-02-04T04:16:02.708500532Z",
        "Path": "docker-entrypoint.sh",
        "Args": [
            "mysqld"
        ],
        "State": {
            "Status": "running",
            "Running": true,
            "Paused": false,
            "Restarting": false,
            "OOMKilled": false,
            "Dead": false,
            "Pid": 35196,
            "ExitCode": 0,
            "Error": "",
            "StartedAt": "2025-02-04T04:16:02.925296491Z",
            "FinishedAt": "0001-01-01T00:00:00Z"
        },
        "Image": "sha256:d404d78aa797c87c255e5ae2beb5d8d0e4d095f930b1f20dc208eaa957477b74",
        "ResolvConfPath": "/var/lib/docker/containers/4ba163c7227065f5e529f7fdff236383ac466def19af92985293efd92ebceb02/resolv.conf",
        "HostnamePath": "/var/lib/docker/containers/4ba163c7227065f5e529f7fdff236383ac466def19af92985293efd92ebceb02/hostname",
        "HostsPath": "/var/lib/docker/containers/4ba163c7227065f5e529f7fdff236383ac466def19af92985293efd92ebceb02/hosts",
        "LogPath": "/var/lib/docker/containers/4ba163c7227065f5e529f7fdff236383ac466def19af92985293efd92ebceb02/4ba163c7227065f5e529f7fdff236383ac466def19af92985293efd92ebceb02-json.log",
        "Name": "/mysql-2",
        "RestartCount": 0,
        "Driver": "overlay2",
        "Platform": "linux",
        "MountLabel": "",
        "ProcessLabel": "",
        "AppArmorProfile": "",
        "ExecIDs": null,
        "HostConfig": {
            "Binds": null,
            "ContainerIDFile": "",
            "LogConfig": {
                "Type": "json-file",
                "Config": {}
            },
            "NetworkMode": "bridge",
            "PortBindings": {},
            "RestartPolicy": {
                "Name": "no",
                "MaximumRetryCount": 0
            },
            "AutoRemove": false,
            "VolumeDriver": "",
            "VolumesFrom": null,
            "ConsoleSize": [
                23,
                84
            ],
            "CapAdd": null,
            "CapDrop": null,
            "CgroupnsMode": "private",
            "Dns": [],
            "DnsOptions": [],
            "DnsSearch": [],
            "ExtraHosts": null,
            "GroupAdd": null,
            "IpcMode": "private",
            "Cgroup": "",
            "Links": null,
            "OomScoreAdj": 0,
            "PidMode": "",
            "Privileged": false,
            "PublishAllPorts": false,
            "ReadonlyRootfs": false,
            "SecurityOpt": null,
            "UTSMode": "",
            "UsernsMode": "",
            "ShmSize": 67108864,
            "Runtime": "runc",
            "Isolation": "",
            "CpuShares": 0,
            "Memory": 0,
            "NanoCpus": 0,
            "CgroupParent": "",
            "BlkioWeight": 0,
            "BlkioWeightDevice": [],
            "BlkioDeviceReadBps": [],
            "BlkioDeviceWriteBps": [],
            "BlkioDeviceReadIOps": [],
            "BlkioDeviceWriteIOps": [],
            "CpuPeriod": 0,
            "CpuQuota": 0,
            "CpuRealtimePeriod": 0,
            "CpuRealtimeRuntime": 0,
            "CpusetCpus": "",
            "CpusetMems": "",
            "Devices": [],
            "DeviceCgroupRules": null,
            "DeviceRequests": null,
            "MemoryReservation": 0,
            "MemorySwap": 0,
            "MemorySwappiness": null,
            "OomKillDisable": null,
            "PidsLimit": null,
            "Ulimits": [],
            "CpuCount": 0,
            "CpuPercent": 0,
            "IOMaximumIOps": 0,
            "IOMaximumBandwidth": 0,
            "MaskedPaths": [
                "/proc/asound",
                "/proc/acpi",
                "/proc/kcore",
                "/proc/keys",
                "/proc/latency_stats",
                "/proc/timer_list",
                "/proc/timer_stats",
                "/proc/sched_debug",
                "/proc/scsi",
                "/sys/firmware",
                "/sys/devices/virtual/powercap"
            ],
            "ReadonlyPaths": [
                "/proc/bus",
                "/proc/fs",
                "/proc/irq",
                "/proc/sys",
                "/proc/sysrq-trigger"
            ]
        },
        "GraphDriver": {
            "Data": {
                "LowerDir": "/var/lib/docker/overlay2/f23a5620f39bdac34073427778e2859b78e5f5add71a26e8dcbb955742296e87-init/diff:/var/lib/docker/overlay2/4de3a310c9a1629895b49b8644c453c1e4526b3279c7611c45cee525286b98ae/diff:/var/lib/docker/overlay2/ca726151a7ba7fffee4d1bc8f46187d661794940176df1aaf17f12eef05caa95/diff:/var/lib/docker/overlay2/66f90f3c3a73af8a3341844c9f47b96448d903bbd4813799e7d6b332558a13c5/diff:/var/lib/docker/overlay2/f232b76ffdaaa213ce82bb136d268d19701d822a68a57d57ef20601e2b7690e1/diff:/var/lib/docker/overlay2/973753a3aacc98dc3bc6c816119fd10e87825d3b7f44a50382450c16852fce3e/diff:/var/lib/docker/overlay2/b895ecd20f387966b02b66f39907412a8169b951c6f1655877f2abb8a1b0a4da/diff:/var/lib/docker/overlay2/91b8ac674961b9330ca96e097c4d8c82d216288ca9f17e258c3e4c1e6d61ca27/diff:/var/lib/docker/overlay2/ac748ba994016d9f243f9fcb710f6382b81debf7b89756e748610cc082257a4b/diff:/var/lib/docker/overlay2/e82d821d31843cd472584cf94a75fa370f4ad0c30a8cbae4fd8d48e3735432a6/diff:/var/lib/docker/overlay2/43f07182b37b8ffc4e5be873f9ae4390d8bb1b6c30c292250c34ad3324385f34/diff:/var/lib/docker/overlay2/0a4fbeb0878f8de8e107e11736b3a8dc1a5e191f4ad27945ec53429447d63297/diff",
                "MergedDir": "/var/lib/docker/overlay2/f23a5620f39bdac34073427778e2859b78e5f5add71a26e8dcbb955742296e87/merged",
                "UpperDir": "/var/lib/docker/overlay2/f23a5620f39bdac34073427778e2859b78e5f5add71a26e8dcbb955742296e87/diff",
                "WorkDir": "/var/lib/docker/overlay2/f23a5620f39bdac34073427778e2859b78e5f5add71a26e8dcbb955742296e87/work"
            },
            "Name": "overlay2"
        },
        "Mounts": [
            {
                "Type": "volume",
                "Name": "43f3ee13500ca7d17b41798170592d6174a825824a67203aed898f5e88794f55",
                "Source": "/var/lib/docker/volumes/43f3ee13500ca7d17b41798170592d6174a825824a67203aed898f5e88794f55/_data",
                "Destination": "/var/lib/mysql",
                "Driver": "local",
                "Mode": "",
                "RW": true,
                "Propagation": ""
            }
        ],
        "Config": {
            "Hostname": "4ba163c72270",
            "Domainname": "",
            "User": "",
            "AttachStdin": false,
            "AttachStdout": false,
            "AttachStderr": false,
            "ExposedPorts": {
                "3306/tcp": {}
            },
            "Tty": true,
            "OpenStdin": true,
            "StdinOnce": false,
            "Env": [
                "MYSQL_ROOT_PASSWORD=container",
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/mysql/bin:/usr/local/mysql/scripts",
                "GOSU_VERSION=1.7",
                "MYSQL_MAJOR=5.5",
                "MYSQL_VERSION=5.5.62"
            ],
            "Cmd": [
                "mysqld"
            ],
            "Image": "192.168.66.51:5000/mysql:5.5",
            "Volumes": {
                "/var/lib/mysql": {}
            },
            "WorkingDir": "",
            "Entrypoint": [
                "docker-entrypoint.sh"
            ],
            "OnBuild": null,
            "Labels": {}
        },
        "NetworkSettings": {
            "Bridge": "",
            "SandboxID": "3898f5004349aadb5bf415ea09ca522eac51aac14f973c19c59706c901ee38ae",
            "SandboxKey": "/var/run/docker/netns/3898f5004349",
            "Ports": {
                "3306/tcp": null
            },
            "HairpinMode": false,
            "LinkLocalIPv6Address": "",
            "LinkLocalIPv6PrefixLen": 0,
            "SecondaryIPAddresses": null,
            "SecondaryIPv6Addresses": null,
            "EndpointID": "8db325c6046c4c3d4cfb58b7b1e6b13bf3cfa057104ef970ef587aaf58c534bd",
            "Gateway": "172.17.0.1",
            "GlobalIPv6Address": "",
            "GlobalIPv6PrefixLen": 0,
            "IPAddress": "172.17.0.3",
            "IPPrefixLen": 16,
            "IPv6Gateway": "",
            "MacAddress": "02:42:ac:11:00:03",
            "Networks": {
                "bridge": {
                    "IPAMConfig": null,
                    "Links": null,
                    "Aliases": null,
                    "MacAddress": "02:42:ac:11:00:03",
                    "DriverOpts": null,
                    "NetworkID": "dc34a3f2154c69829ba28c5ec9910185b24513f2465b759a9054043ed806a982",
                    "EndpointID": "8db325c6046c4c3d4cfb58b7b1e6b13bf3cfa057104ef970ef587aaf58c534bd",
                    "Gateway": "172.17.0.1",
                    "IPAddress": "172.17.0.3",
                    "IPPrefixLen": 16,
                    "IPv6Gateway": "",
                    "GlobalIPv6Address": "",
                    "GlobalIPv6PrefixLen": 0,
                    "DNSNames": null
                }
            }
        }
    }
]
[root@docker2 ~]#

[root@docker2 ~]# docker inspect -f '{{ .NetworkSettings.IPAddress }}' mysql-2
172.17.0.3
[root@docker2 ~]#

[root@docker2 ~]# docker inspect mysql-2 | grep IPAdd
            "SecondaryIPAddresses": null,
            "IPAddress": "172.17.0.3",
                    "IPAddress": "172.17.0.3",
[root@docker2 ~]#
[root@docker2 ~]# docker inspect mysql-2 | grep -i ipadd
            "SecondaryIPAddresses": null,
            "IPAddress": "172.17.0.3",
                    "IPAddress": "172.17.0.3",
[root@docker2 ~]#

[root@docker2 ~]# docker run -it --name mysql-3 -e MYSQL_ROOT_PASSWORD=container 192.168.66.51:5000/mysql:5.5 /bin/bash
root@6502526623f3:/#
root@6502526623f3:/# hostname
6502526623f3
root@6502526623f3:/# exit
exit
[root@docker2 ~]#

[root@docker2 ~]# vi docker_clean_all.sh
[root@docker2 ~]#
[root@docker2 ~]# cat docker_clean_all.sh
#!/bin/bash
# 2019.1.16 Wed Anderson Version 0.0.1
docker stop $(docker ps -aq)
docker rm $(docker ps -aq)
docker rmi -f $(docker images -aq)
[root@docker2 ~]#

[root@docker2 ~]# mkdir -p /docker_data/db1
[root@docker2 ~]#
[root@docker2 ~]# ls -l /docker_data/
total 0
drwxr-xr-x 2 root root 6 Feb  4 12:22 db1
[root@docker2 ~]#

[root@docker2 ~]# docker pull 192.168.66.51:5000/mariadb
Using default tag: latest
latest: Pulling from mariadb
7ddbc47eeb70: Pull complete
c1bbdc448b72: Pull complete
8c3b70e39044: Pull complete
45d437916d57: Pull complete
215d801d0263: Pull complete
59feacde9e08: Pull complete
741aa98d779c: Pull complete
e3f771d07df1: Pull complete
38be307a8063: Pull complete
5ef9df553f6d: Pull complete
4cbd7d15547b: Pull complete
6c6ad526a125: Pull complete
c610f45a4f57: Pull complete
37452d4d6df6: Pull complete
Digest: sha256:efb59fb53c18a3ab7371eb94d09959c68068a1d06762b36023982a8385bcaa27
Status: Downloaded newer image for 192.168.66.51:5000/mariadb:latest
192.168.66.51:5000/mariadb:latest
[root@docker2 ~]#

[root@docker2 ~]# docker run -itd --name db1 -p 3306:3306 -v /docker_data/db1:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=container 192.168.66.51:5000/mariadb
45f821b7df698f68e2ab470de7427c6715d0222e0f52285c8d711a09d7db04de
[root@docker2 ~]#

[root@docker2 ~]# mkdir -p /docker_data/wordpress
[root@docker2 ~]#
[root@docker2 ~]# ls -l /docker_data/
total 4
drwxr-xr-x 4 systemd-coredump root 4096 Feb  4 12:24 db1
drwxr-xr-x 2 root             root    6 Feb  4 12:25 wordpress
[root@docker2 ~]#

[root@docker2 ~]# docker pull 192.168.66.51:5000/wordpress
Using default tag: latest
latest: Pulling from wordpress
8d691f585fa8: Pull complete
cba12d3fd8b1: Pull complete
cda54d6474c8: Pull complete
412447ed0729: Pull complete
84de6fc539c3: Pull complete
d67567ed6145: Pull complete
22ca6c438da4: Pull complete
aaaf25e57dd6: Pull complete
fbccd385090a: Pull complete
15b403f621d7: Pull complete
1cae2d7071d0: Pull complete
5c0cbd6e0573: Pull complete
1b48a6c1e889: Pull complete
855d31502496: Pull complete
10805e670603: Pull complete
e8bb78a1b6fd: Pull complete
2ad26d4ff931: Pull complete
98da1a26f856: Pull complete
9cbdfce1994c: Pull complete
a872c625da6b: Pull complete
f36709107bb2: Pull complete
Digest: sha256:83a8d86d5266cf2ff24715e248226b60b3a3f8e8d4a27fcc7ed4f33a4d09e468
Status: Downloaded newer image for 192.168.66.51:5000/wordpress:latest
192.168.66.51:5000/wordpress:latest
[root@docker2 ~]#

[root@docker2 ~]# docker run -it --name wordpress -p 80:80 --link db1:mysql -v /docker_data/wordpress:/var/www/html -e WORDPRESS_DB_NAME=wp -e WORDPRESS_DB_USER=root -e WORDPRESS_DB_PASSWORD=container -e ServerName=localhost -d 192.168.66.51:5000/wordpress
36aa6bc3480c1665f5e47ca916f2957690739429d35ba6030c645f20cb876462
[root@docker2 ~]#


[root@docker2 ~]# docker pull docker1.training.lab:5000/alpine
Using default tag: latest
latest: Pulling from alpine
89d9c30c1d48: Pull complete
Digest: sha256:e4355b66995c96b4b468159fc5c7e3540fcef961189ca13fee877798649f531a
Status: Downloaded newer image for docker1.training.lab:5000/alpine:latest
docker1.training.lab:5000/alpine:latest
[root@docker2 ~]#

[root@docker2 ~]# docker run -it --name alpine-1 docker1.training.lab:5000/alpine
/ #
/ # bash
/bin/sh: bash: not found
/ #
/ # apk add --no-cache --update-cache bash
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/community/x86_64/APKINDEX.tar.gz
(1/4) Installing ncurses-terminfo-base (6.1_p20190518-r2)
(2/4) Installing ncurses-libs (6.1_p20190518-r2)
(3/4) Installing readline (8.0.0-r0)
(4/4) Installing bash (5.0.0-r0)
Executing bash-5.0.0-r0.post-install
Executing busybox-1.30.1-r2.trigger
OK: 8 MiB in 18 packages
/ # bash
bash-5.0# exit
exit
/ # exit
[root@docker2 ~]#

[root@docker2 ~]# docker commit -m "alpine + bash" alpine-1 alpine-bash
sha256:1a62ef99069d5314f9a24d91658936229e64815769f2776a393c421b9eb6cb9f
[root@docker2 ~]#

[root@docker2 ~]# docker save --output=alpine-bash.tar alpine-bash
[root@docker2 ~]#
[root@docker2 ~]# ls -lh alpine-bash.tar
-rw------- 1 root root 7.6M Feb  4 12:34 alpine-bash.tar
[root@docker2 ~]#
[root@docker2 ~]# gzip -9 alpine-bash.tar
[root@docker2 ~]#
[root@docker2 ~]# ls -lh alpine-bash.tar.gz
-rw------- 1 root root 3.3M Feb  4 12:34 alpine-bash.tar.gz
[root@docker2 ~]#

[root@docker2 ~]# mkdir /root/dockerfile-1
[root@docker2 ~]#
[root@docker2 ~]# cd /root/dockerfile-1
[root@docker2 dockerfile-1]#
[root@docker2 dockerfile-1]# pwd
/root/dockerfile-1
[root@docker2 dockerfile-1]#

[root@docker2 dockerfile-1]# vi dockerfile
[root@docker2 dockerfile-1]#
[root@docker2 dockerfile-1]# cat dockerfile
FROM docker1.training.lab:5000/alpine
#FROM 192.168.66.51:5000/alpine
RUN apk add --no-cache --update-cache bash
CMD ["/bin/bash"]
[root@docker2 dockerfile-1]#


[root@docker2 dockerfile-1]# docker build -t alpine-bash-2 .
[+] Building 2.6s (6/6) FINISHED                                     docker:default
 => [internal] load build definition from dockerfile                           0.0s
 => => transferring dockerfile: 170B                                           0.0s
 => [internal] load metadata for docker1.training.lab:5000/alpine:latest       0.0s
 => [internal] load .dockerignore                                              0.0s
 => => transferring context: 2B                                                0.0s
 => [1/2] FROM docker1.training.lab:5000/alpine:latest@sha256:e4355b66995c96b  0.3s
 => => resolve docker1.training.lab:5000/alpine:latest@sha256:e4355b66995c96b  0.0s
 => => extracting sha256:89d9c30c1d48bac627e5c6cb0d1ed1eec28e7dbdfbcc04712e4c  0.1s
 => => sha256:e4355b66995c96b4b468159fc5c7e3540fcef961189ca13fee8 528B / 528B  0.0s
 => => sha256:965ea09ff2ebd2b9eeec88cd822ce156f6674c7e99be082 1.51kB / 1.51kB  0.0s
 => => sha256:89d9c30c1d48bac627e5c6cb0d1ed1eec28e7dbdfbcc047 2.79MB / 2.79MB  0.1s
 => [2/2] RUN apk add --no-cache --update-cache bash                           2.1s
 => exporting to image                                                         0.1s
 => => exporting layers                                                        0.1s
 => => writing image sha256:4cc47907f10b33ee7fa2003640b6cbed520e83408d0a8fd55  0.0s
 => => naming to docker.io/library/alpine-bash-2                               0.0s
[root@docker2 dockerfile-1]#


[root@docker2 dockerfile-1]# docker build -t alpine-bash-ccw0729 .
[+] Building 0.1s (6/6) FINISHED                                     docker:default
 => [internal] load build definition from dockerfile                           0.0s
 => => transferring dockerfile: 170B                                           0.0s
 => [internal] load metadata for docker1.training.lab:5000/alpine:latest       0.0s
 => [internal] load .dockerignore                                              0.0s
 => => transferring context: 2B                                                0.0s
 => [1/2] FROM docker1.training.lab:5000/alpine:latest@sha256:e4355b66995c96b  0.0s
 => CACHED [2/2] RUN apk add --no-cache --update-cache bash                    0.0s
 => exporting to image                                                         0.0s
 => => exporting layers                                                        0.0s
 => => writing image sha256:4cc47907f10b33ee7fa2003640b6cbed520e83408d0a8fd55  0.0s
 => => naming to docker.io/library/alpine-bash-ccw0729                         0.0s
[root@docker2 dockerfile-1]#

[root@docker2 dockerfile-1]# docker tag alpine-bash-ccw0729 ccw0729/alpine-bash-ccw0729
[root@docker2 dockerfile-1]#
[root@docker2 dockerfile-1]# docker images
REPOSITORY                    TAG       IMAGE ID       CREATED         SIZE
ccw0729/alpine-bash-ccw0729   latest    4cc47907f10b   6 minutes ago   7.55MB
alpine-bash-ccw0729           latest    4cc47907f10b   6 minutes ago   7.55MB
[root@docker2 dockerfile-1]#


[root@k8s-standalone ~]# wget http://10.0.1.248/k8s/scripts/install_k8s-latest.sh
--2025-02-04 12:46:29--  http://10.0.1.248/k8s/scripts/install_k8s-latest.sh
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 22517 (22K) [application/x-sh]
Saving to: ‘install_k8s-latest.sh’

install_k8s-latest.s 100%[======================>]  21.99K  --.-KB/s    in 0s

2025-02-04 12:46:29 (46.6 MB/s) - ‘install_k8s-latest.sh’ saved [22517/22517]

[root@k8s-standalone ~]#
[root@k8s-standalone ~]# chmod 755 install_k8s-latest.sh
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# ./install_k8s-latest.sh

請輸入 完整安裝(full) 或是 standalone
./install_k8s-latest.sh -full
或
./install_k8s-latest.sh -standalone

[root@k8s-standalone ~]# ./install_k8s-latest.sh -standalone

[root@k8s-standalone ~]# ./install_k8s-latest.sh -standalone

standalone

0 files removed
package sshpass is not installed
Rocky Linux 9 - BaseOS                            2.2 MB/s | 3.4 MB     00:01
Rocky Linux 9 - AppStream                         3.6 MB/s | 9.1 MB     00:02
Rocky Linux 9 - Extras                             14 kB/s |  16 kB     00:01
Dependencies resolved.
==================================================================================
 Package          Architecture    Version                Repository          Size
==================================================================================
Installing:
 sshpass          x86_64          1.09-4.el9             appstream           27 k

Transaction Summary
==================================================================================
Install  1 Package

Total download size: 27 k
Installed size: 47 k
Downloading Packages:
sshpass-1.09-4.el9.x86_64.rpm                      78 kB/s |  27 kB     00:00
----------------------------------------------------------------------------------
Total                                              25 kB/s |  27 kB     00:01
Rocky Linux 9 - AppStream                          49 kB/s | 1.7 kB     00:00
Importing GPG key 0x350D275D:
 Userid     : "Rocky Enterprise Software Foundation - Release key 2022 <releng@roc      kylinux.org>"
 Fingerprint: 21CB 256A E16F C54C 6E65 2949 702D 426D 350D 275D
 From       : /etc/pki/rpm-gpg/RPM-GPG-KEY-Rocky-9
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                          1/1
  Installing       : sshpass-1.09-4.el9.x86_64                                1/1
  Running scriptlet: sshpass-1.09-4.el9.x86_64                                1/1
  Verifying        : sshpass-1.09-4.el9.x86_64                                1/1

Installed:
  sshpass-1.09-4.el9.x86_64

Complete!

standalone，不用理會 worker node 的更新

Adding repo from: https://download.docker.com/linux/centos/docker-ce.repo
package docker-ce is not installed
Docker CE Stable - x86_64                         178 kB/s |  63 kB     00:00
Dependencies resolved.
==================================================================================
 Package                     Arch     Version            Repository          Size
==================================================================================
Installing:
 docker-ce                   x86_64   3:27.5.1-1.el9     docker-ce-stable    27 M
Installing dependencies:
 containerd.io               x86_64   1.7.25-3.1.el9     docker-ce-stable    43 M
 docker-ce-cli               x86_64   1:27.5.1-1.el9     docker-ce-stable   8.1 M
Installing weak dependencies:
 docker-buildx-plugin        x86_64   0.20.0-1.el9       docker-ce-stable    15 M
 docker-ce-rootless-extras   x86_64   27.5.1-1.el9       docker-ce-stable   4.4 M
 docker-compose-plugin       x86_64   2.32.4-1.el9       docker-ce-stable    14 M

Transaction Summary
==================================================================================
Install  6 Packages

Total download size: 111 M
Installed size: 440 M
Downloading Packages:
(1/6): docker-buildx-plugin-0.20.0-1.el9.x86_64.r 2.3 MB/s |  15 MB     00:06
(2/6): docker-ce-cli-27.5.1-1.el9.x86_64.rpm      1.2 MB/s | 8.1 MB     00:06
(3/6): docker-ce-rootless-extras-27.5.1-1.el9.x86 961 kB/s | 4.4 MB     00:04
(4/6): docker-ce-27.5.1-1.el9.x86_64.rpm          1.5 MB/s |  27 MB     00:18
(5/6): docker-compose-plugin-2.32.4-1.el9.x86_64. 1.8 MB/s |  14 MB     00:07
(6/6): containerd.io-1.7.25-3.1.el9.x86_64.rpm    1.7 MB/s |  43 MB     00:26
----------------------------------------------------------------------------------
Total                                             4.3 MB/s | 111 MB     00:26
Docker CE Stable - x86_64                          18 kB/s | 1.6 kB     00:00
Importing GPG key 0x621E9F35:
 Userid     : "Docker Release (CE rpm) <docker@docker.com>"
 Fingerprint: 060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35
 From       : https://download.docker.com/linux/centos/gpg
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                          1/1
  Installing       : docker-compose-plugin-2.32.4-1.el9.x86_64                1/6
  Running scriptlet: docker-compose-plugin-2.32.4-1.el9.x86_64                1/6
  Installing       : docker-buildx-plugin-0.20.0-1.el9.x86_64                 2/6
  Running scriptlet: docker-buildx-plugin-0.20.0-1.el9.x86_64                 2/6
  Installing       : docker-ce-cli-1:27.5.1-1.el9.x86_64                      3/6
  Running scriptlet: docker-ce-cli-1:27.5.1-1.el9.x86_64                      3/6
  Installing       : containerd.io-1.7.25-3.1.el9.x86_64                      4/6
  Running scriptlet: containerd.io-1.7.25-3.1.el9.x86_64                      4/6
  Installing       : docker-ce-rootless-extras-27.5.1-1.el9.x86_64            5/6
  Running scriptlet: docker-ce-rootless-extras-27.5.1-1.el9.x86_64            5/6
  Installing       : docker-ce-3:27.5.1-1.el9.x86_64                          6/6
  Running scriptlet: docker-ce-3:27.5.1-1.el9.x86_64                          6/6
  Verifying        : containerd.io-1.7.25-3.1.el9.x86_64                      1/6
  Verifying        : docker-buildx-plugin-0.20.0-1.el9.x86_64                 2/6
  Verifying        : docker-ce-3:27.5.1-1.el9.x86_64                          3/6
  Verifying        : docker-ce-cli-1:27.5.1-1.el9.x86_64                      4/6
  Verifying        : docker-ce-rootless-extras-27.5.1-1.el9.x86_64            5/6
  Verifying        : docker-compose-plugin-2.32.4-1.el9.x86_64                6/6

Installed:
  containerd.io-1.7.25-3.1.el9.x86_64
  docker-buildx-plugin-0.20.0-1.el9.x86_64
  docker-ce-3:27.5.1-1.el9.x86_64
  docker-ce-cli-1:27.5.1-1.el9.x86_64
  docker-ce-rootless-extras-27.5.1-1.el9.x86_64
  docker-compose-plugin-2.32.4-1.el9.x86_64

Complete!
Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/      lib/systemd/system/docker.service.

standalone，不用理會 worker node 的 docker 套件

Last metadata expiration check: 0:01:21 ago on Tue 04 Feb 2025 01:58:53 PM CST.
Package bash-completion-1:2.11-5.el9.noarch is already installed.
Dependencies resolved.
Nothing to do.
Complete!

standalone，不用理會 worker node 的 指令補齊(TAB)功能

               total        used        free      shared  buff/cache   available
Mem:            3626         996        1803          15        1077        2629
Swap:           4011           0        4011
               total        used        free      shared  buff/cache   available
Mem:            3626         992        1808          15        1077        2633
Swap:              0           0           0

#
# /etc/fstab
# Created by anaconda on Mon Dec 30 03:09:13 2024
#
# Accessible filesystems, by reference, are maintained under '/dev/disk/'.
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info.
#
# After editing this file, run 'systemctl daemon-reload' to update systemd
# units generated from this file.
#
/dev/mapper/rl-root     /                       xfs     defaults        0 0
UUID=253f75a6-e58f-41cc-8e6c-3eec510264d6 /boot                   xfs     defaults              0 0
/dev/mapper/rl-home     /home                   xfs     defaults        0 0
#/dev/mapper/rl-swap     none                    swap    defaults        0 0

standalone，不用理會 worker node 的 swap

* Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...
* Applying /usr/lib/sysctl.d/50-coredump.conf ...
* Applying /usr/lib/sysctl.d/50-default.conf ...
* Applying /usr/lib/sysctl.d/50-libkcapi-optmem_max.conf ...
* Applying /usr/lib/sysctl.d/50-pid-max.conf ...
* Applying /usr/lib/sysctl.d/50-redhat.conf ...
* Applying /etc/sysctl.d/99-sysctl.conf ...
* Applying /etc/sysctl.d/k8s.conf ...
* Applying /etc/sysctl.conf ...
kernel.yama.ptrace_scope = 0
kernel.core_pattern = |/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h
kernel.core_pipe_limit = 16
fs.suid_dumpable = 2
kernel.sysrq = 16
kernel.core_uses_pid = 1
net.ipv4.conf.default.rp_filter = 2
net.ipv4.conf.docker0.rp_filter = 2
net.ipv4.conf.ens160.rp_filter = 2
net.ipv4.conf.lo.rp_filter = 2
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.docker0.accept_source_route = 0
net.ipv4.conf.ens160.accept_source_route = 0
net.ipv4.conf.lo.accept_source_route = 0
net.ipv4.conf.default.promote_secondaries = 1
net.ipv4.conf.docker0.promote_secondaries = 1
net.ipv4.conf.ens160.promote_secondaries = 1
net.ipv4.conf.lo.promote_secondaries = 1
net.ipv4.ping_group_range = 0 2147483647
net.core.default_qdisc = fq_codel
fs.protected_hardlinks = 1
fs.protected_symlinks = 1
fs.protected_regular = 1
fs.protected_fifos = 1
net.core.optmem_max = 81920
kernel.pid_max = 4194304
kernel.kptr_restrict = 1
net.ipv4.conf.default.rp_filter = 1
net.ipv4.conf.docker0.rp_filter = 1
net.ipv4.conf.ens160.rp_filter = 1
net.ipv4.conf.lo.rp_filter = 1
net.ipv4.ip_forward = 1
Last metadata expiration check: 0:01:24 ago on Tue 04 Feb 2025 01:58:53 PM CST.
Package curl-7.76.1-31.el9.x86_64 is already installed.
Dependencies resolved.
==================================================================================
 Package                     Arch        Version             Repository      Size
==================================================================================
Installing:
 conntrack-tools             x86_64      1.4.7-2.el9         appstream      221 k
 ipvsadm                     x86_64      1.31-6.el9          appstream       50 k
 sysstat                     x86_64      12.5.4-9.el9        appstream      465 k
Installing dependencies:
 libnetfilter_cthelper       x86_64      1.0.0-22.el9        appstream       23 k
 libnetfilter_cttimeout      x86_64      1.0.0-19.el9        appstream       23 k
 libnetfilter_queue          x86_64      1.0.5-1.el9         appstream       28 k
 lm_sensors-libs             x86_64      3.6.0-10.el9        appstream       41 k
 pcp-conf                    x86_64      6.2.2-7.el9_5       appstream       29 k
 pcp-libs                    x86_64      6.2.2-7.el9_5       appstream      638 k

Transaction Summary
==================================================================================
Install  9 Packages

Total download size: 1.5 M
Installed size: 4.1 M
Downloading Packages:
(1/9): libnetfilter_cttimeout-1.0.0-19.el9.x86_64  94 kB/s |  23 kB     00:00
(2/9): lm_sensors-libs-3.6.0-10.el9.x86_64.rpm    149 kB/s |  41 kB     00:00
(3/9): ipvsadm-1.31-6.el9.x86_64.rpm              347 kB/s |  50 kB     00:00
(4/9): conntrack-tools-1.4.7-2.el9.x86_64.rpm     448 kB/s | 221 kB     00:00
(5/9): libnetfilter_cthelper-1.0.0-22.el9.x86_64. 205 kB/s |  23 kB     00:00
(6/9): libnetfilter_queue-1.0.5-1.el9.x86_64.rpm  166 kB/s |  28 kB     00:00
(7/9): sysstat-12.5.4-9.el9.x86_64.rpm            954 kB/s | 465 kB     00:00
(8/9): pcp-conf-6.2.2-7.el9_5.x86_64.rpm          271 kB/s |  29 kB     00:00
(9/9): pcp-libs-6.2.2-7.el9_5.x86_64.rpm          1.5 MB/s | 638 kB     00:00
----------------------------------------------------------------------------------
Total                                             911 kB/s | 1.5 MB     00:01
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                          1/1
  Installing       : pcp-conf-6.2.2-7.el9_5.x86_64                            1/9
  Installing       : pcp-libs-6.2.2-7.el9_5.x86_64                            2/9
  Installing       : libnetfilter_queue-1.0.5-1.el9.x86_64                    3/9
  Installing       : libnetfilter_cthelper-1.0.0-22.el9.x86_64                4/9
  Installing       : lm_sensors-libs-3.6.0-10.el9.x86_64                      5/9
  Installing       : libnetfilter_cttimeout-1.0.0-19.el9.x86_64               6/9
  Installing       : conntrack-tools-1.4.7-2.el9.x86_64                       7/9
  Running scriptlet: conntrack-tools-1.4.7-2.el9.x86_64                       7/9
  Installing       : sysstat-12.5.4-9.el9.x86_64                              8/9
  Running scriptlet: sysstat-12.5.4-9.el9.x86_64                              8/9
Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /usr      /lib/systemd/system/sysstat.service.
Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer →       /usr/lib/systemd/system/sysstat-collect.timer.
Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer →       /usr/lib/systemd/system/sysstat-summary.timer.

  Installing       : ipvsadm-1.31-6.el9.x86_64                                9/9
  Running scriptlet: ipvsadm-1.31-6.el9.x86_64                                9/9
  Verifying        : conntrack-tools-1.4.7-2.el9.x86_64                       1/9
  Verifying        : libnetfilter_cttimeout-1.0.0-19.el9.x86_64               2/9
  Verifying        : lm_sensors-libs-3.6.0-10.el9.x86_64                      3/9
  Verifying        : ipvsadm-1.31-6.el9.x86_64                                4/9
  Verifying        : sysstat-12.5.4-9.el9.x86_64                              5/9
  Verifying        : libnetfilter_cthelper-1.0.0-22.el9.x86_64                6/9
  Verifying        : libnetfilter_queue-1.0.5-1.el9.x86_64                    7/9
  Verifying        : pcp-libs-6.2.2-7.el9_5.x86_64                            8/9
  Verifying        : pcp-conf-6.2.2-7.el9_5.x86_64                            9/9

Installed:
  conntrack-tools-1.4.7-2.el9.x86_64
  ipvsadm-1.31-6.el9.x86_64
  libnetfilter_cthelper-1.0.0-22.el9.x86_64
  libnetfilter_cttimeout-1.0.0-19.el9.x86_64
  libnetfilter_queue-1.0.5-1.el9.x86_64
  lm_sensors-libs-3.6.0-10.el9.x86_64
  pcp-conf-6.2.2-7.el9_5.x86_64
  pcp-libs-6.2.2-7.el9_5.x86_64
  sysstat-12.5.4-9.el9.x86_64

Complete!

standalone，不用理會 worker node 的 kerenl 參數

[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/repodata/repomd.xml.key
32 files removed
Docker CE Stable - x86_64                         235 kB/s |  63 kB     00:00
Kubernetes                                        8.2 kB/s | 7.8 kB     00:00
Rocky Linux 9 - BaseOS                            2.0 MB/s | 3.4 MB     00:01
Rocky Linux 9 - AppStream                         2.9 MB/s | 9.1 MB     00:03
Rocky Linux 9 - Extras                             17 kB/s |  16 kB     00:00
Dependencies resolved.
==================================================================================
 Package              Architecture Version                 Repository        Size
==================================================================================
Installing:
 kubeadm              x86_64       1.32.1-150500.1.1       kubernetes        12 M
 kubectl              x86_64       1.32.1-150500.1.1       kubernetes        11 M
 kubelet              x86_64       1.32.1-150500.1.1       kubernetes        15 M
Installing dependencies:
 cri-tools            x86_64       1.32.0-150500.1.1       kubernetes       7.1 M
 kubernetes-cni       x86_64       1.6.0-150500.1.1        kubernetes       8.0 M

Transaction Summary
==================================================================================
Install  5 Packages

Total download size: 52 M
Installed size: 288 M
Downloading Packages:
(1/5): cri-tools-1.32.0-150500.1.1.x86_64.rpm     2.1 MB/s | 7.1 MB     00:03
(2/5): kubectl-1.32.1-150500.1.1.x86_64.rpm       1.7 MB/s |  11 MB     00:06
(3/5): kubeadm-1.32.1-150500.1.1.x86_64.rpm       1.5 MB/s |  12 MB     00:07
(4/5): kubelet-1.32.1-150500.1.1.x86_64.rpm       2.3 MB/s |  15 MB     00:06
(5/5): kubernetes-cni-1.6.0-150500.1.1.x86_64.rpm 2.0 MB/s | 8.0 MB     00:03
----------------------------------------------------------------------------------
Total                                             5.0 MB/s |  52 MB     00:10
Kubernetes                                        3.5 kB/s | 1.7 kB     00:00
Importing GPG key 0x9A296436:
 Userid     : "isv:kubernetes OBS Project <isv:kubernetes@build.opensuse.org>"
 Fingerprint: DE15 B144 86CD 377B 9E87 6E1A 2346 54DA 9A29 6436
 From       : https://pkgs.k8s.io/core:/stable:/v1.32/rpm/repodata/repomd.xml.key
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                          1/1
  Installing       : kubernetes-cni-1.6.0-150500.1.1.x86_64                   1/5
  Installing       : cri-tools-1.32.0-150500.1.1.x86_64                       2/5
  Installing       : kubeadm-1.32.1-150500.1.1.x86_64                         3/5
  Installing       : kubelet-1.32.1-150500.1.1.x86_64                         4/5
  Running scriptlet: kubelet-1.32.1-150500.1.1.x86_64                         4/5
  Installing       : kubectl-1.32.1-150500.1.1.x86_64                         5/5
  Running scriptlet: kubectl-1.32.1-150500.1.1.x86_64                         5/5
  Verifying        : cri-tools-1.32.0-150500.1.1.x86_64                       1/5
  Verifying        : kubeadm-1.32.1-150500.1.1.x86_64                         2/5
  Verifying        : kubectl-1.32.1-150500.1.1.x86_64                         3/5
  Verifying        : kubelet-1.32.1-150500.1.1.x86_64                         4/5
  Verifying        : kubernetes-cni-1.6.0-150500.1.1.x86_64                   5/5

Installed:
  cri-tools-1.32.0-150500.1.1.x86_64         kubeadm-1.32.1-150500.1.1.x86_64
  kubectl-1.32.1-150500.1.1.x86_64           kubelet-1.32.1-150500.1.1.x86_64
  kubernetes-cni-1.6.0-150500.1.1.x86_64

Complete!
Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /usr      /lib/systemd/system/kubelet.service.

standalone，不用理會 worker node 的 安裝 k8s RPM 套件

[cri-o]
name=CRI-O
baseurl=https://pkgs.k8s.io/addons:/cri-o:/stable:/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/addons:/cri-o:/stable:/v1.32/rpm/repodata/repomd.xml.ke      y
CRI-O                                             4.1 kB/s | 3.2 kB     00:00
Last metadata expiration check: 0:00:01 ago on Tue 04 Feb 2025 02:01:31 PM CST.
Package cri-tools-1.32.0-150500.1.1.x86_64 is already installed.
Dependencies resolved.
==================================================================================
 Package        Architecture    Version                      Repository      Size
==================================================================================
Installing:
 cri-o          x86_64          1.32.1-150500.1.1            cri-o           20 M

Transaction Summary
==================================================================================
Install  1 Package

Total download size: 20 M
Installed size: 76 M
Downloading Packages:
cri-o-1.32.1-150500.1.1.x86_64.rpm                4.9 MB/s |  20 MB     00:04
----------------------------------------------------------------------------------
Total                                             4.9 MB/s |  20 MB     00:04
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                          1/1
  Installing       : cri-o-1.32.1-150500.1.1.x86_64                           1/1
  Running scriptlet: cri-o-1.32.1-150500.1.1.x86_64                           1/1
  Verifying        : cri-o-1.32.1-150500.1.1.x86_64                           1/1

Installed:
  cri-o-1.32.1-150500.1.1.x86_64

Complete!
Created symlink /etc/systemd/system/cri-o.service → /usr/lib/systemd/system/crio.s      ervice.
Created symlink /etc/systemd/system/multi-user.target.wants/crio.service → /usr/li      b/systemd/system/crio.service.

standalone，不用理會 worker node 的 cri-o

Removed "/etc/systemd/system/multi-user.target.wants/firewalld.service".
Removed "/etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service".

standalone，不用理會 worker node 的更新

W0204 14:01:52.091065   35404 initconfiguration.go:126] Usage of CRI endpoints wit      hout URL scheme is deprecated and can cause kubelet errors in the future. Automati      cally prepending scheme "unix" to the "criSocket" with value "/var/run/crio/crio.s      ock". Please update your configuration!
[init] Using Kubernetes version: v1.32.1
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your intern      et connection
[preflight] You can also perform this action beforehand using 'kubeadm config imag      es pull'
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [k8s-standalone.training.la      b kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.clus      ter.local] and IPs [172.30.0.1 192.168.66.61]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [k8s-standalone.training.      lab localhost] and IPs [192.168.66.61 127.0.0.1 ::1]
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [k8s-standalone.training.la      b localhost] and IPs [192.168.66.61 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "sa" key and public key
[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "super-admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
[control-plane] Creating static Pod manifest for "kube-scheduler"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kube      let/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yam      l"
[kubelet-start] Starting the kubelet
[wait-control-plane] Waiting for the kubelet to boot up the control plane as stati      c Pods from directory "/etc/kubernetes/manifests"
[kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. T      his can take up to 4m0s
[kubelet-check] The kubelet is healthy after 2.068241768s
[api-check] Waiting for a healthy API server. This can take up to 4m0s
[api-check] The API server is healthy after 16.002141979s
[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in th      e "kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config" in namespace kube-system with the       configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node k8s-standalone.training.lab as control-plane       by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/e      xclude-from-external-load-balancers]
[mark-control-plane] Marking the node k8s-standalone.training.lab as control-plane       by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]
[bootstrap-token] Using token: a4urbw.38c04et6o8vtenbw
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get node      s
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSR      s in order for nodes to get long term certificate credentials
[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automa      tically approve CSRs from a Node Bootstrap Token
[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node       client certificates in the cluster
[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" names      pace
[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable       kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as r      oot:

kubeadm join 192.168.66.61:6443 --token a4urbw.38c04et6o8vtenbw \
        --discovery-token-ca-cert-hash sha256:e980af8e264ef403c9c53ce90da08271a95e      42950baf2b50e0e9bec8fa5ccef1
NAME                          STATUS     ROLES           AGE   VERSION
k8s-standalone.training.lab   NotReady   control-plane   9s    v1.32.1
e980af8e264ef403c9c53ce90da08271a95e42950baf2b50e0e9bec8fa5ccef1
a4urbw.38c04et6o8vtenbw
kubeadm join 192.168.66.61:6443 --token 5ydxaf.k73rguavkrek11im --discovery-token-      ca-cert-hash sha256:e980af8e264ef403c9c53ce90da08271a95e42950baf2b50e0e9bec8fa5cce      f1
the bootstrap token "ttl" was not of the form "\\A([a-z0-9]{6})\\.([a-z0-9]{16})\\      z"
To see the stack trace of this error execute with --v=5 or higher

standalone，不用理會 worker node 的 加入 worker node

NAME                          STATUS     ROLES           AGE   VERSION
k8s-standalone.training.lab   NotReady   control-plane   11s   v1.32.1
customresourcedefinition.apiextensions.k8s.io/antreaagentinfos.clusterinformation.      antrea.tanzu.vmware.com created
customresourcedefinition.apiextensions.k8s.io/antreaagentinfos.crd.antrea.io creat      ed
customresourcedefinition.apiextensions.k8s.io/antreacontrollerinfos.cluster             information.antrea.tanzu.vmware.com created
customresourcedefinition.apiextensions.k8s.io/antreacontrollerinfos.crd.ant             rea.io created
customresourcedefinition.apiextensions.k8s.io/clustergroups.core.antrea.tan             zu.vmware.com created
customresourcedefinition.apiextensions.k8s.io/clustergroups.crd.antrea.io c             reated
customresourcedefinition.apiextensions.k8s.io/clusternetworkpolicies.crd.an             trea.io created
customresourcedefinition.apiextensions.k8s.io/clusternetworkpolicies.securi             ty.antrea.tanzu.vmware.com created
customresourcedefinition.apiextensions.k8s.io/egresses.crd.antrea.io create             d
customresourcedefinition.apiextensions.k8s.io/externalentities.core.antrea.             tanzu.vmware.com created
customresourcedefinition.apiextensions.k8s.io/externalentities.crd.antrea.i             o created
customresourcedefinition.apiextensions.k8s.io/externalippools.crd.antrea.io              created
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.antrea.io              created
customresourcedefinition.apiextensions.k8s.io/networkpolicies.security.antr             ea.tanzu.vmware.com created
customresourcedefinition.apiextensions.k8s.io/tiers.crd.antrea.io created
customresourcedefinition.apiextensions.k8s.io/tiers.security.antrea.tanzu.v             mware.com created
customresourcedefinition.apiextensions.k8s.io/traceflows.crd.antrea.io crea             ted
customresourcedefinition.apiextensions.k8s.io/traceflows.ops.antrea.tanzu.v             mware.com created
serviceaccount/antctl created
serviceaccount/antrea-agent created
serviceaccount/antrea-controller created
clusterrole.rbac.authorization.k8s.io/aggregate-antrea-clustergroups-edit c             reated
clusterrole.rbac.authorization.k8s.io/aggregate-antrea-clustergroups-view c             reated
clusterrole.rbac.authorization.k8s.io/aggregate-antrea-policies-edit create             d
clusterrole.rbac.authorization.k8s.io/aggregate-antrea-policies-view create             d
clusterrole.rbac.authorization.k8s.io/aggregate-traceflows-edit created
clusterrole.rbac.authorization.k8s.io/aggregate-traceflows-view created
clusterrole.rbac.authorization.k8s.io/antctl created
clusterrole.rbac.authorization.k8s.io/antrea-agent created
clusterrole.rbac.authorization.k8s.io/antrea-cluster-identity-reader create             d
clusterrole.rbac.authorization.k8s.io/antrea-controller created
clusterrolebinding.rbac.authorization.k8s.io/antctl created
clusterrolebinding.rbac.authorization.k8s.io/antrea-agent created
clusterrolebinding.rbac.authorization.k8s.io/antrea-controller created
configmap/antrea-config-t8cc9bfb6t created
service/antrea created
deployment.apps/antrea-controller created
apiservice.apiregistration.k8s.io/v1alpha1.stats.antrea.io created
apiservice.apiregistration.k8s.io/v1alpha1.stats.antrea.tanzu.vmware.com cr             eated
apiservice.apiregistration.k8s.io/v1beta1.controlplane.antrea.tanzu.vmware.             com created
apiservice.apiregistration.k8s.io/v1beta1.system.antrea.io created
apiservice.apiregistration.k8s.io/v1beta1.system.antrea.tanzu.vmware.com cr             eated
apiservice.apiregistration.k8s.io/v1beta2.controlplane.antrea.io created
apiservice.apiregistration.k8s.io/v1beta2.controlplane.antrea.tanzu.vmware.             com created
daemonset.apps/antrea-agent created
mutatingwebhookconfiguration.admissionregistration.k8s.io/crdmutator.antrea             .io created
mutatingwebhookconfiguration.admissionregistration.k8s.io/crdmutator.antrea             .tanzu.vmware.com created
validatingwebhookconfiguration.admissionregistration.k8s.io/crdvalidator.an             trea.io created
validatingwebhookconfiguration.admissionregistration.k8s.io/crdvalidator.an             trea.tanzu.vmware.com created
NAME                          STATUS     ROLES           AGE   VERSION
k8s-standalone.training.lab   NotReady   control-plane   31s   v1.32.1
NAME                          STATUS     ROLES           AGE   VERSION
k8s-standalone.training.lab   NotReady   control-plane   32s   v1.32.1

Wait 30 seconds for get Ready...

k8s-standalone.training.lab

standalone，開放 master 執行 pods

Taints:             node-role.kubernetes.io/control-plane:NoSchedule
error: node k8s-standalone.training.lab already has node-role.kubernetes.io             /control-plane taint(s) with same effect(s) and --overwrite is false
node/k8s-standalone.training.lab untainted
Taints:             node.kubernetes.io/not-ready:NoSchedule
NAME                          STATUS     ROLES           AGE   VERSION
k8s-standalone.training.lab   NotReady   control-plane   64s   v1.32.1
[root@k8s-standalone ~]#

[root@k8s-standalone ~]# while true; do date; kubectl get nodes; sleep 10; done
Tue Feb  4 02:04:57 PM CST 2025
NAME                          STATUS     ROLES           AGE   VERSION
k8s-standalone.training.lab   NotReady   control-plane   57s   v1.32.1
Tue Feb  4 02:05:07 PM CST 2025
NAME                          STATUS     ROLES           AGE   VERSION
k8s-standalone.training.lab   NotReady   control-plane   67s   v1.32.1
Tue Feb  4 02:05:18 PM CST 2025
NAME                          STATUS     ROLES           AGE   VERSION
k8s-standalone.training.lab   NotReady   control-plane   78s   v1.32.1
Tue Feb  4 02:05:28 PM CST 2025
NAME                          STATUS     ROLES           AGE   VERSION
k8s-standalone.training.lab   NotReady   control-plane   89s   v1.32.1
Tue Feb  4 02:05:39 PM CST 2025
NAME                          STATUS     ROLES           AGE    VERSION
k8s-standalone.training.lab   NotReady   control-plane   100s   v1.32.1
Tue Feb  4 02:05:50 PM CST 2025
NAME                          STATUS     ROLES           AGE    VERSION
k8s-standalone.training.lab   NotReady   control-plane   110s   v1.32.1
Tue Feb  4 02:06:00 PM CST 2025
NAME                          STATUS     ROLES           AGE    VERSION
k8s-standalone.training.lab   NotReady   control-plane   2m1s   v1.32.1
Tue Feb  4 02:06:11 PM CST 2025
NAME                          STATUS     ROLES           AGE     VERSION
k8s-standalone.training.lab   NotReady   control-plane   2m11s   v1.32.1
Tue Feb  4 02:06:21 PM CST 2025
NAME                          STATUS     ROLES           AGE     VERSION
k8s-standalone.training.lab   NotReady   control-plane   2m21s   v1.32.1
Tue Feb  4 02:06:31 PM CST 2025
NAME                          STATUS     ROLES           AGE     VERSION
k8s-standalone.training.lab   NotReady   control-plane   2m31s   v1.32.1
Tue Feb  4 02:06:41 PM CST 2025
NAME                          STATUS     ROLES           AGE     VERSION
k8s-standalone.training.lab   NotReady   control-plane   2m42s   v1.32.1
Tue Feb  4 02:06:52 PM CST 2025
NAME                          STATUS     ROLES           AGE     VERSION
k8s-standalone.training.lab   NotReady   control-plane   2m52s   v1.32.1
Tue Feb  4 02:07:02 PM CST 2025
NAME                          STATUS   ROLES           AGE    VERSION
k8s-standalone.training.lab   Ready    control-plane   3m2s   v1.32.1
Tue Feb  4 02:07:12 PM CST 2025
NAME                          STATUS   ROLES           AGE     VERSION
k8s-standalone.training.lab   Ready    control-plane   3m13s   v1.32.1
^C
[root@k8s-standalone ~]#




[root@k8s-standalone ~]# kubectl create deployment test1 --image=nginx
deployment.apps/test1 created
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# kubectl get deployments
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
test1   1/1     1            1           38s
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
test1-7d9bdc56f4-68l7n   1/1     Running   0          43s
[root@k8s-standalone ~]# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP           NODE                          NOMINATED NODE   READINESS GATES
test1-7d9bdc56f4-68l7n   1/1     Running   0          46s   10.128.0.4   k8s-standalone.training.lab   <none>           <none>
[root@k8s-standalone ~]#

[root@k8s-standalone ~]# curl 10.128.0.4
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
[root@k8s-standalone ~]#


[root@k8s-master1 ~]# wget http://10.0.1.248/k8s/scripts/install_k8s-latest.sh
--2025-02-04 12:57:21--  http://10.0.1.248/k8s/scripts/install_k8s-latest.sh
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 22517 (22K) [application/x-sh]
Saving to: ‘install_k8s-latest.sh’

install_k8s-latest.s 100%[======================>]  21.99K  --.-KB/s    in 0.001s

2025-02-04 12:57:21 (15.9 MB/s) - ‘install_k8s-latest.sh’ saved [22517/22517]

[root@k8s-master1 ~]#
[root@k8s-master1 ~]# chmod 755 install_k8s-latest.sh
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# ./install_k8s-latest.sh

請輸入 完整安裝(full) 或是 standalone
./install_k8s-latest.sh -full
或
./install_k8s-latest.sh -standalone

[root@k8s-master1 ~]# ./install_k8s-latest.sh -full

[root@k8s-master1 ~]# ./install_k8s-latest.sh -full

完整安裝(full)

25 files removed
package sshpass is not installed
Rocky Linux 9 - BaseOS                              1.7 MB/s | 3.4 MB     00:02
Rocky Linux 9 - AppStream                           1.8 MB/s | 9.1 MB     00:05
Rocky Linux 9 - Extras                               13 kB/s |  16 kB     00:01
Dependencies resolved.
===================================================================================
 Package           Architecture     Version               Repository           Size
===================================================================================
Installing:
 sshpass           x86_64           1.09-4.el9            appstream            27 k

Transaction Summary
===================================================================================
Install  1 Package

Total download size: 27 k
Installed size: 47 k
Downloading Packages:
sshpass-1.09-4.el9.x86_64.rpm                        56 kB/s |  27 kB     00:00
-----------------------------------------------------------------------------------
Total                                                24 kB/s |  27 kB     00:01
Rocky Linux 9 - AppStream                           1.1 MB/s | 1.7 kB     00:00
Importing GPG key 0x350D275D:
 Userid     : "Rocky Enterprise Software Foundation - Release key 2022 <releng@rocklinux.org>"
 Fingerprint: 21CB 256A E16F C54C 6E65 2949 702D 426D 350D 275D
 From       : /etc/pki/rpm-gpg/RPM-GPG-KEY-Rocky-9
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                            1/1
  Installing       : sshpass-1.09-4.el9.x86_64                                  1/1
  Running scriptlet: sshpass-1.09-4.el9.x86_64                                  1/1
  Verifying        : sshpass-1.09-4.el9.x86_64                                  1/1

Installed:
  sshpass-1.09-4.el9.x86_64

Complete!

完整安裝(full)

Adding repo from: https://download.docker.com/linux/centos/docker-ce.repo
package docker-ce is not installed
Docker CE Stable - x86_64                           193 kB/s |  63 kB     00:00
Dependencies resolved.
===================================================================================
 Package                      Arch      Version           Repository           Size
===================================================================================
Installing:
 docker-ce                    x86_64    3:27.5.1-1.el9    docker-ce-stable     27 M
Installing dependencies:
 containerd.io                x86_64    1.7.25-3.1.el9    docker-ce-stable     43 M
 docker-ce-cli                x86_64    1:27.5.1-1.el9    docker-ce-stable    8.1 M
Installing weak dependencies:
 docker-buildx-plugin         x86_64    0.20.0-1.el9      docker-ce-stable     15 M
 docker-ce-rootless-extras    x86_64    27.5.1-1.el9      docker-ce-stable    4.4 M
 docker-compose-plugin        x86_64    2.32.4-1.el9      docker-ce-stable     14 M

Transaction Summary
===================================================================================
Install  6 Packages

Total download size: 111 M
Installed size: 440 M
Downloading Packages:
(1/6): docker-buildx-plugin-0.20.0-1.el9.x86_64.rpm 1.7 MB/s |  15 MB     00:08
(2/6): docker-ce-27.5.1-1.el9.x86_64.rpm            1.9 MB/s |  27 MB     00:14
(3/6): docker-ce-cli-27.5.1-1.el9.x86_64.rpm        1.4 MB/s | 8.1 MB     00:05
(4/6): docker-ce-rootless-extras-27.5.1-1.el9.x86_6 1.0 MB/s | 4.4 MB     00:04
(5/6): docker-compose-plugin-2.32.4-1.el9.x86_64.rp 1.9 MB/s |  14 MB     00:07
(6/6): containerd.io-1.7.25-3.1.el9.x86_64.rpm      1.7 MB/s |  43 MB     00:25
-----------------------------------------------------------------------------------
Total                                               4.4 MB/s | 111 MB     00:25
Docker CE Stable - x86_64                            22 kB/s | 1.6 kB     00:00
Importing GPG key 0x621E9F35:
 Userid     : "Docker Release (CE rpm) <docker@docker.com>"
 Fingerprint: 060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35
 From       : https://download.docker.com/linux/centos/gpg
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                            1/1
  Installing       : docker-compose-plugin-2.32.4-1.el9.x86_64                  1/6
  Running scriptlet: docker-compose-plugin-2.32.4-1.el9.x86_64                  1/6
  Installing       : docker-buildx-plugin-0.20.0-1.el9.x86_64                   2/6
  Running scriptlet: docker-buildx-plugin-0.20.0-1.el9.x86_64                   2/6
  Installing       : docker-ce-cli-1:27.5.1-1.el9.x86_64                        3/6
  Running scriptlet: docker-ce-cli-1:27.5.1-1.el9.x86_64                        3/6
  Installing       : containerd.io-1.7.25-3.1.el9.x86_64                        4/6
  Running scriptlet: containerd.io-1.7.25-3.1.el9.x86_64                        4/6
  Installing       : docker-ce-rootless-extras-27.5.1-1.el9.x86_64              5/6
  Running scriptlet: docker-ce-rootless-extras-27.5.1-1.el9.x86_64              5/6
  Installing       : docker-ce-3:27.5.1-1.el9.x86_64                            6/6
  Running scriptlet: docker-ce-3:27.5.1-1.el9.x86_64                            6/6
  Verifying        : containerd.io-1.7.25-3.1.el9.x86_64                        1/6
  Verifying        : docker-buildx-plugin-0.20.0-1.el9.x86_64                   2/6
  Verifying        : docker-ce-3:27.5.1-1.el9.x86_64                            3/6
  Verifying        : docker-ce-cli-1:27.5.1-1.el9.x86_64                        4/6
  Verifying        : docker-ce-rootless-extras-27.5.1-1.el9.x86_64              5/6
  Verifying        : docker-compose-plugin-2.32.4-1.el9.x86_64                  6/6

Installed:
  containerd.io-1.7.25-3.1.el9.x86_64
  docker-buildx-plugin-0.20.0-1.el9.x86_64
  docker-ce-3:27.5.1-1.el9.x86_64
  docker-ce-cli-1:27.5.1-1.el9.x86_64
  docker-ce-rootless-extras-27.5.1-1.el9.x86_64
  docker-compose-plugin-2.32.4-1.el9.x86_64

Complete!
Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lb/systemd/system/docker.service.

完整安裝(full)，檢查是否安裝 docker 套件

Warning: Permanently added 'k8s-node1' (ED25519) to the list of known hosts.
Adding repo from: https://download.docker.com/linux/centos/docker-ce.repo
package docker-ce is not installed
Docker CE Stable - x86_64                       284 kB/s |  63 kB     00:00
Dependencies resolved.
================================================================================
 Package                     Arch     Version          Repository          Size
================================================================================
Installing:
 docker-ce                   x86_64   3:27.5.1-1.el9   docker-ce-stable    27 M
Installing dependencies:
 containerd.io               x86_64   1.7.25-3.1.el9   docker-ce-stable    43 M
 docker-ce-cli               x86_64   1:27.5.1-1.el9   docker-ce-stable   8.1 M
Installing weak dependencies:
 docker-buildx-plugin        x86_64   0.20.0-1.el9     docker-ce-stable    15 M
 docker-ce-rootless-extras   x86_64   27.5.1-1.el9     docker-ce-stable   4.4 M
 docker-compose-plugin       x86_64   2.32.4-1.el9     docker-ce-stable    14 M

Transaction Summary
================================================================================
Install  6 Packages

Total download size: 111 M
Installed size: 440 M
Downloading Packages:
(1/6): docker-buildx-plugin-0.20.0-1.el9.x86_64 1.7 MB/s |  15 MB     00:08
(2/6): docker-ce-27.5.1-1.el9.x86_64.rpm        1.8 MB/s |  27 MB     00:15
(3/6): docker-ce-cli-27.5.1-1.el9.x86_64.rpm    904 kB/s | 8.1 MB     00:09
(4/6): docker-ce-rootless-extras-27.5.1-1.el9.x 1.2 MB/s | 4.4 MB     00:03
(5/6): docker-compose-plugin-2.32.4-1.el9.x86_6 1.3 MB/s |  14 MB     00:10
(6/6): containerd.io-1.7.25-3.1.el9.x86_64.rpm  1.5 MB/s |  43 MB     00:29
--------------------------------------------------------------------------------
Total                                           3.8 MB/s | 111 MB     00:29
Docker CE Stable - x86_64                        14 kB/s | 1.6 kB     00:00
Importing GPG key 0x621E9F35:
 Userid     : "Docker Release (CE rpm) <docker@docker.com>"
 Fingerprint: 060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35
 From       : https://download.docker.com/linux/centos/gpg
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                        1/1
  Installing       : docker-compose-plugin-2.32.4-1.el9.x86_64              1/6
  Running scriptlet: docker-compose-plugin-2.32.4-1.el9.x86_64              1/6
  Installing       : docker-buildx-plugin-0.20.0-1.el9.x86_64               2/6
  Running scriptlet: docker-buildx-plugin-0.20.0-1.el9.x86_64               2/6
  Installing       : docker-ce-cli-1:27.5.1-1.el9.x86_64                    3/6
  Running scriptlet: docker-ce-cli-1:27.5.1-1.el9.x86_64                    3/6
  Installing       : containerd.io-1.7.25-3.1.el9.x86_64                    4/6
  Running scriptlet: containerd.io-1.7.25-3.1.el9.x86_64                    4/6
  Installing       : docker-ce-rootless-extras-27.5.1-1.el9.x86_64          5/6
  Running scriptlet: docker-ce-rootless-extras-27.5.1-1.el9.x86_64          5/6
  Installing       : docker-ce-3:27.5.1-1.el9.x86_64                        6/6
  Running scriptlet: docker-ce-3:27.5.1-1.el9.x86_64                        6/6
  Verifying        : containerd.io-1.7.25-3.1.el9.x86_64                    1/6
  Verifying        : docker-buildx-plugin-0.20.0-1.el9.x86_64               2/6
  Verifying        : docker-ce-3:27.5.1-1.el9.x86_64                        3/6
  Verifying        : docker-ce-cli-1:27.5.1-1.el9.x86_64                    4/6
  Verifying        : docker-ce-rootless-extras-27.5.1-1.el9.x86_64          5/6
  Verifying        : docker-compose-plugin-2.32.4-1.el9.x86_64              6/6

Installed:
  containerd.io-1.7.25-3.1.el9.x86_64
  docker-buildx-plugin-0.20.0-1.el9.x86_64
  docker-ce-3:27.5.1-1.el9.x86_64
  docker-ce-cli-1:27.5.1-1.el9.x86_64
  docker-ce-rootless-extras-27.5.1-1.el9.x86_64
  docker-compose-plugin-2.32.4-1.el9.x86_64

Complete!
Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lb/systemd/system/docker.service.
Warning: Permanently added 'k8s-node2' (ED25519) to the list of known hosts.
Adding repo from: https://download.docker.com/linux/centos/docker-ce.repo
package docker-ce is not installed
Docker CE Stable - x86_64                       286 kB/s |  63 kB     00:00
Last metadata expiration check: 0:00:01 ago on Tue 04 Feb 2025 01:01:24 PM CST.
Dependencies resolved.
================================================================================
 Package                     Arch     Version          Repository          Size
================================================================================
Installing:
 docker-ce                   x86_64   3:27.5.1-1.el9   docker-ce-stable    27 M
Installing dependencies:
 containerd.io               x86_64   1.7.25-3.1.el9   docker-ce-stable    43 M
 docker-ce-cli               x86_64   1:27.5.1-1.el9   docker-ce-stable   8.1 M
Installing weak dependencies:
 docker-buildx-plugin        x86_64   0.20.0-1.el9     docker-ce-stable    15 M
 docker-ce-rootless-extras   x86_64   27.5.1-1.el9     docker-ce-stable   4.4 M
 docker-compose-plugin       x86_64   2.32.4-1.el9     docker-ce-stable    14 M

Transaction Summary
================================================================================
Install  6 Packages

Total download size: 111 M
Installed size: 440 M
Downloading Packages:
(1/6): docker-buildx-plugin-0.20.0-1.el9.x86_64 1.6 MB/s |  15 MB     00:09
(2/6): docker-ce-27.5.1-1.el9.x86_64.rpm        1.9 MB/s |  27 MB     00:14
(3/6): docker-ce-cli-27.5.1-1.el9.x86_64.rpm    1.0 MB/s | 8.1 MB     00:07
(4/6): docker-ce-rootless-extras-27.5.1-1.el9.x 1.4 MB/s | 4.4 MB     00:03
(5/6): docker-compose-plugin-2.32.4-1.el9.x86_6 2.0 MB/s |  14 MB     00:06
(6/6): containerd.io-1.7.25-3.1.el9.x86_64.rpm  1.7 MB/s |  43 MB     00:25
--------------------------------------------------------------------------------
Total                                           4.4 MB/s | 111 MB     00:25
Docker CE Stable - x86_64                       9.2 kB/s | 1.6 kB     00:00
Importing GPG key 0x621E9F35:
 Userid     : "Docker Release (CE rpm) <docker@docker.com>"
 Fingerprint: 060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35
 From       : https://download.docker.com/linux/centos/gpg
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                        1/1
  Installing       : docker-compose-plugin-2.32.4-1.el9.x86_64              1/6
  Running scriptlet: docker-compose-plugin-2.32.4-1.el9.x86_64              1/6
  Installing       : docker-buildx-plugin-0.20.0-1.el9.x86_64               2/6
  Running scriptlet: docker-buildx-plugin-0.20.0-1.el9.x86_64               2/6
  Installing       : docker-ce-cli-1:27.5.1-1.el9.x86_64                    3/6
  Running scriptlet: docker-ce-cli-1:27.5.1-1.el9.x86_64                    3/6
  Installing       : containerd.io-1.7.25-3.1.el9.x86_64                    4/6
  Running scriptlet: containerd.io-1.7.25-3.1.el9.x86_64                    4/6
  Installing       : docker-ce-rootless-extras-27.5.1-1.el9.x86_64          5/6
  Running scriptlet: docker-ce-rootless-extras-27.5.1-1.el9.x86_64          5/6
  Installing       : docker-ce-3:27.5.1-1.el9.x86_64                        6/6
  Running scriptlet: docker-ce-3:27.5.1-1.el9.x86_64                        6/6
  Verifying        : containerd.io-1.7.25-3.1.el9.x86_64                    1/6
  Verifying        : docker-buildx-plugin-0.20.0-1.el9.x86_64               2/6
  Verifying        : docker-ce-3:27.5.1-1.el9.x86_64                        3/6
  Verifying        : docker-ce-cli-1:27.5.1-1.el9.x86_64                    4/6
  Verifying        : docker-ce-rootless-extras-27.5.1-1.el9.x86_64          5/6
  Verifying        : docker-compose-plugin-2.32.4-1.el9.x86_64              6/6

Installed:
  containerd.io-1.7.25-3.1.el9.x86_64
  docker-buildx-plugin-0.20.0-1.el9.x86_64
  docker-ce-3:27.5.1-1.el9.x86_64
  docker-ce-cli-1:27.5.1-1.el9.x86_64
  docker-ce-rootless-extras-27.5.1-1.el9.x86_64
  docker-compose-plugin-2.32.4-1.el9.x86_64

Complete!
Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lb/systemd/system/docker.service.
Last metadata expiration check: 0:03:44 ago on Tue 04 Feb 2025 12:58:50 PM CST.
Package bash-completion-1:2.11-5.el9.noarch is already installed.
Dependencies resolved.
Nothing to do.
Complete!

完整安裝(full)，檢查指令補齊(TAB)功能

Last metadata expiration check: 0:02:37 ago on Tue 04 Feb 2025 01:00:01 PM CST.
Package bash-completion-1:2.11-5.el9.noarch is already installed.
Dependencies resolved.
Nothing to do.
Complete!
Last metadata expiration check: 0:01:16 ago on Tue 04 Feb 2025 01:01:24 PM CST.
Package bash-completion-1:2.11-5.el9.noarch is already installed.
Dependencies resolved.
Nothing to do.
Complete!
               total        used        free      shared  buff/cache   available
Mem:            3626         993        1745          15        1139        2633
Swap:           4011           0        4011
               total        used        free      shared  buff/cache   available
Mem:            3626         991        1748          15        1138        2634
Swap:              0           0           0

#
# /etc/fstab
# Created by anaconda on Mon Dec 30 03:09:13 2024
#
# Accessible filesystems, by reference, are maintained under '/dev/disk/'.
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info.
#
# After editing this file, run 'systemctl daemon-reload' to update systemd
# units generated from this file.
#
/dev/mapper/rl-root     /                       xfs     defaults        0 0
UUID=253f75a6-e58f-41cc-8e6c-3eec510264d6 /boot                   xfs     defaults       0 0
/dev/mapper/rl-home     /home                   xfs     defaults        0 0
#/dev/mapper/rl-swap     none                    swap    defaults        0 0

完整安裝(full)，swap

               total        used        free      shared  buff/cache   available
Mem:            3626         969        1865          15        1060        2656
Swap:              0           0           0
               total        used        free      shared  buff/cache   available
Mem:            3626        1416         274          21        2190        2209
Swap:              0           0           0
* Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...
* Applying /usr/lib/sysctl.d/50-coredump.conf ...
* Applying /usr/lib/sysctl.d/50-default.conf ...
* Applying /usr/lib/sysctl.d/50-libkcapi-optmem_max.conf ...
* Applying /usr/lib/sysctl.d/50-pid-max.conf ...
* Applying /usr/lib/sysctl.d/50-redhat.conf ...
* Applying /etc/sysctl.d/99-sysctl.conf ...
* Applying /etc/sysctl.d/k8s.conf ...
* Applying /etc/sysctl.conf ...
kernel.yama.ptrace_scope = 0
kernel.core_pattern = |/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h
kernel.core_pipe_limit = 16
fs.suid_dumpable = 2
kernel.sysrq = 16
kernel.core_uses_pid = 1
net.ipv4.conf.default.rp_filter = 2
net.ipv4.conf.docker0.rp_filter = 2
net.ipv4.conf.ens160.rp_filter = 2
net.ipv4.conf.lo.rp_filter = 2
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.docker0.accept_source_route = 0
net.ipv4.conf.ens160.accept_source_route = 0
net.ipv4.conf.lo.accept_source_route = 0
net.ipv4.conf.default.promote_secondaries = 1
net.ipv4.conf.docker0.promote_secondaries = 1
net.ipv4.conf.ens160.promote_secondaries = 1
net.ipv4.conf.lo.promote_secondaries = 1
net.ipv4.ping_group_range = 0 2147483647
net.core.default_qdisc = fq_codel
fs.protected_hardlinks = 1
fs.protected_symlinks = 1
fs.protected_regular = 1
fs.protected_fifos = 1
net.core.optmem_max = 81920
kernel.pid_max = 4194304
kernel.kptr_restrict = 1
net.ipv4.conf.default.rp_filter = 1
net.ipv4.conf.docker0.rp_filter = 1
net.ipv4.conf.ens160.rp_filter = 1
net.ipv4.conf.lo.rp_filter = 1
net.ipv4.ip_forward = 1
Last metadata expiration check: 0:03:55 ago on Tue 04 Feb 2025 12:58:50 PM CST.
Package curl-7.76.1-31.el9.x86_64 is already installed.
Dependencies resolved.
===================================================================================
 Package                     Arch        Version               Repository      Size
===================================================================================
Installing:
 conntrack-tools             x86_64      1.4.7-2.el9           appstream      221 k
 ipvsadm                     x86_64      1.31-6.el9            appstream       50 k
 sysstat                     x86_64      12.5.4-9.el9          appstream      465 k
Installing dependencies:
 libnetfilter_cthelper       x86_64      1.0.0-22.el9          appstream       23 k
 libnetfilter_cttimeout      x86_64      1.0.0-19.el9          appstream       23 k
 libnetfilter_queue          x86_64      1.0.5-1.el9           appstream       28 k
 lm_sensors-libs             x86_64      3.6.0-10.el9          appstream       41 k
 pcp-conf                    x86_64      6.2.2-7.el9_5         appstream       29 k
 pcp-libs                    x86_64      6.2.2-7.el9_5         appstream      638 k

Transaction Summary
===================================================================================
Install  9 Packages

Total download size: 1.5 M
Installed size: 4.1 M
Downloading Packages:
(1/9): lm_sensors-libs-3.6.0-10.el9.x86_64.rpm      159 kB/s |  41 kB     00:00
(2/9): libnetfilter_cttimeout-1.0.0-19.el9.x86_64.r  76 kB/s |  23 kB     00:00
(3/9): conntrack-tools-1.4.7-2.el9.x86_64.rpm       348 kB/s | 221 kB     00:00
(4/9): ipvsadm-1.31-6.el9.x86_64.rpm                129 kB/s |  50 kB     00:00
(5/9): libnetfilter_queue-1.0.5-1.el9.x86_64.rpm     84 kB/s |  28 kB     00:00
(6/9): libnetfilter_cthelper-1.0.0-22.el9.x86_64.rp  65 kB/s |  23 kB     00:00
(7/9): sysstat-12.5.4-9.el9.x86_64.rpm              608 kB/s | 465 kB     00:00
(8/9): pcp-conf-6.2.2-7.el9_5.x86_64.rpm             77 kB/s |  29 kB     00:00
(9/9): pcp-libs-6.2.2-7.el9_5.x86_64.rpm            866 kB/s | 638 kB     00:00
-----------------------------------------------------------------------------------
Total                                               634 kB/s | 1.5 MB     00:02
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                            1/1
  Installing       : pcp-conf-6.2.2-7.el9_5.x86_64                              1/9
  Installing       : pcp-libs-6.2.2-7.el9_5.x86_64                              2/9
  Installing       : libnetfilter_queue-1.0.5-1.el9.x86_64                      3/9
  Installing       : libnetfilter_cthelper-1.0.0-22.el9.x86_64                  4/9
  Installing       : lm_sensors-libs-3.6.0-10.el9.x86_64                        5/9
  Installing       : libnetfilter_cttimeout-1.0.0-19.el9.x86_64                 6/9
  Installing       : conntrack-tools-1.4.7-2.el9.x86_64                         7/9
  Running scriptlet: conntrack-tools-1.4.7-2.el9.x86_64                         7/9
  Installing       : sysstat-12.5.4-9.el9.x86_64                                8/9
  Running scriptlet: sysstat-12.5.4-9.el9.x86_64                                8/9
Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /usr/ib/systemd/system/sysstat.service.
Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /sr/lib/systemd/system/sysstat-collect.timer.
Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /sr/lib/systemd/system/sysstat-summary.timer.

  Installing       : ipvsadm-1.31-6.el9.x86_64                                  9/9
  Running scriptlet: ipvsadm-1.31-6.el9.x86_64                                  9/9
  Verifying        : conntrack-tools-1.4.7-2.el9.x86_64                         1/9
  Verifying        : libnetfilter_cttimeout-1.0.0-19.el9.x86_64                 2/9
  Verifying        : lm_sensors-libs-3.6.0-10.el9.x86_64                        3/9
  Verifying        : ipvsadm-1.31-6.el9.x86_64                                  4/9
  Verifying        : sysstat-12.5.4-9.el9.x86_64                                5/9
  Verifying        : libnetfilter_cthelper-1.0.0-22.el9.x86_64                  6/9
  Verifying        : libnetfilter_queue-1.0.5-1.el9.x86_64                      7/9
  Verifying        : pcp-libs-6.2.2-7.el9_5.x86_64                              8/9
  Verifying        : pcp-conf-6.2.2-7.el9_5.x86_64                              9/9

Installed:
  conntrack-tools-1.4.7-2.el9.x86_64
  ipvsadm-1.31-6.el9.x86_64
  libnetfilter_cthelper-1.0.0-22.el9.x86_64
  libnetfilter_cttimeout-1.0.0-19.el9.x86_64
  libnetfilter_queue-1.0.5-1.el9.x86_64
  lm_sensors-libs-3.6.0-10.el9.x86_64
  pcp-conf-6.2.2-7.el9_5.x86_64
  pcp-libs-6.2.2-7.el9_5.x86_64
  sysstat-12.5.4-9.el9.x86_64

Complete!

完整安裝(full)，kerenl 參數

* Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...
* Applying /usr/lib/sysctl.d/50-coredump.conf ...
* Applying /usr/lib/sysctl.d/50-default.conf ...
* Applying /usr/lib/sysctl.d/50-libkcapi-optmem_max.conf ...
* Applying /usr/lib/sysctl.d/50-pid-max.conf ...
* Applying /usr/lib/sysctl.d/50-redhat.conf ...
* Applying /etc/sysctl.d/99-sysctl.conf ...
* Applying /etc/sysctl.d/k8s.conf ...
* Applying /etc/sysctl.conf ...
kernel.yama.ptrace_scope = 0
kernel.core_pattern = |/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h
kernel.core_pipe_limit = 16
fs.suid_dumpable = 2
kernel.sysrq = 16
kernel.core_uses_pid = 1
net.ipv4.conf.default.rp_filter = 2
net.ipv4.conf.docker0.rp_filter = 2
net.ipv4.conf.ens160.rp_filter = 2
net.ipv4.conf.lo.rp_filter = 2
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.docker0.accept_source_route = 0
net.ipv4.conf.ens160.accept_source_route = 0
net.ipv4.conf.lo.accept_source_route = 0
net.ipv4.conf.default.promote_secondaries = 1
net.ipv4.conf.docker0.promote_secondaries = 1
net.ipv4.conf.ens160.promote_secondaries = 1
net.ipv4.conf.lo.promote_secondaries = 1
net.ipv4.ping_group_range = 0 2147483647
net.core.default_qdisc = fq_codel
fs.protected_hardlinks = 1
fs.protected_symlinks = 1
fs.protected_regular = 1
fs.protected_fifos = 1
net.core.optmem_max = 81920
kernel.pid_max = 4194304
kernel.kptr_restrict = 1
net.ipv4.conf.default.rp_filter = 1
net.ipv4.conf.docker0.rp_filter = 1
net.ipv4.conf.ens160.rp_filter = 1
net.ipv4.conf.lo.rp_filter = 1
net.ipv4.ip_forward = 1
Last metadata expiration check: 0:03:00 ago on Tue 04 Feb 2025 01:00:01 PM CST.
Package curl-7.76.1-31.el9.x86_64 is already installed.
Dependencies resolved.
================================================================================
 Package                    Arch       Version              Repository     Size
================================================================================
Installing:
 conntrack-tools            x86_64     1.4.7-2.el9          appstream     221 k
 ipvsadm                    x86_64     1.31-6.el9           appstream      50 k
 sysstat                    x86_64     12.5.4-9.el9         appstream     465 k
Installing dependencies:
 libnetfilter_cthelper      x86_64     1.0.0-22.el9         appstream      23 k
 libnetfilter_cttimeout     x86_64     1.0.0-19.el9         appstream      23 k
 libnetfilter_queue         x86_64     1.0.5-1.el9          appstream      28 k
 lm_sensors-libs            x86_64     3.6.0-10.el9         appstream      41 k
 pcp-conf                   x86_64     6.2.2-7.el9_5        appstream      29 k
 pcp-libs                   x86_64     6.2.2-7.el9_5        appstream     638 k

Transaction Summary
================================================================================
Install  9 Packages

Total download size: 1.5 M
Installed size: 4.1 M
Downloading Packages:
(1/9): libnetfilter_cttimeout-1.0.0-19.el9.x86_ 171 kB/s |  23 kB     00:00
(2/9): lm_sensors-libs-3.6.0-10.el9.x86_64.rpm  292 kB/s |  41 kB     00:00
(3/9): conntrack-tools-1.4.7-2.el9.x86_64.rpm   731 kB/s | 221 kB     00:00
(4/9): ipvsadm-1.31-6.el9.x86_64.rpm            284 kB/s |  50 kB     00:00
(5/9): libnetfilter_cthelper-1.0.0-22.el9.x86_6  34 kB/s |  23 kB     00:00
(6/9): libnetfilter_queue-1.0.5-1.el9.x86_64.rp  42 kB/s |  28 kB     00:00
(7/9): sysstat-12.5.4-9.el9.x86_64.rpm          477 kB/s | 465 kB     00:00
(8/9): pcp-conf-6.2.2-7.el9_5.x86_64.rpm         59 kB/s |  29 kB     00:00
(9/9): pcp-libs-6.2.2-7.el9_5.x86_64.rpm        939 kB/s | 638 kB     00:00
--------------------------------------------------------------------------------
Total                                           644 kB/s | 1.5 MB     00:02
Rocky Linux 9 - AppStream                       205 kB/s | 1.7 kB     00:00
Importing GPG key 0x350D275D:
 Userid     : "Rocky Enterprise Software Foundation - Release key 2022 <releng@rocklinux.org>"
 Fingerprint: 21CB 256A E16F C54C 6E65 2949 702D 426D 350D 275D
 From       : /etc/pki/rpm-gpg/RPM-GPG-KEY-Rocky-9
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                        1/1
  Installing       : pcp-conf-6.2.2-7.el9_5.x86_64                          1/9
  Installing       : pcp-libs-6.2.2-7.el9_5.x86_64                          2/9
  Installing       : libnetfilter_queue-1.0.5-1.el9.x86_64                  3/9
  Installing       : libnetfilter_cthelper-1.0.0-22.el9.x86_64              4/9
  Installing       : lm_sensors-libs-3.6.0-10.el9.x86_64                    5/9
  Installing       : libnetfilter_cttimeout-1.0.0-19.el9.x86_64             6/9
  Installing       : conntrack-tools-1.4.7-2.el9.x86_64                     7/9
  Running scriptlet: conntrack-tools-1.4.7-2.el9.x86_64                     7/9
  Installing       : sysstat-12.5.4-9.el9.x86_64                            8/9
  Running scriptlet: sysstat-12.5.4-9.el9.x86_64                            8/9
Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /usr/ib/systemd/system/sysstat.service.
Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /sr/lib/systemd/system/sysstat-collect.timer.
Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /sr/lib/systemd/system/sysstat-summary.timer.

  Installing       : ipvsadm-1.31-6.el9.x86_64                              9/9
  Running scriptlet: ipvsadm-1.31-6.el9.x86_64                              9/9
  Verifying        : conntrack-tools-1.4.7-2.el9.x86_64                     1/9
  Verifying        : libnetfilter_cttimeout-1.0.0-19.el9.x86_64             2/9
  Verifying        : lm_sensors-libs-3.6.0-10.el9.x86_64                    3/9
  Verifying        : ipvsadm-1.31-6.el9.x86_64                              4/9
  Verifying        : sysstat-12.5.4-9.el9.x86_64                            5/9
  Verifying        : libnetfilter_cthelper-1.0.0-22.el9.x86_64              6/9
  Verifying        : libnetfilter_queue-1.0.5-1.el9.x86_64                  7/9
  Verifying        : pcp-libs-6.2.2-7.el9_5.x86_64                          8/9
  Verifying        : pcp-conf-6.2.2-7.el9_5.x86_64                          9/9

Installed:
  conntrack-tools-1.4.7-2.el9.x86_64
  ipvsadm-1.31-6.el9.x86_64
  libnetfilter_cthelper-1.0.0-22.el9.x86_64
  libnetfilter_cttimeout-1.0.0-19.el9.x86_64
  libnetfilter_queue-1.0.5-1.el9.x86_64
  lm_sensors-libs-3.6.0-10.el9.x86_64
  pcp-conf-6.2.2-7.el9_5.x86_64
  pcp-libs-6.2.2-7.el9_5.x86_64
  sysstat-12.5.4-9.el9.x86_64

Complete!
* Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...
* Applying /usr/lib/sysctl.d/50-coredump.conf ...
* Applying /usr/lib/sysctl.d/50-default.conf ...
* Applying /usr/lib/sysctl.d/50-libkcapi-optmem_max.conf ...
* Applying /usr/lib/sysctl.d/50-pid-max.conf ...
* Applying /usr/lib/sysctl.d/50-redhat.conf ...
* Applying /etc/sysctl.d/99-sysctl.conf ...
* Applying /etc/sysctl.d/k8s.conf ...
* Applying /etc/sysctl.conf ...
kernel.yama.ptrace_scope = 0
kernel.core_pattern = |/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h
kernel.core_pipe_limit = 16
fs.suid_dumpable = 2
kernel.sysrq = 16
kernel.core_uses_pid = 1
net.ipv4.conf.default.rp_filter = 2
net.ipv4.conf.docker0.rp_filter = 2
net.ipv4.conf.ens160.rp_filter = 2
net.ipv4.conf.lo.rp_filter = 2
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.docker0.accept_source_route = 0
net.ipv4.conf.ens160.accept_source_route = 0
net.ipv4.conf.lo.accept_source_route = 0
net.ipv4.conf.default.promote_secondaries = 1
net.ipv4.conf.docker0.promote_secondaries = 1
net.ipv4.conf.ens160.promote_secondaries = 1
net.ipv4.conf.lo.promote_secondaries = 1
net.ipv4.ping_group_range = 0 2147483647
net.core.default_qdisc = fq_codel
fs.protected_hardlinks = 1
fs.protected_symlinks = 1
fs.protected_regular = 1
fs.protected_fifos = 1
net.core.optmem_max = 81920
kernel.pid_max = 4194304
kernel.kptr_restrict = 1
net.ipv4.conf.default.rp_filter = 1
net.ipv4.conf.docker0.rp_filter = 1
net.ipv4.conf.ens160.rp_filter = 1
net.ipv4.conf.lo.rp_filter = 1
net.ipv4.ip_forward = 1
Last metadata expiration check: 0:01:53 ago on Tue 04 Feb 2025 01:01:24 PM CST.
Package curl-7.76.1-31.el9.x86_64 is already installed.
Dependencies resolved.
================================================================================
 Package                    Arch       Version              Repository     Size
================================================================================
Installing:
 conntrack-tools            x86_64     1.4.7-2.el9          appstream     221 k
 ipvsadm                    x86_64     1.31-6.el9           appstream      50 k
 sysstat                    x86_64     12.5.4-9.el9         appstream     465 k
Installing dependencies:
 libnetfilter_cthelper      x86_64     1.0.0-22.el9         appstream      23 k
 libnetfilter_cttimeout     x86_64     1.0.0-19.el9         appstream      23 k
 libnetfilter_queue         x86_64     1.0.5-1.el9          appstream      28 k
 lm_sensors-libs            x86_64     3.6.0-10.el9         appstream      41 k
 pcp-conf                   x86_64     6.2.2-7.el9_5        appstream      29 k
 pcp-libs                   x86_64     6.2.2-7.el9_5        appstream     638 k

Transaction Summary
================================================================================
Install  9 Packages

Total download size: 1.5 M
Installed size: 4.1 M
Downloading Packages:
(1/9): libnetfilter_cttimeout-1.0.0-19.el9.x86_ 200 kB/s |  23 kB     00:00
(2/9): lm_sensors-libs-3.6.0-10.el9.x86_64.rpm  349 kB/s |  41 kB     00:00
(3/9): conntrack-tools-1.4.7-2.el9.x86_64.rpm   1.3 MB/s | 221 kB     00:00
(4/9): ipvsadm-1.31-6.el9.x86_64.rpm            234 kB/s |  50 kB     00:00
(5/9): libnetfilter_cthelper-1.0.0-22.el9.x86_6 141 kB/s |  23 kB     00:00
(6/9): libnetfilter_queue-1.0.5-1.el9.x86_64.rp 710 kB/s |  28 kB     00:00
(7/9): pcp-conf-6.2.2-7.el9_5.x86_64.rpm        540 kB/s |  29 kB     00:00
(8/9): sysstat-12.5.4-9.el9.x86_64.rpm          972 kB/s | 465 kB     00:00
(9/9): pcp-libs-6.2.2-7.el9_5.x86_64.rpm        680 kB/s | 638 kB     00:00
--------------------------------------------------------------------------------
Total                                           754 kB/s | 1.5 MB     00:02
Rocky Linux 9 - AppStream                       1.7 MB/s | 1.7 kB     00:00
Importing GPG key 0x350D275D:
 Userid     : "Rocky Enterprise Software Foundation - Release key 2022 <releng@rocklinux.org>"
 Fingerprint: 21CB 256A E16F C54C 6E65 2949 702D 426D 350D 275D
 From       : /etc/pki/rpm-gpg/RPM-GPG-KEY-Rocky-9
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                        1/1
  Installing       : pcp-conf-6.2.2-7.el9_5.x86_64                          1/9
  Installing       : pcp-libs-6.2.2-7.el9_5.x86_64                          2/9
  Installing       : libnetfilter_queue-1.0.5-1.el9.x86_64                  3/9
  Installing       : libnetfilter_cthelper-1.0.0-22.el9.x86_64              4/9
  Installing       : lm_sensors-libs-3.6.0-10.el9.x86_64                    5/9
  Installing       : libnetfilter_cttimeout-1.0.0-19.el9.x86_64             6/9
  Installing       : conntrack-tools-1.4.7-2.el9.x86_64                     7/9
  Running scriptlet: conntrack-tools-1.4.7-2.el9.x86_64                     7/9
  Installing       : sysstat-12.5.4-9.el9.x86_64                            8/9
  Running scriptlet: sysstat-12.5.4-9.el9.x86_64                            8/9
Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /usr/ib/systemd/system/sysstat.service.
Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /sr/lib/systemd/system/sysstat-collect.timer.
Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /sr/lib/systemd/system/sysstat-summary.timer.

  Installing       : ipvsadm-1.31-6.el9.x86_64                              9/9
  Running scriptlet: ipvsadm-1.31-6.el9.x86_64                              9/9
  Verifying        : conntrack-tools-1.4.7-2.el9.x86_64                     1/9
  Verifying        : libnetfilter_cttimeout-1.0.0-19.el9.x86_64             2/9
  Verifying        : lm_sensors-libs-3.6.0-10.el9.x86_64                    3/9
  Verifying        : ipvsadm-1.31-6.el9.x86_64                              4/9
  Verifying        : sysstat-12.5.4-9.el9.x86_64                            5/9
  Verifying        : libnetfilter_cthelper-1.0.0-22.el9.x86_64              6/9
  Verifying        : libnetfilter_queue-1.0.5-1.el9.x86_64                  7/9
  Verifying        : pcp-libs-6.2.2-7.el9_5.x86_64                          8/9
  Verifying        : pcp-conf-6.2.2-7.el9_5.x86_64                          9/9

Installed:
  conntrack-tools-1.4.7-2.el9.x86_64
  ipvsadm-1.31-6.el9.x86_64
  libnetfilter_cthelper-1.0.0-22.el9.x86_64
  libnetfilter_cttimeout-1.0.0-19.el9.x86_64
  libnetfilter_queue-1.0.5-1.el9.x86_64
  lm_sensors-libs-3.6.0-10.el9.x86_64
  pcp-conf-6.2.2-7.el9_5.x86_64
  pcp-libs-6.2.2-7.el9_5.x86_64
  sysstat-12.5.4-9.el9.x86_64

Complete!
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/repodata/repomd.xml.key
32 files removed
Docker CE Stable - x86_64                           223 kB/s |  63 kB     00:00
Kubernetes                                          9.6 kB/s | 7.8 kB     00:00
Rocky Linux 9 - BaseOS                              976 kB/s | 3.4 MB     00:03
Rocky Linux 9 - AppStream                           1.6 MB/s | 9.1 MB     00:05
Rocky Linux 9 - Extras                               16 kB/s |  16 kB     00:00
Dependencies resolved.
===================================================================================
 Package              Architecture Version                   Repository        Size
===================================================================================
Installing:
 kubeadm              x86_64       1.32.1-150500.1.1         kubernetes        12 M
 kubectl              x86_64       1.32.1-150500.1.1         kubernetes        11 M
 kubelet              x86_64       1.32.1-150500.1.1         kubernetes        15 M
Installing dependencies:
 cri-tools            x86_64       1.32.0-150500.1.1         kubernetes       7.1 M
 kubernetes-cni       x86_64       1.6.0-150500.1.1          kubernetes       8.0 M

Transaction Summary
===================================================================================
Install  5 Packages

Total download size: 52 M
Installed size: 288 M
Downloading Packages:
(1/5): cri-tools-1.32.0-150500.1.1.x86_64.rpm       1.1 MB/s | 7.1 MB     00:06
(2/5): kubeadm-1.32.1-150500.1.1.x86_64.rpm         1.6 MB/s |  12 MB     00:07
(3/5): kubectl-1.32.1-150500.1.1.x86_64.rpm         1.1 MB/s |  11 MB     00:09
(4/5): kubernetes-cni-1.6.0-150500.1.1.x86_64.rpm   1.4 MB/s | 8.0 MB     00:05
(5/5): kubelet-1.32.1-150500.1.1.x86_64.rpm         1.7 MB/s |  15 MB     00:08
-----------------------------------------------------------------------------------
Total                                               3.5 MB/s |  52 MB     00:15
Kubernetes                                          4.8 kB/s | 1.7 kB     00:00
Importing GPG key 0x9A296436:
 Userid     : "isv:kubernetes OBS Project <isv:kubernetes@build.opensuse.org>"
 Fingerprint: DE15 B144 86CD 377B 9E87 6E1A 2346 54DA 9A29 6436
 From       : https://pkgs.k8s.io/core:/stable:/v1.32/rpm/repodata/repomd.xml.key
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                            1/1
  Installing       : kubernetes-cni-1.6.0-150500.1.1.x86_64                     1/5
  Installing       : cri-tools-1.32.0-150500.1.1.x86_64                         2/5
  Installing       : kubeadm-1.32.1-150500.1.1.x86_64                           3/5
  Installing       : kubelet-1.32.1-150500.1.1.x86_64                           4/5
  Running scriptlet: kubelet-1.32.1-150500.1.1.x86_64                           4/5
  Installing       : kubectl-1.32.1-150500.1.1.x86_64                           5/5
  Running scriptlet: kubectl-1.32.1-150500.1.1.x86_64                           5/5
  Verifying        : cri-tools-1.32.0-150500.1.1.x86_64                         1/5
  Verifying        : kubeadm-1.32.1-150500.1.1.x86_64                           2/5
  Verifying        : kubectl-1.32.1-150500.1.1.x86_64                           3/5
  Verifying        : kubelet-1.32.1-150500.1.1.x86_64                           4/5
  Verifying        : kubernetes-cni-1.6.0-150500.1.1.x86_64                     5/5

Installed:
  cri-tools-1.32.0-150500.1.1.x86_64          kubeadm-1.32.1-150500.1.1.x86_64
  kubectl-1.32.1-150500.1.1.x86_64            kubelet-1.32.1-150500.1.1.x86_64
  kubernetes-cni-1.6.0-150500.1.1.x86_64

Complete!
Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /usr/ib/systemd/system/kubelet.service.

完整安裝(full)，安裝 k8s RPM 套件

Kubernetes                                      7.0 kB/s | 7.8 kB     00:01
Last metadata expiration check: 0:00:01 ago on Tue 04 Feb 2025 01:04:44 PM CST.
Dependencies resolved.
================================================================================
 Package             Arch        Version                  Repository       Size
================================================================================
Installing:
 kubeadm             x86_64      1.32.1-150500.1.1        kubernetes       12 M
 kubectl             x86_64      1.32.1-150500.1.1        kubernetes       11 M
 kubelet             x86_64      1.32.1-150500.1.1        kubernetes       15 M
Installing dependencies:
 cri-tools           x86_64      1.32.0-150500.1.1        kubernetes      7.1 M
 kubernetes-cni      x86_64      1.6.0-150500.1.1         kubernetes      8.0 M

Transaction Summary
================================================================================
Install  5 Packages

Total download size: 52 M
Installed size: 288 M
Downloading Packages:
(1/5): cri-tools-1.32.0-150500.1.1.x86_64.rpm   1.3 MB/s | 7.1 MB     00:05
(2/5): kubectl-1.32.1-150500.1.1.x86_64.rpm     1.7 MB/s |  11 MB     00:06
(3/5): kubeadm-1.32.1-150500.1.1.x86_64.rpm     1.2 MB/s |  12 MB     00:09
(4/5): kubernetes-cni-1.6.0-150500.1.1.x86_64.r 1.5 MB/s | 8.0 MB     00:05
(5/5): kubelet-1.32.1-150500.1.1.x86_64.rpm     2.0 MB/s |  15 MB     00:07
--------------------------------------------------------------------------------
Total                                           4.1 MB/s |  52 MB     00:12
Kubernetes                                      3.9 kB/s | 1.7 kB     00:00
Importing GPG key 0x9A296436:
 Userid     : "isv:kubernetes OBS Project <isv:kubernetes@build.opensuse.org>"
 Fingerprint: DE15 B144 86CD 377B 9E87 6E1A 2346 54DA 9A29 6436
 From       : https://pkgs.k8s.io/core:/stable:/v1.32/rpm/repodata/repomd.xml.key
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                        1/1
  Installing       : kubernetes-cni-1.6.0-150500.1.1.x86_64                 1/5
  Installing       : cri-tools-1.32.0-150500.1.1.x86_64                     2/5
  Installing       : kubeadm-1.32.1-150500.1.1.x86_64                       3/5
  Installing       : kubelet-1.32.1-150500.1.1.x86_64                       4/5
  Running scriptlet: kubelet-1.32.1-150500.1.1.x86_64                       4/5
  Installing       : kubectl-1.32.1-150500.1.1.x86_64                       5/5
  Running scriptlet: kubectl-1.32.1-150500.1.1.x86_64                       5/5
  Verifying        : cri-tools-1.32.0-150500.1.1.x86_64                     1/5
  Verifying        : kubeadm-1.32.1-150500.1.1.x86_64                       2/5
  Verifying        : kubectl-1.32.1-150500.1.1.x86_64                       3/5
  Verifying        : kubelet-1.32.1-150500.1.1.x86_64                       4/5
  Verifying        : kubernetes-cni-1.6.0-150500.1.1.x86_64                 5/5

Installed:
  cri-tools-1.32.0-150500.1.1.x86_64        kubeadm-1.32.1-150500.1.1.x86_64
  kubectl-1.32.1-150500.1.1.x86_64          kubelet-1.32.1-150500.1.1.x86_64
  kubernetes-cni-1.6.0-150500.1.1.x86_64

Complete!
Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /usr/ib/systemd/system/kubelet.service.
Kubernetes                                       11 kB/s | 7.8 kB     00:00
Dependencies resolved.
================================================================================
 Package             Arch        Version                  Repository       Size
================================================================================
Installing:
 kubeadm             x86_64      1.32.1-150500.1.1        kubernetes       12 M
 kubectl             x86_64      1.32.1-150500.1.1        kubernetes       11 M
 kubelet             x86_64      1.32.1-150500.1.1        kubernetes       15 M
Installing dependencies:
 cri-tools           x86_64      1.32.0-150500.1.1        kubernetes      7.1 M
 kubernetes-cni      x86_64      1.6.0-150500.1.1         kubernetes      8.0 M

Transaction Summary
================================================================================
Install  5 Packages

Total download size: 52 M
Installed size: 288 M
Downloading Packages:
(1/5): cri-tools-1.32.0-150500.1.1.x86_64.rpm   1.6 MB/s | 7.1 MB     00:04
(2/5): kubectl-1.32.1-150500.1.1.x86_64.rpm     1.5 MB/s |  11 MB     00:07
(3/5): kubeadm-1.32.1-150500.1.1.x86_64.rpm     1.5 MB/s |  12 MB     00:07
(4/5): kubernetes-cni-1.6.0-150500.1.1.x86_64.r 2.3 MB/s | 8.0 MB     00:03
(5/5): kubelet-1.32.1-150500.1.1.x86_64.rpm     1.7 MB/s |  15 MB     00:08
--------------------------------------------------------------------------------
Total                                           4.0 MB/s |  52 MB     00:13
Kubernetes                                      5.8 kB/s | 1.7 kB     00:00
Importing GPG key 0x9A296436:
 Userid     : "isv:kubernetes OBS Project <isv:kubernetes@build.opensuse.org>"
 Fingerprint: DE15 B144 86CD 377B 9E87 6E1A 2346 54DA 9A29 6436
 From       : https://pkgs.k8s.io/core:/stable:/v1.32/rpm/repodata/repomd.xml.key
Key imported successfully
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                        1/1
  Installing       : kubernetes-cni-1.6.0-150500.1.1.x86_64                 1/5
  Installing       : cri-tools-1.32.0-150500.1.1.x86_64                     2/5
  Installing       : kubeadm-1.32.1-150500.1.1.x86_64                       3/5
  Installing       : kubelet-1.32.1-150500.1.1.x86_64                       4/5
  Running scriptlet: kubelet-1.32.1-150500.1.1.x86_64                       4/5
  Installing       : kubectl-1.32.1-150500.1.1.x86_64                       5/5
  Running scriptlet: kubectl-1.32.1-150500.1.1.x86_64                       5/5
  Verifying        : cri-tools-1.32.0-150500.1.1.x86_64                     1/5
  Verifying        : kubeadm-1.32.1-150500.1.1.x86_64                       2/5
  Verifying        : kubectl-1.32.1-150500.1.1.x86_64                       3/5
  Verifying        : kubelet-1.32.1-150500.1.1.x86_64                       4/5
  Verifying        : kubernetes-cni-1.6.0-150500.1.1.x86_64                 5/5

Installed:
  cri-tools-1.32.0-150500.1.1.x86_64        kubeadm-1.32.1-150500.1.1.x86_64
  kubectl-1.32.1-150500.1.1.x86_64          kubelet-1.32.1-150500.1.1.x86_64
  kubernetes-cni-1.6.0-150500.1.1.x86_64

Complete!
Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /usr/ib/systemd/system/kubelet.service.
[cri-o]
name=CRI-O
baseurl=https://pkgs.k8s.io/addons:/cri-o:/stable:/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/addons:/cri-o:/stable:/v1.32/rpm/repodata/repomd.xml.key
CRI-O                                               4.4 kB/s | 3.2 kB     00:00
Package cri-tools-1.32.0-150500.1.1.x86_64 is already installed.
Dependencies resolved.
===================================================================================
 Package         Architecture     Version                     Repository       Size
===================================================================================
Installing:
 cri-o           x86_64           1.32.1-150500.1.1           cri-o            20 M

Transaction Summary
===================================================================================
Install  1 Package

Total download size: 20 M
Installed size: 76 M
Downloading Packages:
cri-o-1.32.1-150500.1.1.x86_64.rpm                  3.3 MB/s |  20 MB     00:06
-----------------------------------------------------------------------------------
Total                                               3.3 MB/s |  20 MB     00:06
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                            1/1
  Installing       : cri-o-1.32.1-150500.1.1.x86_64                             1/1
  Running scriptlet: cri-o-1.32.1-150500.1.1.x86_64                             1/1
  Verifying        : cri-o-1.32.1-150500.1.1.x86_64                             1/1

Installed:
  cri-o-1.32.1-150500.1.1.x86_64

Complete!
Created symlink /etc/systemd/system/cri-o.service → /usr/lib/systemd/system/crio.sevice.
Created symlink /etc/systemd/system/multi-user.target.wants/crio.service → /usr/libsystemd/system/crio.service.

完整安裝(full)，cri-o

CRI-O                                           4.2 kB/s | 3.2 kB     00:00
Package cri-tools-1.32.0-150500.1.1.x86_64 is already installed.
Dependencies resolved.
================================================================================
 Package        Architecture    Version                    Repository      Size
================================================================================
Installing:
 cri-o          x86_64          1.32.1-150500.1.1          cri-o           20 M

Transaction Summary
================================================================================
Install  1 Package

Total download size: 20 M
Installed size: 76 M
Downloading Packages:
cri-o-1.32.1-150500.1.1.x86_64.rpm              4.8 MB/s |  20 MB     00:04
--------------------------------------------------------------------------------
Total                                           4.8 MB/s |  20 MB     00:04
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                        1/1
  Installing       : cri-o-1.32.1-150500.1.1.x86_64                         1/1
  Running scriptlet: cri-o-1.32.1-150500.1.1.x86_64                         1/1
  Verifying        : cri-o-1.32.1-150500.1.1.x86_64                         1/1

Installed:
  cri-o-1.32.1-150500.1.1.x86_64

Complete!
Created symlink /etc/systemd/system/cri-o.service → /usr/lib/systemd/system/crio.sevice.
Created symlink /etc/systemd/system/multi-user.target.wants/crio.service → /usr/libsystemd/system/crio.service.
CRI-O                                           4.2 kB/s | 3.2 kB     00:00
Package cri-tools-1.32.0-150500.1.1.x86_64 is already installed.
Dependencies resolved.
================================================================================
 Package        Architecture    Version                    Repository      Size
================================================================================
Installing:
 cri-o          x86_64          1.32.1-150500.1.1          cri-o           20 M

Transaction Summary
================================================================================
Install  1 Package

Total download size: 20 M
Installed size: 76 M
Downloading Packages:
cri-o-1.32.1-150500.1.1.x86_64.rpm              4.4 MB/s |  20 MB     00:04
--------------------------------------------------------------------------------
Total                                           4.4 MB/s |  20 MB     00:04
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                        1/1
  Installing       : cri-o-1.32.1-150500.1.1.x86_64                         1/1
  Running scriptlet: cri-o-1.32.1-150500.1.1.x86_64                         1/1
  Verifying        : cri-o-1.32.1-150500.1.1.x86_64                         1/1

Installed:
  cri-o-1.32.1-150500.1.1.x86_64

Complete!
Created symlink /etc/systemd/system/cri-o.service → /usr/lib/systemd/system/crio.sevice.
Created symlink /etc/systemd/system/multi-user.target.wants/crio.service → /usr/libsystemd/system/crio.service.
Removed "/etc/systemd/system/multi-user.target.wants/firewalld.service".
Removed "/etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service".

完整安裝(full)

Removed "/etc/systemd/system/multi-user.target.wants/firewalld.service".
Removed "/etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service".
Removed "/etc/systemd/system/multi-user.target.wants/firewalld.service".
Removed "/etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service".
W0204 13:07:15.849016   35671 initconfiguration.go:126] Usage of CRI endpoints withut URL scheme is deprecated and can cause kubelet errors in the future. Automaticaly prepending scheme "unix" to the "criSocket" with value "/var/run/crio/crio.sock".Please update your configuration!
[init] Using Kubernetes version: v1.32.1
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your interne connection
[preflight] You can also perform this action beforehand using 'kubeadm config image pull'
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [k8s-master1.training.lab kuernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.loal] and IPs [172.30.0.1 192.168.66.71]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [k8s-master1.training.lab ocalhost] and IPs [192.168.66.71 127.0.0.1 ::1]
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [k8s-master1.training.lab loalhost] and IPs [192.168.66.71 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "sa" key and public key
[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "super-admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
[control-plane] Creating static Pod manifest for "kube-scheduler"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelt/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml
[kubelet-start] Starting the kubelet
[wait-control-plane] Waiting for the kubelet to boot up the control plane as staticPods from directory "/etc/kubernetes/manifests"
[kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. Ths can take up to 4m0s
[kubelet-check] The kubelet is healthy after 1.502144174s
[api-check] Waiting for a healthy API server. This can take up to 4m0s
[api-check] The API server is healthy after 16.0025174s
[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the"kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config" in namespace kube-system with the cnfiguration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node k8s-master1.training.lab as control-plane by dding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/excludefrom-external-load-balancers]
[mark-control-plane] Marking the node k8s-master1.training.lab as control-plane by dding the taints [node-role.kubernetes.io/control-plane:NoSchedule]
[bootstrap-token] Using token: 9n8yud.b13p6yb2djhlt7t3
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRsin order for nodes to get long term certificate credentials
[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatcally approve CSRs from a Node Bootstrap Token
[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node lient certificates in the cluster
[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespce
[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable ubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as rot:

kubeadm join 192.168.66.71:6443 --token 9n8yud.b13p6yb2djhlt7t3 \
        --discovery-token-ca-cert-hash sha256:97eb558ee0e6a0dee68abab9ece116a91d108be33742b192046f73140de22c3
NAME                       STATUS     ROLES           AGE   VERSION
k8s-master1.training.lab   NotReady   control-plane   10s   v1.32.1
97eb558ee0e6a0dee68abab9ece116a91d108fbe33742b192046f73140de22c3
9n8yud.b13p6yb2djhlt7t3
kubeadm join 192.168.66.71:6443 --token nl9pe7.y41bej3u1qyrijcb --discovery-token-c-cert-hash sha256:97eb558ee0e6a0dee68abab9ece116a91d108fbe33742b192046f73140de22c3
the bootstrap token "ttl" was not of the form "\\A([a-z0-9]{6})\\.([a-z0-9]{16})\\z
To see the stack trace of this error execute with --v=5 or higher

完整安裝(full)，加入 worker node

[preflight] Running pre-flight checks
W0204 13:09:27.556090   36022 initconfiguration.go:126] Usage of CRI endpoints withut URL scheme is deprecated and can cause kubelet errors in the future. Automaticaly prepending scheme "unix" to the "criSocket" with value "/var/run/crio/crio.sock".Please update your configuration!
[preflight] Reading configuration from the "kubeadm-config" ConfigMap in namespace kube-system"...
[preflight] Use 'kubeadm init phase upload-config --config your-config.yaml' to re-pload it.
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelt/kubeadm-flags.env"
[kubelet-start] Starting the kubelet
[kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. Ths can take up to 4m0s
[kubelet-check] The kubelet is healthy after 2.004777591s
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.

[preflight] Running pre-flight checks
W0204 13:09:35.143302   37051 initconfiguration.go:126] Usage of CRI endpoints withut URL scheme is deprecated and can cause kubelet errors in the future. Automaticaly prepending scheme "unix" to the "criSocket" with value "/var/run/crio/crio.sock".Please update your configuration!
[preflight] Reading configuration from the "kubeadm-config" ConfigMap in namespace kube-system"...
[preflight] Use 'kubeadm init phase upload-config --config your-config.yaml' to re-pload it.
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelt/kubeadm-flags.env"
[kubelet-start] Starting the kubelet
[kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. Ths can take up to 4m0s
[kubelet-check] The kubelet is healthy after 1.518808027s
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.

NAME                       STATUS     ROLES           AGE   VERSION
k8s-master1.training.lab   NotReady   control-plane   28s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          9s    v1.32.1
k8s-node2.training.lab     NotReady   <none>          3s    v1.32.1
customresourcedefinition.apiextensions.k8s.io/antreaagentinfos.clusterinformation.atrea.tanzu.vmware.com created
customresourcedefinition.apiextensions.k8s.io/antreaagentinfos.crd.antrea.io create
customresourcedefinition.apiextensions.k8s.io/antreacontrollerinfos.clusterinformaton.antrea.tanzu.vmware.com created
customresourcedefinition.apiextensions.k8s.io/antreacontrollerinfos.crd.antrea.io ceated
customresourcedefinition.apiextensions.k8s.io/clustergroups.core.antrea.tanzu.vmwar.com created
customresourcedefinition.apiextensions.k8s.io/clustergroups.crd.antrea.io created
customresourcedefinition.apiextensions.k8s.io/clusternetworkpolicies.crd.antrea.io reated
customresourcedefinition.apiextensions.k8s.io/clusternetworkpolicies.security.antre.tanzu.vmware.com created
customresourcedefinition.apiextensions.k8s.io/egresses.crd.antrea.io created
customresourcedefinition.apiextensions.k8s.io/externalentities.core.antrea.tanzu.vmare.com created
customresourcedefinition.apiextensions.k8s.io/externalentities.crd.antrea.io create
customresourcedefinition.apiextensions.k8s.io/externalippools.crd.antrea.io created
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.antrea.io created
customresourcedefinition.apiextensions.k8s.io/networkpolicies.security.antrea.tanzuvmware.com created
customresourcedefinition.apiextensions.k8s.io/tiers.crd.antrea.io created
customresourcedefinition.apiextensions.k8s.io/tiers.security.antrea.tanzu.vmware.co created
customresourcedefinition.apiextensions.k8s.io/traceflows.crd.antrea.io created
customresourcedefinition.apiextensions.k8s.io/traceflows.ops.antrea.tanzu.vmware.co created
serviceaccount/antctl created
serviceaccount/antrea-agent created
serviceaccount/antrea-controller created
clusterrole.rbac.authorization.k8s.io/aggregate-antrea-clustergroups-edit created
clusterrole.rbac.authorization.k8s.io/aggregate-antrea-clustergroups-view created
clusterrole.rbac.authorization.k8s.io/aggregate-antrea-policies-edit created
clusterrole.rbac.authorization.k8s.io/aggregate-antrea-policies-view created
clusterrole.rbac.authorization.k8s.io/aggregate-traceflows-edit created
clusterrole.rbac.authorization.k8s.io/aggregate-traceflows-view created
clusterrole.rbac.authorization.k8s.io/antctl created
clusterrole.rbac.authorization.k8s.io/antrea-agent created
clusterrole.rbac.authorization.k8s.io/antrea-cluster-identity-reader created
clusterrole.rbac.authorization.k8s.io/antrea-controller created
clusterrolebinding.rbac.authorization.k8s.io/antctl created
clusterrolebinding.rbac.authorization.k8s.io/antrea-agent created
clusterrolebinding.rbac.authorization.k8s.io/antrea-controller created
configmap/antrea-config-t8cc9bfb6t created
service/antrea created
deployment.apps/antrea-controller created
apiservice.apiregistration.k8s.io/v1alpha1.stats.antrea.io created
apiservice.apiregistration.k8s.io/v1alpha1.stats.antrea.tanzu.vmware.com created
apiservice.apiregistration.k8s.io/v1beta1.controlplane.antrea.tanzu.vmware.com creaed
apiservice.apiregistration.k8s.io/v1beta1.system.antrea.io created
apiservice.apiregistration.k8s.io/v1beta1.system.antrea.tanzu.vmware.com created
apiservice.apiregistration.k8s.io/v1beta2.controlplane.antrea.io created
apiservice.apiregistration.k8s.io/v1beta2.controlplane.antrea.tanzu.vmware.com creaed
daemonset.apps/antrea-agent created
mutatingwebhookconfiguration.admissionregistration.k8s.io/crdmutator.antrea.io creaed
mutatingwebhookconfiguration.admissionregistration.k8s.io/crdmutator.antrea.tanzu.vware.com created
validatingwebhookconfiguration.admissionregistration.k8s.io/crdvalidator.antrea.io reated
validatingwebhookconfiguration.admissionregistration.k8s.io/crdvalidator.antrea.tanu.vmware.com created
NAME                       STATUS     ROLES           AGE   VERSION
k8s-master1.training.lab   NotReady   control-plane   71s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          52s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          46s   v1.32.1
NAME                       STATUS     ROLES           AGE   VERSION
k8s-master1.training.lab   NotReady   control-plane   72s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          53s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          47s   v1.32.1

Wait 30 seconds for get Ready...

k8s-master1.training.lab

完整安裝(full)，不用理會 - 開放 master 執行 pods

NAME                       STATUS     ROLES           AGE    VERSION
k8s-master1.training.lab   NotReady   control-plane   114s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          95s    v1.32.1
k8s-node2.training.lab     NotReady   <none>          89s    v1.32.1
[root@k8s-master1 ~]#


[root@k8s-master1 ~]# while true; do date; kubectl get nodes; sleep 10; done
Tue Feb  4 01:11:39 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   2m25s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          2m6s    v1.32.1
k8s-node2.training.lab     NotReady   <none>          2m      v1.32.1
Tue Feb  4 01:11:49 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   2m37s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          2m18s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          2m12s   v1.32.1
Tue Feb  4 01:12:01 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   2m50s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          2m31s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          2m25s   v1.32.1
Tue Feb  4 01:12:14 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   3m1s    v1.32.1
k8s-node1.training.lab     NotReady   <none>          2m42s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          2m36s   v1.32.1
Tue Feb  4 01:12:25 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   3m11s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          2m52s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          2m46s   v1.32.1
Tue Feb  4 01:12:35 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   3m21s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          3m2s    v1.32.1
k8s-node2.training.lab     NotReady   <none>          2m56s   v1.32.1
Tue Feb  4 01:12:45 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   3m32s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          3m13s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          3m7s    v1.32.1
Tue Feb  4 01:12:56 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   3m43s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          3m24s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          3m18s   v1.32.1
Tue Feb  4 01:13:07 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   3m54s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          3m35s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          3m29s   v1.32.1
Tue Feb  4 01:13:18 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   4m4s    v1.32.1
k8s-node1.training.lab     NotReady   <none>          3m45s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          3m39s   v1.32.1
Tue Feb  4 01:13:28 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   4m15s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          3m56s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          3m50s   v1.32.1
Tue Feb  4 01:13:39 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   4m25s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          4m6s    v1.32.1
k8s-node2.training.lab     NotReady   <none>          4m      v1.32.1
Tue Feb  4 01:13:49 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   4m36s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          4m17s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          4m11s   v1.32.1
Tue Feb  4 01:14:00 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   4m48s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          4m29s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          4m23s   v1.32.1
Tue Feb  4 01:14:12 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   5m1s    v1.32.1
k8s-node1.training.lab     NotReady   <none>          4m42s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          4m36s   v1.32.1
Tue Feb  4 01:14:25 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   5m13s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          4m54s   v1.32.1
k8s-node2.training.lab     NotReady   <none>          4m48s   v1.32.1
Tue Feb  4 01:14:37 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   5m24s   v1.32.1
k8s-node1.training.lab     NotReady   <none>          5m5s    v1.32.1
k8s-node2.training.lab     Ready      <none>          4m59s   v1.32.1
Tue Feb  4 01:14:49 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   5m36s   v1.32.1
k8s-node1.training.lab     Ready      <none>          5m17s   v1.32.1
k8s-node2.training.lab     Ready      <none>          5m11s   v1.32.1
Tue Feb  4 01:15:00 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   5m47s   v1.32.1
k8s-node1.training.lab     Ready      <none>          5m28s   v1.32.1
k8s-node2.training.lab     Ready      <none>          5m22s   v1.32.1
Tue Feb  4 01:15:11 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   5m57s   v1.32.1
k8s-node1.training.lab     Ready      <none>          5m38s   v1.32.1
k8s-node2.training.lab     Ready      <none>          5m32s   v1.32.1
Tue Feb  4 01:15:21 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   6m8s    v1.32.1
k8s-node1.training.lab     Ready      <none>          5m49s   v1.32.1
k8s-node2.training.lab     Ready      <none>          5m43s   v1.32.1
Tue Feb  4 01:15:32 PM CST 2025
NAME                       STATUS     ROLES           AGE     VERSION
k8s-master1.training.lab   NotReady   control-plane   6m18s   v1.32.1
k8s-node1.training.lab     Ready      <none>          5m59s   v1.32.1
k8s-node2.training.lab     Ready      <none>          5m53s   v1.32.1
Tue Feb  4 01:15:43 PM CST 2025
NAME                       STATUS   ROLES           AGE     VERSION
k8s-master1.training.lab   Ready    control-plane   6m29s   v1.32.1
k8s-node1.training.lab     Ready    <none>          6m10s   v1.32.1
k8s-node2.training.lab     Ready    <none>          6m4s    v1.32.1
Tue Feb  4 01:15:53 PM CST 2025
NAME                       STATUS   ROLES           AGE     VERSION
k8s-master1.training.lab   Ready    control-plane   6m39s   v1.32.1
k8s-node1.training.lab     Ready    <none>          6m20s   v1.32.1
k8s-node2.training.lab     Ready    <none>          6m14s   v1.32.1
^C
[root@k8s-master1 ~]#


[root@k8s-master1 ~]# kubectl create deployment test1 --image=httpd
deployment.apps/test1 created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get deployments.apps
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
test1   1/1     1            1           79s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
test1-8f778c7d6-zls4m   1/1     Running   0          84s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pods -o wide
NAME                    READY   STATUS    RESTARTS   AGE   IP           NODE                     NOMINATED NODE   READINESS GATES
test1-8f778c7d6-zls4m   1/1     Running   0          87s   10.128.1.2   k8s-node1.training.lab   <none>           <none>
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# curl 10.128.1.2
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]#


#
# kubernetes 1.32 使用自建的私庫 private registry
#

[root@k8s-standalone ~]# ls -l /etc/containers/registries.conf.d/
total 504
-rw-r--r--. 1 root root   6387 Nov 12 20:02 000-shortnames.conf
-rw-r--r--. 1 root root 499167 Nov 12 20:02 001-rhel-shortnames.conf
-rw-r--r--. 1 root root    497 Nov 12 20:02 002-rhel-shortnames-overrides.conf
-rw-r--r--  1 root root     57 Feb  4 09:37 crio.conf
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# vi /etc/containers/registries.conf.d/insecure-registry.conf
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# cat /etc/containers/registries.conf.d/insecure-registry.conf
[[registry]]
#prefix = "10.0.1.248:5000"
location = "10.0.1.248:5000"
insecure = true

[[registry]]
location = "192.168.66.248:5000"
insecure = true

[[registry]]
location = "docker1.training.lab:5000"
insecure = true

[[registry]]
location = "192.168.66.51:5000"
insecure = true
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# systemctl restart crio
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# kubectl get deployments.apps
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
test1   1/1     1            1           52s
test2   1/1     1            1           33s
test3   1/1     1            1           8s
[root@k8s-standalone ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
test1-8f778c7d6-lth27    1/1     Running   0          58s
test2-64cb98c9b9-44j96   1/1     Running   0          39s
test3-7cc5897b79-7ct2v   1/1     Running   0          14s
[root@k8s-standalone ~]#

[root@k8s-standalone ~]# kubectl get deployments.apps
No resources found in default namespace.
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# kubectl create deployment test1 --image=nginx
deployment.apps/test1 created
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# kubectl create deployment test2 --image=httpd
deployment.apps/test2 created
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# kubectl get deployments.apps
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
test1   1/1     1            1           73s
test2   1/1     1            1           50s
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
test1-7d9bdc56f4-fdw8t   1/1     Running   0          79s
test2-858c9c4dbf-nbtcq   1/1     Running   0          56s
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP           NODE                          NOMINATED NODE   READINESS GATES
test1-7d9bdc56f4-fdw8t   1/1     Running   0          84s   10.128.0.4   k8s-standalone.training.lab   <none>           <none>
test2-858c9c4dbf-nbtcq   1/1     Running   0          61s   10.128.0.5   k8s-standalone.training.lab   <none>           <none>
[root@k8s-standalone ~]# curl 10.128.0.5
<html><body><h1>It works!</h1></body></html>
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# kubectl create deployment test3 --image=docker1.training.lab:5000/httpd
deployment.apps/test3 created
[root@k8s-standalone ~]#
[root@k8s-standalone ~]# kubectl get deployments.apps
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
test1   1/1     1            1           2m59s
test2   1/1     1            1           2m36s
test3   1/1     1            1           65s
[root@k8s-standalone ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
test1-7d9bdc56f4-fdw8t   1/1     Running   0          3m5s
test2-858c9c4dbf-nbtcq   1/1     Running   0          2m42s
test3-57597df6d-9xdlk    1/1     Running   0          71s
[root@k8s-standalone ~]# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE     IP           NODE                          NOMINATED NODE   READINESS GATES
test1-7d9bdc56f4-fdw8t   1/1     Running   0          3m8s    10.128.0.4   k8s-standalone.training.lab   <none>           <none>
test2-858c9c4dbf-nbtcq   1/1     Running   0          2m45s   10.128.0.5   k8s-standalone.training.lab   <none>           <none>
test3-57597df6d-9xdlk    1/1     Running   0          74s     10.128.0.6   k8s-standalone.training.lab   <none>           <none>
[root@k8s-standalone ~]# curl 10.128.0.6
<html><body><h1>It works!</h1></body></html>
[root@k8s-standalone ~]#


[root@k8s-standalone ~]# scp -p /etc/containers/registries.conf.d/insecure-registry.conf root@k8s-node2:/etc/containers/registries.conf.d/insecure-registry.conf
root@k8s-node2's password:
insecure-registry.conf                                                                        100%  288    27.0KB/s   00:00
[root@k8s-standalone ~]# scp -p /etc/containers/registries.conf.d/insecure-registry.conf root@k8s-node1:/etc/containers/registries.conf.d/insecure-registry.conf
root@k8s-node1's password:
insecure-registry.conf                                                                        100%  288   135.0KB/s   00:00
[root@k8s-standalone ~]# scp -p /etc/containers/registries.conf.d/insecure-registry.conf root@k8s-master1:/etc/containers/registries.conf.d/insecure-registry.conf
root@k8s-master1's password:
insecure-registry.conf                                                                        100%  288   128.6KB/s   00:00
[root@k8s-standalone ~]#

[root@k8s-master1 ~]# cat /etc/containers/registries.conf.d/insecure-registry.conf
[[registry]]
#prefix = "10.0.1.248:5000"
location = "10.0.1.248:5000"
insecure = true

[[registry]]
location = "192.168.66.248:5000"
insecure = true

[[registry]]
location = "docker1.training.lab:5000"
insecure = true

[[registry]]
location = "192.168.66.51:5000"
insecure = true
[root@k8s-master1 ~]# systemctl restart crio
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# sshpass -p container scp /etc/containers/registries.conf.d/insecure-registry.conf root@k8s-node1:/etc/containers/registries.conf.d/insecure-registry.conf
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# sshpass -p container ssh -p 22 root@k8s-node1 "systemctl restart crio"
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# sshpass -p container scp /etc/containers/registries.conf.d/insecure-registry.conf root@k8s-node2:/etc/containers/registries.conf.d/insecure-registry.conf
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# sshpass -p container ssh -p 22 root@k8s-node2 "systemctl restart crio"                                    [root@k8s-master1 ~]#

[root@k8s-node1 ~]# cat /etc/containers/registries.conf.d/insecure-registry.conf
[[registry]]
#prefix = "192.168.66.249:5000"
location = "192.168.66.249:5000"
insecure = true

[[registry]]
location = "192.168.66.248:5000"
insecure = true

[[registry]]
location = "docker1.training.lab:5000"
insecure = true

[[registry]]
location = "192.168.66.51:5000"
insecure = true
[root@k8s-node1 ~]#
[root@k8s-node1 ~]# systemctl restart crio
[root@k8s-node1 ~]#

[root@k8s-node2 ~]# cat /etc/containers/registries.conf.d/insecure-registry.conf
[[registry]]
#prefix = "192.168.66.249:5000"
location = "192.168.66.249:5000"
insecure = true

[[registry]]
location = "192.168.66.248:5000"
insecure = true

[[registry]]
location = "docker1.training.lab:5000"
insecure = true

[[registry]]
location = "192.168.66.51:5000"
insecure = true
[root@k8s-node2 ~]#
[root@k8s-node2 ~]# systemctl restart crio
[root@k8s-node2 ~]#


[root@k8s-master1 ~]# kubectl get deployments.apps
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
test1   1/1     1            1           13m
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl create deployment test2 --image=docker1.training.lab:5000/httpd --replicas=2
deployment.apps/test2 created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get deployments.apps
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
test1   1/1     1            1           15m
test2   2/2     2            2           76s
[root@k8s-master1 ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
test1-8f778c7d6-zls4m    1/1     Running   0          15m
test2-64cb98c9b9-sgqlg   1/1     Running   0          82s
test2-64cb98c9b9-z9xmj   1/1     Running   0          82s
[root@k8s-master1 ~]# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP           NODE                     NOMINATED NODE   READINESS GATES
test1-8f778c7d6-zls4m    1/1     Running   0          15m   10.128.1.2   k8s-node1.training.lab   <none>           <none>
test2-64cb98c9b9-sgqlg   1/1     Running   0          85s   10.128.1.3   k8s-node1.training.lab   <none>           <none>
test2-64cb98c9b9-z9xmj   1/1     Running   0          85s   10.128.2.4   k8s-node2.training.lab   <none>           <none>
[root@k8s-master1 ~]# curl 10.128.1.3
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# curl 10.128.2.4
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]#


[root@k8s-master1 ~]# docker login -u ccw0729
Password:
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credential-stores

Login Succeeded
[root@k8s-master1 ~]# ls -l /root/.docker/config.json
-rw------- 1 root root 95 Jan 14 10:34 /root/.docker/config.json
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# cat /root/.docker/config.json
{
        "auths": {
                "https://index.docker.io/v1/": {
                        "auth": "XXXXXXXXXXXXXXXXXXXXXXXXX"
                }
        }
}[root@k8s-master1 ~]#


[root@k8s-master1 ~]# kubectl get secrets
No resources found in default namespace.
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl create secret generic regcred \
    --from-file=.dockerconfigjson=/root/.docker/config.json \
    --type=kubernetes.io/dockerconfigjson
secret/regcred created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get secrets
NAME      TYPE                             DATA   AGE
regcred   kubernetes.io/dockerconfigjson   1      4s
[root@k8s-master1 ~]#

https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/

[root@k8s-master1 ~]# wget https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/pods/private-reg-pod.yaml
--2025-01-14 11:02:29--  https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/pods/private-reg-pod.yaml
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 178 [text/plain]
Saving to: ‘private-reg-pod.yaml’

private-reg-pod.yaml            100%[=======================================================>]     178  --.-KB/s    in 0s

2025-01-14 11:02:29 (5.82 MB/s) - ‘private-reg-pod.yaml’ saved [178/178]

[root@k8s-master1 ~]# ls -l private-reg-pod.yaml
-rw-r--r-- 1 root root 178 Jan 14 11:02 private-reg-pod.yaml
[root@k8s-master1 ~]#


[root@k8s-master1 ~]# vi private-reg-pod.yaml
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# cat private-reg-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: private-reg
spec:
  containers:
  - name: httpd
    image: httpd
  imagePullSecrets:
  - name: regcred

[root@k8s-master1 ~]#

[root@k8s-master1 ~]# ./check_docker_pull_rate_limit.sh
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  5429    0  5429    0     0   5781      0 --:--:-- --:--:-- --:--:--  5787
HTTP/1.1 200 OK
content-length: 527
content-type: application/vnd.docker.distribution.manifest.v2+json
docker-content-digest: sha256:c2d41d2ba6d8b7b4a3ffec621578eb4d9a0909df29dfa2f6fd8a2e5fd0836aed
docker-distribution-api-version: registry/2.0
etag: "sha256:c2d41d2ba6d8b7b4a3ffec621578eb4d9a0909df29dfa2f6fd8a2e5fd0836aed"
date: Tue, 14 Jan 2025 03:04:20 GMT
strict-transport-security: max-age=31536000
ratelimit-limit: 100;w=21600
ratelimit-remaining: 94;w=21600
docker-ratelimit-source: 61.221.67.195

[root@k8s-master1 ~]# ./check_docker_pull_rate_limit-freeaccount.sh
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  5703    0  5703    0     0   5909      0 --:--:-- --:--:-- --:--:--  5909
HTTP/1.1 200 OK
content-length: 527
content-type: application/vnd.docker.distribution.manifest.v2+json
docker-content-digest: sha256:c2d41d2ba6d8b7b4a3ffec621578eb4d9a0909df29dfa2f6fd8a2e5fd0836aed
docker-distribution-api-version: registry/2.0
etag: "sha256:c2d41d2ba6d8b7b4a3ffec621578eb4d9a0909df29dfa2f6fd8a2e5fd0836aed"
date: Tue, 14 Jan 2025 03:04:26 GMT
strict-transport-security: max-age=31536000
ratelimit-limit: 200;w=21600
ratelimit-remaining: 198;w=21600
docker-ratelimit-source: a9029fe2-8965-489a-a63b-0a5cf869753c

[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl apply -f private-reg-pod.yaml
pod/private-reg created
[root@k8s-master1 ~]# ./check_docker_pull_rate_limit.sh
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  5429    0  5429    0     0   5806      0 --:--:-- --:--:-- --:--:--  5806
HTTP/1.1 200 OK
content-length: 527
content-type: application/vnd.docker.distribution.manifest.v2+json
docker-content-digest: sha256:c2d41d2ba6d8b7b4a3ffec621578eb4d9a0909df29dfa2f6fd8a2e5fd0836aed
docker-distribution-api-version: registry/2.0
etag: "sha256:c2d41d2ba6d8b7b4a3ffec621578eb4d9a0909df29dfa2f6fd8a2e5fd0836aed"
date: Tue, 14 Jan 2025 03:04:39 GMT
strict-transport-security: max-age=31536000
ratelimit-limit: 100;w=21600
ratelimit-remaining: 93;w=21600
docker-ratelimit-source: 61.221.67.195

[root@k8s-master1 ~]# ./check_docker_pull_rate_limit-freeaccount.sh
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  5703    0  5703    0     0   6517      0 --:--:-- --:--:-- --:--:--  6517
HTTP/1.1 200 OK
content-length: 527
content-type: application/vnd.docker.distribution.manifest.v2+json
docker-content-digest: sha256:c2d41d2ba6d8b7b4a3ffec621578eb4d9a0909df29dfa2f6fd8a2e5fd0836aed
docker-distribution-api-version: registry/2.0
etag: "sha256:c2d41d2ba6d8b7b4a3ffec621578eb4d9a0909df29dfa2f6fd8a2e5fd0836aed"
date: Tue, 14 Jan 2025 03:04:44 GMT
strict-transport-security: max-age=31536000
ratelimit-limit: 200;w=21600
ratelimit-remaining: 198;w=21600
docker-ratelimit-source: a9029fe2-8965-489a-a63b-0a5cf869753c


[root@k8s-master1 ~]# source <(kubectl completion bash)
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl delete all --all
pod "test1-8f778c7d6-zls4m" deleted
pod "test2-64cb98c9b9-sgqlg" deleted
pod "test2-64cb98c9b9-z9xmj" deleted
service "kubernetes" deleted
deployment.apps "test1" deleted
deployment.apps "test2" deleted
[root@k8s-master1 ~]#


[root@k8s-master1 ~]# kubectl create namespace ns1
namespace/ns1 created
[root@k8s-master1 ~]# kubectl create namespace ns2
namespace/ns2 created
[root@k8s-master1 ~]# kubectl create deployment test1 --image=docker1.training.lab:5000/nginx --namespace=ns1
deployment.apps/test1 created
[root@k8s-master1 ~]# kubectl create deployment test2 --image=docker1.training.lab:5000/nginx --namespace=ns2
deployment.apps/test2 created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get deployments.apps
No resources found in default namespace.
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get deployments.apps --all-namespaces
NAMESPACE     NAME                READY   UP-TO-DATE   AVAILABLE   AGE
kube-system   antrea-controller   1/1     1            1           91m
kube-system   coredns             2/2     2            2           92m
ns1           test1               0/1     1            0           26s
ns2           test2               1/1     1            1           17s
[root@k8s-master1 ~]#




[root@k8s-master1 ~]# kubectl create deployment test1 --image=docker1.training.lab:5000/nginx:1.7.1 --replicas=3 --dry-run=client -o yaml > test1-1.7.1.yaml
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# cat test1-1.7.1.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: test1
  name: test1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: test1
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: test1
    spec:
      containers:
      - image: docker1.training.lab:5000/nginx:1.7.1
        name: nginx
        resources: {}
status: {}
[root@k8s-master1 ~]#


[root@k8s-master1 ~]# while true; do for i in $(kubectl get pods | tail -n +2 | awk '{ print $1 }'); do kubectl get pod ${i} -o yaml | grep "\- image: .*nginx"; done; echo; kubectl get deployments -o wide; echo; sleep 1; done
  - image: docker1.training.lab:5000/nginx:1.7.1
  - image: docker1.training.lab:5000/nginx:1.7.1
  - image: docker1.training.lab:5000/nginx:1.7.1

NAME    READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES                                  SELECTOR
test1   3/3     3            3           3m45s   nginx        docker1.training.lab:5000/nginx:1.7.1   app=test1

  - image: docker1.training.lab:5000/nginx:1.7.1
  - image: docker1.training.lab:5000/nginx:1.7.1
  - image: docker1.training.lab:5000/nginx:1.7.1

NAME    READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES                                  SELECTOR
test1   3/3     3            3           3m47s   nginx        docker1.training.lab:5000/nginx:1.7.1   app=test1

^C
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl create deployment test1 --image=docker1.training.lab:5000/nginx:1.9.1 --replicas=3 --dry-run=client -o yaml > test1-1.9.1.yaml
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# cat test1-1.9.1.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: test1
  name: test1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: test1
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: test1
    spec:
      containers:
      - image: docker1.training.lab:5000/nginx:1.9.1
        name: nginx
        resources: {}
status: {}
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl rollout history deployment test1
deployment.apps/test1
REVISION  CHANGE-CAUSE
1         <none>
2         <none>

[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl rollout undo deployment test1
deployment.apps/test1 rolled back
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl rollout history deployment test1
deployment.apps/test1
REVISION  CHANGE-CAUSE
2         <none>
3         <none>

[root@k8s-master1 ~]#


[root@k8s-master1 ~]# kubectl create deployment test2 --image=docker1.training.lab:5000/httpd --replicas=3 --dry-run=client -o yaml > test2.yaml
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# cat test2.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: test2
  name: test2
spec:
  replicas: 3
  selector:
    matchLabels:
      app: test2
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: test2
    spec:
      containers:
      - image: docker1.training.lab:5000/httpd
        name: httpd
        resources: {}
status: {}
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# wget https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/controllers/nginx-deployment.yaml
--2025-02-04 14:50:43--  https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/controllers/nginx-deployment.yaml
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 341 [text/plain]
Saving to: ‘nginx-deployment.yaml’

nginx-deployment.yam 100%[===================>]     341  --.-KB/s    in 0s

2025-02-04 14:50:44 (13.6 MB/s) - ‘nginx-deployment.yaml’ saved [341/341]

[root@k8s-master1 ~]#
[root@k8s-master1 ~]# cat nginx-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl apply -f https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/controllers/nginx-deployment.yaml
deployment.apps/nginx-deployment created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get deployments.apps
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     3            3           77s
test1              3/3     3            3           9m18s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pods
NAME                                READY   STATUS    RESTARTS   AGE
nginx-deployment-647677fc66-2m6ww   1/1     Running   0          82s
nginx-deployment-647677fc66-4zmqw   1/1     Running   0          82s
nginx-deployment-647677fc66-8h9zg   1/1     Running   0          82s
test1-65cbd75c57-bp48t              1/1     Running   0          9m23s
test1-65cbd75c57-nc2tx              1/1     Running   0          4m17s
test1-65cbd75c57-pl5zn              1/1     Running   0          9m22s
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl delete -f https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/controllers/nginx-deployment.yaml
deployment.apps "nginx-deployment" deleted
[root@k8s-master1 ~]#


[root@k8s-master1 ~]# wget http://10.0.1.248/k8s/yaml/service-clusterIP.yaml
--2025-02-04 14:54:16--  http://10.0.1.248/k8s/yaml/service-clusterIP.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 989
Saving to: ‘service-clusterIP.yaml’

service-clusterIP.ya 100%[===================>]     989  --.-KB/s    in 0s

2025-02-04 14:54:16 (111 MB/s) - ‘service-clusterIP.yaml’ saved [989/989]

[root@k8s-master1 ~]# cat service-clusterIP.yaml
# service --> ClusterIP
# pod`s IP:80
# service`s IP(172.30.218.17):8081
# 切換 current namespace
#   kubectl config set-context --current --namespace=service-clusterip-2
---
apiVersion: v1
kind: Namespace
metadata:
  name: service-clusterip-2
---
apiVersion: v1
kind: Service
metadata:
  name: svc-2-httpd
  labels:
    app: svc-2-httpd
  namespace: service-clusterip-2
spec:
  #type: NodePort
  type: ClusterIP
  #type: LoadBalancer
  #clusterIP: 172.30.218.17
  ports:
  - port: 8081
  #- port: 80
    targetPort: 80
    #nodePort: 30007
  selector:
    app: httpd-2
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: httpd-2
  labels:
    app: httpd-2
  namespace: service-clusterip-2
spec:
  replicas: 2
  selector:
    matchLabels:
      app: httpd-2
  template:
    metadata:
      labels:
        app: httpd-2
    spec:
      containers:
      #- image: httpd
      - image: docker1.training.lab:5000/httpd
        name: httpd
        ports:
        - containerPort: 80
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl apply -f service-clusterIP.yaml
namespace/service-clusterip-2 created
service/svc-2-httpd created
deployment.apps/httpd-2 created
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl get service -A
NAMESPACE             NAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGE
default               kubernetes    ClusterIP   172.30.0.1       <none>        443/TCP                  13m
kube-system           antrea        ClusterIP   172.30.116.178   <none>        443/TCP                  105m
kube-system           kube-dns      ClusterIP   172.30.0.10      <none>        53/UDP,53/TCP,9153/TCP   106m
service-clusterip-2   svc-2-httpd   ClusterIP   172.30.24.63     <none>        8081/TCP                 95s
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl get pods --namespace=service-clusterip-2
NAME                       READY   STATUS    RESTARTS   AGE
httpd-2-68b85d46c7-t4v87   1/1     Running   0          2m52s
httpd-2-68b85d46c7-trhk5   1/1     Running   0          2m52s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get namespaces
NAME                  STATUS   AGE
default               Active   109m
kube-node-lease       Active   14m
kube-public           Active   109m
kube-system           Active   109m
service-clusterip-2   Active   4m17s
[root@k8s-master1 ~]# kubectl exec httpd-2-68b85d46c7-t4v87 --namespace=service-clusterip-2 -it -- bash
root@httpd-2-68b85d46c7-t4v87:/usr/local/apache2#
root@httpd-2-68b85d46c7-t4v87:/usr/local/apache2# ls -l
total 36
drwxr-xr-x 2 root root 4096 Feb 26  2020 bin
drwxr-xr-x 2 root root  167 Feb 26  2020 build
drwxr-xr-x 2 root root   78 Feb 26  2020 cgi-bin
drwxr-xr-x 4 root root   84 Feb 26  2020 conf
drwxr-xr-x 3 root root 4096 Feb 26  2020 error
drwxr-xr-x 2 root root   24 Feb 26  2020 htdocs
drwxr-xr-x 3 root root 8192 Feb 26  2020 icons
drwxr-xr-x 2 root root 4096 Feb 26  2020 include
drwxr-xr-x 1 root root   23 Feb  4 06:54 logs
drwxr-xr-x 2 root root 8192 Feb 26  2020 modules
root@httpd-2-68b85d46c7-t4v87:/usr/local/apache2# cd htdocs/
root@httpd-2-68b85d46c7-t4v87:/usr/local/apache2/htdocs# ls -l
total 4
-rw-r--r-- 1 root src 45 Jun 11  2007 index.html
root@httpd-2-68b85d46c7-t4v87:/usr/local/apache2/htdocs#
root@httpd-2-68b85d46c7-t4v87:/usr/local/apache2/htdocs# echo AAA > index.html
root@httpd-2-68b85d46c7-t4v87:/usr/local/apache2/htdocs# exit
exit
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pods --namespace=service-clusterip-2           NAME                       READY   STATUS    RESTARTS   AGE
httpd-2-68b85d46c7-t4v87   1/1     Running   0          4m46s
httpd-2-68b85d46c7-trhk5   1/1     Running   0          4m46s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl exec httpd-2-68b85d46c7-trhk5 --namespace=service-clusterip-2 -it -- bash
root@httpd-2-68b85d46c7-trhk5:/usr/local/apache2#
root@httpd-2-68b85d46c7-trhk5:/usr/local/apache2# cd htdocs/
root@httpd-2-68b85d46c7-trhk5:/usr/local/apache2/htdocs# echo BBB > index.html
root@httpd-2-68b85d46c7-trhk5:/usr/local/apache2/htdocs# exit
exit
[root@k8s-master1 ~]# kubectl get pods --namespace=service-clusterip-2           NAME                       READY   STATUS    RESTARTS   AGE
httpd-2-68b85d46c7-t4v87   1/1     Running   0          5m12s
httpd-2-68b85d46c7-trhk5   1/1     Running   0          5m12s
[root@k8s-master1 ~]# kubectl get pods --namespace=service-clusterip-2 -o wide
NAME                       READY   STATUS    RESTARTS   AGE     IP            NODE                     NOMINATED NODE   READINESS GATES
httpd-2-68b85d46c7-t4v87   1/1     Running   0          5m16s   10.128.1.14   k8s-node1.training.lab   <none>           <none>
httpd-2-68b85d46c7-trhk5   1/1     Running   0          5m16s   10.128.2.9    k8s-node2.training.lab   <none>           <none>
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# curl 10.128.1.14
AAA
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# curl 10.128.2.9
BBB
[root@k8s-master1 ~]# kubectl get service -A
NAMESPACE             NAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGE
default               kubernetes    ClusterIP   172.30.0.1       <none>        443/TCP                  18m
kube-system           antrea        ClusterIP   172.30.116.178   <none>        443/TCP                  111m
kube-system           kube-dns      ClusterIP   172.30.0.10      <none>        53/UDP,53/TCP,9153/TCP   112m
service-clusterip-2   svc-2-httpd   ClusterIP   172.30.24.63     <none>        8081/TCP                 7m5s
[root@k8s-master1 ~]# curl 172.30.24.63:8081
BBB
[root@k8s-master1 ~]# curl 172.30.24.63:8081
AAA
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# wget http://10.0.1.248/k8s/yaml/service-nodeport.yaml
--2025-02-04 15:02:40--  http://10.0.1.248/k8s/yaml/service-nodeport.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1067 (1.0K)
Saving to: ‘service-nodeport.yaml’

service-nodeport.yam 100%[===================>]   1.04K  --.-KB/s    in 0s

2025-02-04 15:02:40 (105 MB/s) - ‘service-nodeport.yaml’ saved [1067/1067]

[root@k8s-master1 ~]# cat service-nodeport.yaml
# service --> NodePort
# pod`s IP:80
# service`s IP(172.30.88.5):8082
# worker node`s IP:30008
# 切換 current namespace
#   kubectl config set-context --current --namespace=service-nodeport-2
---
apiVersion: v1
kind: Namespace
metadata:
  name: service-nodeport-2
---
apiVersion: v1
kind: Service
metadata:
  name: svc-2-httpd-nodeport
  labels:
    app: svc-2-httpd-nodeport
  namespace: service-nodeport-2
spec:
  #type: ClusterIP
  type: NodePort
  #type: LoadBalancer
  #clusterIP: 172.30.88.5
  ports:
  - port: 8082
  #- port: 80
    targetPort: 80
    nodePort: 30008
  selector:
    app: httpd-2-nodeport
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: httpd-2-nodeport
  labels:
    app: httpd-2-nodeport
  namespace: service-nodeport-2
spec:
  replicas: 2
  selector:
    matchLabels:
      app: httpd-2-nodeport
  template:
    metadata:
      labels:
        app: httpd-2-nodeport
    spec:
      containers:
      #- image: httpd
      - image: docker1.training.lab:5000/httpd
        name: httpd
        ports:
        - containerPort: 80
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl apply -f service-nodeport.yaml
namespace/service-nodeport-2 created
service/svc-2-httpd-nodeport created
deployment.apps/httpd-2-nodeport created
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl get namespaces
NAME                  STATUS   AGE
default               Active   114m
kube-node-lease       Active   19m
kube-public           Active   114m
kube-system           Active   114m
service-clusterip-2   Active   9m18s
service-nodeport-2    Active   65s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get services -A
NAMESPACE             NAME                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                  AGE
default               kubernetes             ClusterIP   172.30.0.1       <none>        443/TCP                  20m
kube-system           antrea                 ClusterIP   172.30.116.178   <none>        443/TCP                  113m
kube-system           kube-dns               ClusterIP   172.30.0.10      <none>        53/UDP,53/TCP,9153/TCP   114m
service-clusterip-2   svc-2-httpd            ClusterIP   172.30.24.63     <none>        8081/TCP                 9m25s
service-nodeport-2    svc-2-httpd-nodeport   NodePort    172.30.21.179    <none>        8082:30008/TCP           72s
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
test1-65cbd75c57-bp48t   1/1     Running   0          21m
test1-65cbd75c57-nc2tx   1/1     Running   0          16m
test1-65cbd75c57-pl5zn   1/1     Running   0          21m
[root@k8s-master1 ~]# kubectl get pods --namespace=service-nodeport-2
NAME                             READY   STATUS    RESTARTS   AGE
httpd-2-nodeport-68dc9dc-pfgdw   1/1     Running   0          111s
httpd-2-nodeport-68dc9dc-zwbdv   1/1     Running   0          111s
[root@k8s-master1 ~]# kubectl get pods --namespace=service-nodeport-2 -o wide
NAME                             READY   STATUS    RESTARTS   AGE    IP            NODE                     NOMINATED NODE   READINESS GATES
httpd-2-nodeport-68dc9dc-pfgdw   1/1     Running   0          115s   10.128.1.15   k8s-node1.training.lab   <none>           <none>
httpd-2-nodeport-68dc9dc-zwbdv   1/1     Running   0          115s   10.128.2.10   k8s-node2.training.lab   <none>           <none>
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# curl 10.128.1.15
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]# curl 10.128.2.10
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]# kubectl get services --namespace=service-nodeport-2
NAME                   TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
svc-2-httpd-nodeport   NodePort   172.30.21.179   <none>        8082:30008/TCP   2m31s
[root@k8s-master1 ~]# curl 172.30.21.179:8082
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# curl k8s-node1:30008
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# curl k8s-node2:30008
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# curl k8s-master1:30008
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# wget http://192.168.66.248/k8s/yaml/service-loadbalancer.yaml
--2025-02-04 15:06:52--  http://192.168.66.248/k8s/yaml/service-loadbalancer.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1052 (1.0K)
Saving to: ‘service-loadbalancer.yaml’

service-loadbalancer 100%[===================>]   1.03K  --.-KB/s    in 0s

2025-02-04 15:06:52 (74.1 MB/s) - ‘service-loadbalancer.yaml’ saved [1052/1052]

[root@k8s-master1 ~]# cat service-loadbalancer.yaml
# service --> LoadBalancer
# pod`s IP:80
# service`s IP(172.30.118.207):8083
# worker node`s IP:30009
# 切換 current namespace
#   kubectl config set-context --current --namespace=service-loadbalancer-1
---
apiVersion: v1
kind: Namespace
metadata:
  name: service-loadbalancer-1
---
apiVersion: v1
kind: Service
metadata:
  name: svc-2-httpd-lb
  labels:
    app: svc-2-httpd-lb
  namespace: service-loadbalancer-1
spec:
  #type: NodePort
  #type: ClusterIP
  type: LoadBalancer
  #clusterIP: 172.30.118.207
  ports:
  - port: 8083
  #- port: 80
    targetPort: 80
    #nodePort: 30009
  selector:
    app: httpd-2-lb
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: httpd-2-lb
  labels:
    app: httpd-2-lb
  namespace: service-loadbalancer-1
spec:
  replicas: 2
  selector:
    matchLabels:
      app: httpd-2-lb
  template:
    metadata:
      labels:
        app: httpd-2-lb
    spec:
      containers:
      #- image: httpd
      - image: docker1.training.lab:5000/httpd
        name: httpd
        ports:
        - containerPort: 80
[root@k8s-master1 ~]# kubectl apply -f service-loadbalancer.yaml
namespace/service-loadbalancer-1 created
service/svc-2-httpd-lb created
deployment.apps/httpd-2-lb created
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl get namespaces
NAME                     STATUS   AGE
default                  Active   118m
kube-node-lease          Active   23m
kube-public              Active   118m
kube-system              Active   118m
service-clusterip-2      Active   13m
service-loadbalancer-1   Active   48s
service-nodeport-2       Active   5m4s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get services --namespace=service-loadbalancer-1
NAME             TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
svc-2-httpd-lb   LoadBalancer   172.30.227.169   <pending>     8083:32254/TCP   60s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# curl 172.30.227.169:8083
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl get pods --namespace=service-loadbalancer-1
NAME                          READY   STATUS    RESTARTS   AGE
httpd-2-lb-77476db4bd-7wg64   1/1     Running   0          97s
httpd-2-lb-77476db4bd-cw9wp   1/1     Running   0          97s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pods --namespace=service-loadbalancer-1 -o wide
NAME                          READY   STATUS    RESTARTS   AGE    IP            NODE                     NOMINATED NODE   READINESS GATES
httpd-2-lb-77476db4bd-7wg64   1/1     Running   0          102s   10.128.2.11   k8s-node2.training.lab   <none>           <none>
httpd-2-lb-77476db4bd-cw9wp   1/1     Running   0          102s   10.128.1.16   k8s-node1.training.lab   <none>           <none>
[root@k8s-master1 ~]# curl 10.128.2.11
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]# curl 10.128.1.16
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl get services --namespace=service-loadbalancer-1
NAME             TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
svc-2-httpd-lb   LoadBalancer   172.30.227.169   <pending>     8083:32254/TCP   2m17s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# curl k8s-node1:32254
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]# curl k8s-node2:32254
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]# curl k8s-master1:32254
<html><body><h1>It works!</h1></body></html>
[root@k8s-master1 ~]#

##########################
# PV/PVC
##########################

[root@k8s-node1 ~]# ls -l /mnt
total 0
drwxr-xr-x. 2 root root 6 Dec 30 11:22 hgfs
[root@k8s-node1 ~]#
[root@k8s-node1 ~]# mkdir -p /mnt/data
[root@k8s-node1 ~]# vi /mnt/data/index.html
[root@k8s-node1 ~]#
[root@k8s-node1 ~]# cat /mnt/data/index.html
node1...AAA
[root@k8s-node1 ~]#


[root@k8s-node2 ~]# ls -l /mnt
total 0
drwxr-xr-x. 2 root root 6 Dec 30 11:22 hgfs
[root@k8s-node2 ~]# mkdir -p /mnt/data
[root@k8s-node2 ~]#
[root@k8s-node2 ~]# vi /mnt/data/index.html
[root@k8s-node2 ~]#
[root@k8s-node2 ~]# cat /mnt/data/index.html
node2...BBB
[root@k8s-node2 ~]#

[root@k8s-master1 ~]# wget http://10.0.1.248/k8s/yaml/pv1-local.yaml
--2025-02-04 15:13:23--  http://10.0.1.248/k8s/yaml/pv1-local.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 224
Saving to: ‘pv1-local.yaml’

pv1-local.yaml       100%[===================>]     224  --.-KB/s    in 0s

2025-02-04 15:13:23 (20.8 MB/s) - ‘pv1-local.yaml’ saved [224/224]

[root@k8s-master1 ~]# kubectl get pv
No resources found
[root@k8s-master1 ~]# kubectl apply -f pv1-local.yaml
persistentvolume/pv1-local created
[root@k8s-master1 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv1-local   10Gi       RWO            Retain           Available           manual         <unset>                          3s
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# wget http://10.0.1.248/k8s/yaml/pvc1-local.yaml
--2025-02-04 15:14:54--  http://10.0.1.248/k8s/yaml/pvc1-local.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 186
Saving to: ‘pvc1-local.yaml’

pvc1-local.yaml      100%[===================>]     186  --.-KB/s    in 0s

2025-02-04 15:14:54 (16.2 MB/s) - ‘pvc1-local.yaml’ saved [186/186]

[root@k8s-master1 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv1-local   10Gi       RWO            Retain           Available           manual         <unset>                          84s
[root@k8s-master1 ~]# kubectl get pvc
No resources found in default namespace.
[root@k8s-master1 ~]# kubectl apply -f pvc1-local.yaml
persistentvolumeclaim/pvc1-local created
[root@k8s-master1 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv1-local   10Gi       RWO            Retain           Bound    default/pvc1-local   manual         <unset>                          95s
[root@k8s-master1 ~]# kubectl get pvc
NAME         STATUS   VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
pvc1-local   Bound    pv1-local   10Gi       RWO            manual         <unset>                 5s
[root@k8s-master1 ~]#


[root@k8s-master1 ~]# wget http://10.0.1.248/k8s/yaml/pv1-pod-local.yaml
--2025-02-04 15:16:10--  http://10.0.1.248/k8s/yaml/pv1-pod-local.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 442
Saving to: ‘pv1-pod-local.yaml’

pv1-pod-local.yaml   100%[===================>]     442  --.-KB/s    in 0s

2025-02-04 15:16:10 (38.0 MB/s) - ‘pv1-pod-local.yaml’ saved [442/442]

[root@k8s-master1 ~]# kubectl apply -f pv1-pod-local.yaml
pod/pv1-pod-local created
[root@k8s-master1 ~]# kubectl get pods
NAME            READY   STATUS    RESTARTS   AGE
pv1-pod-local   1/1     Running   0          17s
[root@k8s-master1 ~]# kubectl get pods -o wide
NAME            READY   STATUS    RESTARTS   AGE   IP            NODE                     NOMINATED NODE   READINESS GATES
pv1-pod-local   1/1     Running   0          21s   10.128.1.17   k8s-node1.training.lab   <none>           <none>
[root@k8s-master1 ~]# curl 10.128.1.17
node1...AAA
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# yum install nfs-utils -y
Last metadata expiration check: 2:16:53 ago on Tue 04 Feb 2025 01:06:06 PM CST.
Dependencies resolved.
=================================================================================
 Package                Architecture Version                  Repository    Size
=================================================================================
Installing:
 nfs-utils              x86_64       1:2.5.4-27.el9           baseos       431 k
Upgrading:
 libipa_hbac            x86_64       2.9.5-4.el9_5.4          baseos        35 k
 libsss_certmap         x86_64       2.9.5-4.el9_5.4          baseos        90 k
 libsss_idmap           x86_64       2.9.5-4.el9_5.4          baseos        41 k
 libsss_nss_idmap       x86_64       2.9.5-4.el9_5.4          baseos        45 k
 libsss_sudo            x86_64       2.9.5-4.el9_5.4          baseos        35 k
 sssd                   x86_64       2.9.5-4.el9_5.4          baseos        27 k
 sssd-ad                x86_64       2.9.5-4.el9_5.4          baseos       215 k
 sssd-client            x86_64       2.9.5-4.el9_5.4          baseos       161 k
 sssd-common            x86_64       2.9.5-4.el9_5.4          baseos       1.6 M
 sssd-common-pac        x86_64       2.9.5-4.el9_5.4          baseos        96 k
 sssd-ipa               x86_64       2.9.5-4.el9_5.4          baseos       281 k
 sssd-kcm               x86_64       2.9.5-4.el9_5.4          baseos       109 k
 sssd-krb5              x86_64       2.9.5-4.el9_5.4          baseos        72 k
 sssd-krb5-common       x86_64       2.9.5-4.el9_5.4          baseos        94 k
 sssd-ldap              x86_64       2.9.5-4.el9_5.4          baseos       159 k
 sssd-proxy             x86_64       2.9.5-4.el9_5.4          baseos        72 k
Installing dependencies:
 gssproxy               x86_64       0.8.4-7.el9              baseos       108 k
 libev                  x86_64       4.33-5.el9.0.1           baseos        51 k
 libnfsidmap            x86_64       1:2.5.4-27.el9           baseos        59 k
 libverto-libev         x86_64       0.3.2-3.el9              baseos        13 k
 rpcbind                x86_64       1.2.6-7.el9              baseos        56 k
 sssd-nfs-idmap         x86_64       2.9.5-4.el9_5.4          baseos        39 k

Transaction Summary
=================================================================================
Install   7 Packages
Upgrade  16 Packages

Total download size: 3.8 M
Downloading Packages:
(1/23): libverto-libev-0.3.2-3.el9.x86_64.rpm    126 kB/s |  13 kB     00:00
(2/23): rpcbind-1.2.6-7.el9.x86_64.rpm           370 kB/s |  56 kB     00:00
(3/23): libev-4.33-5.el9.0.1.x86_64.rpm          331 kB/s |  51 kB     00:00
(4/23): sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64.rp 462 kB/s |  39 kB     00:00
(5/23): libnfsidmap-2.5.4-27.el9.x86_64.rpm      745 kB/s |  59 kB     00:00
(6/23): gssproxy-0.8.4-7.el9.x86_64.rpm          706 kB/s | 108 kB     00:00
(7/23): sssd-proxy-2.9.5-4.el9_5.4.x86_64.rpm    605 kB/s |  72 kB     00:00
(8/23): sssd-ldap-2.9.5-4.el9_5.4.x86_64.rpm     612 kB/s | 159 kB     00:00
(9/23): sssd-krb5-common-2.9.5-4.el9_5.4.x86_64. 199 kB/s |  94 kB     00:00
(10/23): sssd-krb5-2.9.5-4.el9_5.4.x86_64.rpm    227 kB/s |  72 kB     00:00
(11/23): nfs-utils-2.5.4-27.el9.x86_64.rpm       575 kB/s | 431 kB     00:00
(12/23): sssd-kcm-2.9.5-4.el9_5.4.x86_64.rpm     955 kB/s | 109 kB     00:00
(13/23): sssd-ipa-2.9.5-4.el9_5.4.x86_64.rpm     790 kB/s | 281 kB     00:00
(14/23): sssd-common-pac-2.9.5-4.el9_5.4.x86_64. 198 kB/s |  96 kB     00:00
(15/23): sssd-client-2.9.5-4.el9_5.4.x86_64.rpm  840 kB/s | 161 kB     00:00
(16/23): sssd-2.9.5-4.el9_5.4.x86_64.rpm         371 kB/s |  27 kB     00:00
(17/23): libsss_sudo-2.9.5-4.el9_5.4.x86_64.rpm   65 kB/s |  35 kB     00:00
(18/23): sssd-ad-2.9.5-4.el9_5.4.x86_64.rpm      309 kB/s | 215 kB     00:00
(19/23): libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64 291 kB/s |  45 kB     00:00
(20/23): libsss_idmap-2.9.5-4.el9_5.4.x86_64.rpm 248 kB/s |  41 kB     00:00
(21/23): libipa_hbac-2.9.5-4.el9_5.4.x86_64.rpm  137 kB/s |  35 kB     00:00
(22/23): libsss_certmap-2.9.5-4.el9_5.4.x86_64.r 251 kB/s |  90 kB     00:00
(23/23): sssd-common-2.9.5-4.el9_5.4.x86_64.rpm  797 kB/s | 1.6 MB     00:02
---------------------------------------------------------------------------------
Total                                            1.0 MB/s | 3.8 MB     00:03
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                         1/1
  Upgrading        : libsss_idmap-2.9.5-4.el9_5.4.x86_64                    1/39
  Upgrading        : libsss_certmap-2.9.5-4.el9_5.4.x86_64                  2/39
  Installing       : libnfsidmap-1:2.5.4-27.el9.x86_64                      3/39
  Installing       : sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64                  4/39
  Upgrading        : libipa_hbac-2.9.5-4.el9_5.4.x86_64                     5/39
  Upgrading        : libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64                6/39
  Upgrading        : sssd-client-2.9.5-4.el9_5.4.x86_64                     7/39
  Running scriptlet: sssd-client-2.9.5-4.el9_5.4.x86_64                     7/39
  Upgrading        : libsss_sudo-2.9.5-4.el9_5.4.x86_64                     8/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.4.x86_64                     9/39
  Upgrading        : sssd-common-2.9.5-4.el9_5.4.x86_64                     9/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.4.x86_64                     9/39
  Upgrading        : sssd-krb5-common-2.9.5-4.el9_5.4.x86_64               10/39
  Upgrading        : sssd-common-pac-2.9.5-4.el9_5.4.x86_64                11/39
  Upgrading        : sssd-ipa-2.9.5-4.el9_5.4.x86_64                       12/39
  Upgrading        : sssd-ad-2.9.5-4.el9_5.4.x86_64                        13/39
  Upgrading        : sssd-ldap-2.9.5-4.el9_5.4.x86_64                      14/39
  Upgrading        : sssd-krb5-2.9.5-4.el9_5.4.x86_64                      15/39
  Upgrading        : sssd-proxy-2.9.5-4.el9_5.4.x86_64                     16/39
  Installing       : libev-4.33-5.el9.0.1.x86_64                           17/39
  Installing       : libverto-libev-0.3.2-3.el9.x86_64                     18/39
  Installing       : gssproxy-0.8.4-7.el9.x86_64                           19/39
  Running scriptlet: gssproxy-0.8.4-7.el9.x86_64                           19/39
  Running scriptlet: rpcbind-1.2.6-7.el9.x86_64                            20/39
  Installing       : rpcbind-1.2.6-7.el9.x86_64                            20/39
  Running scriptlet: rpcbind-1.2.6-7.el9.x86_64                            20/39
Created symlink /etc/systemd/system/multi-user.target.wants/rpcbind.service → /usr/lib/systemd/system/rpcbind.service.
Created symlink /etc/systemd/system/sockets.target.wants/rpcbind.socket → /usr/lib/systemd/system/rpcbind.socket.

  Running scriptlet: nfs-utils-1:2.5.4-27.el9.x86_64                       21/39
  Installing       : nfs-utils-1:2.5.4-27.el9.x86_64                       21/39
  Running scriptlet: nfs-utils-1:2.5.4-27.el9.x86_64                       21/39
  Upgrading        : sssd-2.9.5-4.el9_5.4.x86_64                           22/39
  Upgrading        : sssd-kcm-2.9.5-4.el9_5.4.x86_64                       23/39
  Running scriptlet: sssd-kcm-2.9.5-4.el9_5.4.x86_64                       23/39
  Cleanup          : sssd-2.9.5-4.el9_5.1.x86_64                           24/39
  Cleanup          : sssd-ipa-2.9.5-4.el9_5.1.x86_64                       25/39
  Cleanup          : sssd-ad-2.9.5-4.el9_5.1.x86_64                        26/39
  Cleanup          : sssd-ldap-2.9.5-4.el9_5.1.x86_64                      27/39
  Cleanup          : sssd-proxy-2.9.5-4.el9_5.1.x86_64                     28/39
  Cleanup          : sssd-common-pac-2.9.5-4.el9_5.1.x86_64                29/39
  Cleanup          : sssd-krb5-2.9.5-4.el9_5.1.x86_64                      30/39
  Running scriptlet: sssd-kcm-2.9.5-4.el9_5.1.x86_64                       31/39
  Cleanup          : sssd-kcm-2.9.5-4.el9_5.1.x86_64                       31/39
  Running scriptlet: sssd-kcm-2.9.5-4.el9_5.1.x86_64                       31/39
  Cleanup          : sssd-krb5-common-2.9.5-4.el9_5.1.x86_64               32/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.1.x86_64                    33/39
  Cleanup          : sssd-common-2.9.5-4.el9_5.1.x86_64                    33/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.1.x86_64                    33/39
  Running scriptlet: sssd-client-2.9.5-4.el9_5.1.x86_64                    34/39
  Cleanup          : sssd-client-2.9.5-4.el9_5.1.x86_64                    34/39
  Cleanup          : libsss_idmap-2.9.5-4.el9_5.1.x86_64                   35/39
  Cleanup          : libsss_nss_idmap-2.9.5-4.el9_5.1.x86_64               36/39
  Cleanup          : libsss_sudo-2.9.5-4.el9_5.1.x86_64                    37/39
  Cleanup          : libsss_certmap-2.9.5-4.el9_5.1.x86_64                 38/39
  Cleanup          : libipa_hbac-2.9.5-4.el9_5.1.x86_64                    39/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.4.x86_64                    39/39
  Running scriptlet: libipa_hbac-2.9.5-4.el9_5.1.x86_64                    39/39
  Verifying        : libverto-libev-0.3.2-3.el9.x86_64                      1/39
  Verifying        : rpcbind-1.2.6-7.el9.x86_64                             2/39
  Verifying        : libev-4.33-5.el9.0.1.x86_64                            3/39
  Verifying        : sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64                  4/39
  Verifying        : gssproxy-0.8.4-7.el9.x86_64                            5/39
  Verifying        : nfs-utils-1:2.5.4-27.el9.x86_64                        6/39
  Verifying        : libnfsidmap-1:2.5.4-27.el9.x86_64                      7/39
  Verifying        : sssd-proxy-2.9.5-4.el9_5.4.x86_64                      8/39
  Verifying        : sssd-proxy-2.9.5-4.el9_5.1.x86_64                      9/39
  Verifying        : sssd-ldap-2.9.5-4.el9_5.4.x86_64                      10/39
  Verifying        : sssd-ldap-2.9.5-4.el9_5.1.x86_64                      11/39
  Verifying        : sssd-krb5-common-2.9.5-4.el9_5.4.x86_64               12/39
  Verifying        : sssd-krb5-common-2.9.5-4.el9_5.1.x86_64               13/39
  Verifying        : sssd-krb5-2.9.5-4.el9_5.4.x86_64                      14/39
  Verifying        : sssd-krb5-2.9.5-4.el9_5.1.x86_64                      15/39
  Verifying        : sssd-kcm-2.9.5-4.el9_5.4.x86_64                       16/39
  Verifying        : sssd-kcm-2.9.5-4.el9_5.1.x86_64                       17/39
  Verifying        : sssd-ipa-2.9.5-4.el9_5.4.x86_64                       18/39
  Verifying        : sssd-ipa-2.9.5-4.el9_5.1.x86_64                       19/39
  Verifying        : sssd-common-pac-2.9.5-4.el9_5.4.x86_64                20/39
  Verifying        : sssd-common-pac-2.9.5-4.el9_5.1.x86_64                21/39
  Verifying        : sssd-common-2.9.5-4.el9_5.4.x86_64                    22/39
  Verifying        : sssd-common-2.9.5-4.el9_5.1.x86_64                    23/39
  Verifying        : sssd-client-2.9.5-4.el9_5.4.x86_64                    24/39
  Verifying        : sssd-client-2.9.5-4.el9_5.1.x86_64                    25/39
  Verifying        : sssd-ad-2.9.5-4.el9_5.4.x86_64                        26/39
  Verifying        : sssd-ad-2.9.5-4.el9_5.1.x86_64                        27/39
  Verifying        : sssd-2.9.5-4.el9_5.4.x86_64                           28/39
  Verifying        : sssd-2.9.5-4.el9_5.1.x86_64                           29/39
  Verifying        : libsss_sudo-2.9.5-4.el9_5.4.x86_64                    30/39
  Verifying        : libsss_sudo-2.9.5-4.el9_5.1.x86_64                    31/39
  Verifying        : libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64               32/39
  Verifying        : libsss_nss_idmap-2.9.5-4.el9_5.1.x86_64               33/39
  Verifying        : libsss_idmap-2.9.5-4.el9_5.4.x86_64                   34/39
  Verifying        : libsss_idmap-2.9.5-4.el9_5.1.x86_64                   35/39
  Verifying        : libsss_certmap-2.9.5-4.el9_5.4.x86_64                 36/39
  Verifying        : libsss_certmap-2.9.5-4.el9_5.1.x86_64                 37/39
  Verifying        : libipa_hbac-2.9.5-4.el9_5.4.x86_64                    38/39
  Verifying        : libipa_hbac-2.9.5-4.el9_5.1.x86_64                    39/39

Upgraded:
  libipa_hbac-2.9.5-4.el9_5.4.x86_64    libsss_certmap-2.9.5-4.el9_5.4.x86_64
  libsss_idmap-2.9.5-4.el9_5.4.x86_64   libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64
  libsss_sudo-2.9.5-4.el9_5.4.x86_64    sssd-2.9.5-4.el9_5.4.x86_64
  sssd-ad-2.9.5-4.el9_5.4.x86_64        sssd-client-2.9.5-4.el9_5.4.x86_64
  sssd-common-2.9.5-4.el9_5.4.x86_64    sssd-common-pac-2.9.5-4.el9_5.4.x86_64
  sssd-ipa-2.9.5-4.el9_5.4.x86_64       sssd-kcm-2.9.5-4.el9_5.4.x86_64
  sssd-krb5-2.9.5-4.el9_5.4.x86_64      sssd-krb5-common-2.9.5-4.el9_5.4.x86_64
  sssd-ldap-2.9.5-4.el9_5.4.x86_64      sssd-proxy-2.9.5-4.el9_5.4.x86_64
Installed:
  gssproxy-0.8.4-7.el9.x86_64               libev-4.33-5.el9.0.1.x86_64
  libnfsidmap-1:2.5.4-27.el9.x86_64         libverto-libev-0.3.2-3.el9.x86_64
  nfs-utils-1:2.5.4-27.el9.x86_64           rpcbind-1.2.6-7.el9.x86_64
  sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64

Complete!
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# ls -l /etc/exports
-rw-r--r--. 1 root root 0 Jun 23  2020 /etc/exports
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# vi /etc/exports
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# cat /etc/exports
/data *(rw,no_root_squash)
[root@k8s-master1 ~]#

[root@k8s-master1 ~]#
[root@k8s-master1 ~]# ls -ld /data
ls: cannot access '/data': No such file or directory
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# mkdir -p /data
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# vi /data/index.html
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# cat /data/index.html
master...CCC
[root@k8s-master1 ~]#



[root@k8s-master1 ~]# systemctl start nfs-server.service
[root@k8s-master1 ~]# systemctl enable nfs-server.service
Created symlink /etc/systemd/system/multi-user.target.wants/nfs-server.service → /usr/lib/systemd/system/nfs-server.service.
[root@k8s-master1 ~]# systemctl status nfs-server.service
● nfs-server.service - NFS server and services
     Loaded: loaded (/usr/lib/systemd/system/nfs-server.service; enabled; preset>
    Drop-In: /run/systemd/generator/nfs-server.service.d
             └─order-with-mounts.conf
     Active: active (exited) since Tue 2025-02-04 15:25:58 CST; 10s ago
       Docs: man:rpc.nfsd(8)
             man:exportfs(8)
   Main PID: 66886 (code=exited, status=0/SUCCESS)
        CPU: 65ms

Feb 04 15:25:57 k8s-master1.training.lab systemd[1]: Starting NFS server and ser>
Feb 04 15:25:58 k8s-master1.training.lab systemd[1]: Finished NFS server and ser>
[root@k8s-master1 ~]#


[root@k8s-node1 ~]# showmount
bash: showmount: command not found...
Packages providing this file are:
'nfs-utils'
'nfs-utils-coreos'
[root@k8s-node1 ~]#
[root@k8s-node1 ~]# yum install nfs-utils -y
Last metadata expiration check: 2:20:27 ago on Tue 04 Feb 2025 01:06:27 PM CST.
Dependencies resolved.
=================================================================================
 Package                Architecture Version                  Repository    Size
=================================================================================
Installing:
 nfs-utils              x86_64       1:2.5.4-27.el9           baseos       431 k
Upgrading:
 libipa_hbac            x86_64       2.9.5-4.el9_5.4          baseos        35 k
 libsss_certmap         x86_64       2.9.5-4.el9_5.4          baseos        90 k
 libsss_idmap           x86_64       2.9.5-4.el9_5.4          baseos        41 k
 libsss_nss_idmap       x86_64       2.9.5-4.el9_5.4          baseos        45 k
 libsss_sudo            x86_64       2.9.5-4.el9_5.4          baseos        35 k
 sssd                   x86_64       2.9.5-4.el9_5.4          baseos        27 k
 sssd-ad                x86_64       2.9.5-4.el9_5.4          baseos       215 k
 sssd-client            x86_64       2.9.5-4.el9_5.4          baseos       161 k
 sssd-common            x86_64       2.9.5-4.el9_5.4          baseos       1.6 M
 sssd-common-pac        x86_64       2.9.5-4.el9_5.4          baseos        96 k
 sssd-ipa               x86_64       2.9.5-4.el9_5.4          baseos       281 k
 sssd-kcm               x86_64       2.9.5-4.el9_5.4          baseos       109 k
 sssd-krb5              x86_64       2.9.5-4.el9_5.4          baseos        72 k
 sssd-krb5-common       x86_64       2.9.5-4.el9_5.4          baseos        94 k
 sssd-ldap              x86_64       2.9.5-4.el9_5.4          baseos       159 k
 sssd-proxy             x86_64       2.9.5-4.el9_5.4          baseos        72 k
Installing dependencies:
 gssproxy               x86_64       0.8.4-7.el9              baseos       108 k
 libev                  x86_64       4.33-5.el9.0.1           baseos        51 k
 libnfsidmap            x86_64       1:2.5.4-27.el9           baseos        59 k
 libverto-libev         x86_64       0.3.2-3.el9              baseos        13 k
 rpcbind                x86_64       1.2.6-7.el9              baseos        56 k
 sssd-nfs-idmap         x86_64       2.9.5-4.el9_5.4          baseos        39 k

Transaction Summary
=================================================================================
Install   7 Packages
Upgrade  16 Packages

Total download size: 3.8 M
Downloading Packages:
(1/23): libverto-libev-0.3.2-3.el9.x86_64.rpm    125 kB/s |  13 kB     00:00
(2/23): rpcbind-1.2.6-7.el9.x86_64.rpm           414 kB/s |  56 kB     00:00
(3/23): libev-4.33-5.el9.0.1.x86_64.rpm          364 kB/s |  51 kB     00:00
(4/23): gssproxy-0.8.4-7.el9.x86_64.rpm          334 kB/s | 108 kB     00:00
(5/23): nfs-utils-2.5.4-27.el9.x86_64.rpm        1.0 MB/s | 431 kB     00:00
(6/23): libnfsidmap-2.5.4-27.el9.x86_64.rpm      505 kB/s |  59 kB     00:00
(7/23): sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64.rp  78 kB/s |  39 kB     00:00
(8/23): sssd-proxy-2.9.5-4.el9_5.4.x86_64.rpm    391 kB/s |  72 kB     00:00
(9/23): sssd-krb5-2.9.5-4.el9_5.4.x86_64.rpm     225 kB/s |  72 kB     00:00
(10/23): sssd-ldap-2.9.5-4.el9_5.4.x86_64.rpm    317 kB/s | 159 kB     00:00
(11/23): sssd-krb5-common-2.9.5-4.el9_5.4.x86_64 176 kB/s |  94 kB     00:00
(12/23): sssd-kcm-2.9.5-4.el9_5.4.x86_64.rpm      98 kB/s | 109 kB     00:01
(13/23): sssd-common-pac-2.9.5-4.el9_5.4.x86_64.  89 kB/s |  96 kB     00:01
(14/23): sssd-ipa-2.9.5-4.el9_5.4.x86_64.rpm     191 kB/s | 281 kB     00:01
(15/23): sssd-client-2.9.5-4.el9_5.4.x86_64.rpm  464 kB/s | 161 kB     00:00
(16/23): sssd-2.9.5-4.el9_5.4.x86_64.rpm         224 kB/s |  27 kB     00:00
(17/23): libsss_sudo-2.9.5-4.el9_5.4.x86_64.rpm   87 kB/s |  35 kB     00:00
(18/23): sssd-ad-2.9.5-4.el9_5.4.x86_64.rpm      394 kB/s | 215 kB     00:00
(19/23): libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64  43 kB/s |  45 kB     00:01
(20/23): libsss_idmap-2.9.5-4.el9_5.4.x86_64.rpm  38 kB/s |  41 kB     00:01
(21/23): libsss_certmap-2.9.5-4.el9_5.4.x86_64.r 371 kB/s |  90 kB     00:00
(22/23): libipa_hbac-2.9.5-4.el9_5.4.x86_64.rpm   83 kB/s |  35 kB     00:00
(23/23): sssd-common-2.9.5-4.el9_5.4.x86_64.rpm  585 kB/s | 1.6 MB     00:02
---------------------------------------------------------------------------------
Total                                            694 kB/s | 3.8 MB     00:05
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                         1/1
  Upgrading        : libsss_idmap-2.9.5-4.el9_5.4.x86_64                    1/39
  Upgrading        : libsss_certmap-2.9.5-4.el9_5.4.x86_64                  2/39
  Installing       : libnfsidmap-1:2.5.4-27.el9.x86_64                      3/39
  Installing       : sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64                  4/39
  Upgrading        : libipa_hbac-2.9.5-4.el9_5.4.x86_64                     5/39
  Upgrading        : libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64                6/39
  Upgrading        : sssd-client-2.9.5-4.el9_5.4.x86_64                     7/39
  Running scriptlet: sssd-client-2.9.5-4.el9_5.4.x86_64                     7/39
  Upgrading        : libsss_sudo-2.9.5-4.el9_5.4.x86_64                     8/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.4.x86_64                     9/39
  Upgrading        : sssd-common-2.9.5-4.el9_5.4.x86_64                     9/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.4.x86_64                     9/39
  Upgrading        : sssd-krb5-common-2.9.5-4.el9_5.4.x86_64               10/39
  Upgrading        : sssd-common-pac-2.9.5-4.el9_5.4.x86_64                11/39
  Upgrading        : sssd-ipa-2.9.5-4.el9_5.4.x86_64                       12/39
  Upgrading        : sssd-ad-2.9.5-4.el9_5.4.x86_64                        13/39
  Upgrading        : sssd-ldap-2.9.5-4.el9_5.4.x86_64                      14/39
  Upgrading        : sssd-krb5-2.9.5-4.el9_5.4.x86_64                      15/39
  Upgrading        : sssd-proxy-2.9.5-4.el9_5.4.x86_64                     16/39
  Installing       : libev-4.33-5.el9.0.1.x86_64                           17/39
  Installing       : libverto-libev-0.3.2-3.el9.x86_64                     18/39
  Installing       : gssproxy-0.8.4-7.el9.x86_64                           19/39
  Running scriptlet: gssproxy-0.8.4-7.el9.x86_64                           19/39
  Running scriptlet: rpcbind-1.2.6-7.el9.x86_64                            20/39
  Installing       : rpcbind-1.2.6-7.el9.x86_64                            20/39
  Running scriptlet: rpcbind-1.2.6-7.el9.x86_64                            20/39
Created symlink /etc/systemd/system/multi-user.target.wants/rpcbind.service → /usr/lib/systemd/system/rpcbind.service.
Created symlink /etc/systemd/system/sockets.target.wants/rpcbind.socket → /usr/lib/systemd/system/rpcbind.socket.

  Running scriptlet: nfs-utils-1:2.5.4-27.el9.x86_64                       21/39
  Installing       : nfs-utils-1:2.5.4-27.el9.x86_64                       21/39
  Running scriptlet: nfs-utils-1:2.5.4-27.el9.x86_64                       21/39
  Upgrading        : sssd-2.9.5-4.el9_5.4.x86_64                           22/39
  Upgrading        : sssd-kcm-2.9.5-4.el9_5.4.x86_64                       23/39
  Running scriptlet: sssd-kcm-2.9.5-4.el9_5.4.x86_64                       23/39
  Cleanup          : sssd-2.9.5-4.el9_5.1.x86_64                           24/39
  Cleanup          : sssd-ipa-2.9.5-4.el9_5.1.x86_64                       25/39
  Cleanup          : sssd-ad-2.9.5-4.el9_5.1.x86_64                        26/39
  Cleanup          : sssd-ldap-2.9.5-4.el9_5.1.x86_64                      27/39
  Cleanup          : sssd-proxy-2.9.5-4.el9_5.1.x86_64                     28/39
  Cleanup          : sssd-common-pac-2.9.5-4.el9_5.1.x86_64                29/39
  Cleanup          : sssd-krb5-2.9.5-4.el9_5.1.x86_64                      30/39
  Running scriptlet: sssd-kcm-2.9.5-4.el9_5.1.x86_64                       31/39
  Cleanup          : sssd-kcm-2.9.5-4.el9_5.1.x86_64                       31/39
  Running scriptlet: sssd-kcm-2.9.5-4.el9_5.1.x86_64                       31/39
  Cleanup          : sssd-krb5-common-2.9.5-4.el9_5.1.x86_64               32/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.1.x86_64                    33/39
  Cleanup          : sssd-common-2.9.5-4.el9_5.1.x86_64                    33/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.1.x86_64                    33/39
  Running scriptlet: sssd-client-2.9.5-4.el9_5.1.x86_64                    34/39
  Cleanup          : sssd-client-2.9.5-4.el9_5.1.x86_64                    34/39
  Cleanup          : libsss_idmap-2.9.5-4.el9_5.1.x86_64                   35/39
  Cleanup          : libsss_nss_idmap-2.9.5-4.el9_5.1.x86_64               36/39
  Cleanup          : libsss_sudo-2.9.5-4.el9_5.1.x86_64                    37/39
  Cleanup          : libsss_certmap-2.9.5-4.el9_5.1.x86_64                 38/39
  Cleanup          : libipa_hbac-2.9.5-4.el9_5.1.x86_64                    39/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.4.x86_64                    39/39
  Running scriptlet: libipa_hbac-2.9.5-4.el9_5.1.x86_64                    39/39
  Verifying        : libverto-libev-0.3.2-3.el9.x86_64                      1/39
  Verifying        : rpcbind-1.2.6-7.el9.x86_64                             2/39
  Verifying        : libev-4.33-5.el9.0.1.x86_64                            3/39
  Verifying        : sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64                  4/39
  Verifying        : gssproxy-0.8.4-7.el9.x86_64                            5/39
  Verifying        : nfs-utils-1:2.5.4-27.el9.x86_64                        6/39
  Verifying        : libnfsidmap-1:2.5.4-27.el9.x86_64                      7/39
  Verifying        : sssd-proxy-2.9.5-4.el9_5.4.x86_64                      8/39
  Verifying        : sssd-proxy-2.9.5-4.el9_5.1.x86_64                      9/39
  Verifying        : sssd-ldap-2.9.5-4.el9_5.4.x86_64                      10/39
  Verifying        : sssd-ldap-2.9.5-4.el9_5.1.x86_64                      11/39
  Verifying        : sssd-krb5-common-2.9.5-4.el9_5.4.x86_64               12/39
  Verifying        : sssd-krb5-common-2.9.5-4.el9_5.1.x86_64               13/39
  Verifying        : sssd-krb5-2.9.5-4.el9_5.4.x86_64                      14/39
  Verifying        : sssd-krb5-2.9.5-4.el9_5.1.x86_64                      15/39
  Verifying        : sssd-kcm-2.9.5-4.el9_5.4.x86_64                       16/39
  Verifying        : sssd-kcm-2.9.5-4.el9_5.1.x86_64                       17/39
  Verifying        : sssd-ipa-2.9.5-4.el9_5.4.x86_64                       18/39
  Verifying        : sssd-ipa-2.9.5-4.el9_5.1.x86_64                       19/39
  Verifying        : sssd-common-pac-2.9.5-4.el9_5.4.x86_64                20/39
  Verifying        : sssd-common-pac-2.9.5-4.el9_5.1.x86_64                21/39
  Verifying        : sssd-common-2.9.5-4.el9_5.4.x86_64                    22/39
  Verifying        : sssd-common-2.9.5-4.el9_5.1.x86_64                    23/39
  Verifying        : sssd-client-2.9.5-4.el9_5.4.x86_64                    24/39
  Verifying        : sssd-client-2.9.5-4.el9_5.1.x86_64                    25/39
  Verifying        : sssd-ad-2.9.5-4.el9_5.4.x86_64                        26/39
  Verifying        : sssd-ad-2.9.5-4.el9_5.1.x86_64                        27/39
  Verifying        : sssd-2.9.5-4.el9_5.4.x86_64                           28/39
  Verifying        : sssd-2.9.5-4.el9_5.1.x86_64                           29/39
  Verifying        : libsss_sudo-2.9.5-4.el9_5.4.x86_64                    30/39
  Verifying        : libsss_sudo-2.9.5-4.el9_5.1.x86_64                    31/39
  Verifying        : libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64               32/39
  Verifying        : libsss_nss_idmap-2.9.5-4.el9_5.1.x86_64               33/39
  Verifying        : libsss_idmap-2.9.5-4.el9_5.4.x86_64                   34/39
  Verifying        : libsss_idmap-2.9.5-4.el9_5.1.x86_64                   35/39
  Verifying        : libsss_certmap-2.9.5-4.el9_5.4.x86_64                 36/39
  Verifying        : libsss_certmap-2.9.5-4.el9_5.1.x86_64                 37/39
  Verifying        : libipa_hbac-2.9.5-4.el9_5.4.x86_64                    38/39
  Verifying        : libipa_hbac-2.9.5-4.el9_5.1.x86_64                    39/39

Upgraded:
  libipa_hbac-2.9.5-4.el9_5.4.x86_64    libsss_certmap-2.9.5-4.el9_5.4.x86_64
  libsss_idmap-2.9.5-4.el9_5.4.x86_64   libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64
  libsss_sudo-2.9.5-4.el9_5.4.x86_64    sssd-2.9.5-4.el9_5.4.x86_64
  sssd-ad-2.9.5-4.el9_5.4.x86_64        sssd-client-2.9.5-4.el9_5.4.x86_64
  sssd-common-2.9.5-4.el9_5.4.x86_64    sssd-common-pac-2.9.5-4.el9_5.4.x86_64
  sssd-ipa-2.9.5-4.el9_5.4.x86_64       sssd-kcm-2.9.5-4.el9_5.4.x86_64
  sssd-krb5-2.9.5-4.el9_5.4.x86_64      sssd-krb5-common-2.9.5-4.el9_5.4.x86_64
  sssd-ldap-2.9.5-4.el9_5.4.x86_64      sssd-proxy-2.9.5-4.el9_5.4.x86_64
Installed:
  gssproxy-0.8.4-7.el9.x86_64               libev-4.33-5.el9.0.1.x86_64
  libnfsidmap-1:2.5.4-27.el9.x86_64         libverto-libev-0.3.2-3.el9.x86_64
  nfs-utils-1:2.5.4-27.el9.x86_64           rpcbind-1.2.6-7.el9.x86_64
  sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64

Complete!
[root@k8s-node1 ~]#

[root@k8s-node1 ~]# ls -l /mnt
total 0
drwxr-xr-x  2 root root 24 Feb  4 15:11 data
drwxr-xr-x. 2 root root  6 Dec 30 11:22 hgfs
[root@k8s-node1 ~]# mkdir -p /mnt/nfs
[root@k8s-node1 ~]#
[root@k8s-node1 ~]# mount -t nfs k8s-master1:/data /mnt/nfs
[root@k8s-node1 ~]#
[root@k8s-node1 ~]# df -Th | grep nfs
k8s-master1:/data   nfs4       70G  7.4G   63G  11% /mnt/nfs
[root@k8s-node1 ~]#

[root@k8s-node1 ~]# ls -l /mnt/nfs
total 4
-rw-r--r-- 1 root root 13 Feb  4 15:25 index.html
[root@k8s-node1 ~]#
[root@k8s-node1 ~]# cat /mnt/nfs/index.html
master...CCC
[root@k8s-node1 ~]#
[root@k8s-node1 ~]# umount /mnt/nfs
[root@k8s-node1 ~]#


[root@k8s-node2 ~]# showmount
bash: showmount: command not found...
Packages providing this file are:
'nfs-utils'
'nfs-utils-coreos'
[root@k8s-node2 ~]#
[root@k8s-node2 ~]# yum install nfs-utils -y
Last metadata expiration check: 2:23:20 ago on Tue 04 Feb 2025 01:06:47 PM CST.
Dependencies resolved.
=================================================================================
 Package                Architecture Version                  Repository    Size
=================================================================================
Installing:
 nfs-utils              x86_64       1:2.5.4-27.el9           baseos       431 k
Upgrading:
 libipa_hbac            x86_64       2.9.5-4.el9_5.4          baseos        35 k
 libsss_certmap         x86_64       2.9.5-4.el9_5.4          baseos        90 k
 libsss_idmap           x86_64       2.9.5-4.el9_5.4          baseos        41 k
 libsss_nss_idmap       x86_64       2.9.5-4.el9_5.4          baseos        45 k
 libsss_sudo            x86_64       2.9.5-4.el9_5.4          baseos        35 k
 sssd                   x86_64       2.9.5-4.el9_5.4          baseos        27 k
 sssd-ad                x86_64       2.9.5-4.el9_5.4          baseos       215 k
 sssd-client            x86_64       2.9.5-4.el9_5.4          baseos       161 k
 sssd-common            x86_64       2.9.5-4.el9_5.4          baseos       1.6 M
 sssd-common-pac        x86_64       2.9.5-4.el9_5.4          baseos        96 k
 sssd-ipa               x86_64       2.9.5-4.el9_5.4          baseos       281 k
 sssd-kcm               x86_64       2.9.5-4.el9_5.4          baseos       109 k
 sssd-krb5              x86_64       2.9.5-4.el9_5.4          baseos        72 k
 sssd-krb5-common       x86_64       2.9.5-4.el9_5.4          baseos        94 k
 sssd-ldap              x86_64       2.9.5-4.el9_5.4          baseos       159 k
 sssd-proxy             x86_64       2.9.5-4.el9_5.4          baseos        72 k
Installing dependencies:
 gssproxy               x86_64       0.8.4-7.el9              baseos       108 k
 libev                  x86_64       4.33-5.el9.0.1           baseos        51 k
 libnfsidmap            x86_64       1:2.5.4-27.el9           baseos        59 k
 libverto-libev         x86_64       0.3.2-3.el9              baseos        13 k
 rpcbind                x86_64       1.2.6-7.el9              baseos        56 k
 sssd-nfs-idmap         x86_64       2.9.5-4.el9_5.4          baseos        39 k

Transaction Summary
=================================================================================
Install   7 Packages
Upgrade  16 Packages

Total download size: 3.8 M
Downloading Packages:
(1/23): libverto-libev-0.3.2-3.el9.x86_64.rpm     42 kB/s |  13 kB     00:00
(2/23): rpcbind-1.2.6-7.el9.x86_64.rpm           161 kB/s |  56 kB     00:00
(3/23): libev-4.33-5.el9.0.1.x86_64.rpm          163 kB/s |  51 kB     00:00
(4/23): sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64.rp  51 kB/s |  39 kB     00:00
(5/23): gssproxy-0.8.4-7.el9.x86_64.rpm          135 kB/s | 108 kB     00:00
(6/23): sssd-proxy-2.9.5-4.el9_5.4.x86_64.rpm    282 kB/s |  72 kB     00:00
(7/23): libnfsidmap-2.5.4-27.el9.x86_64.rpm      177 kB/s |  59 kB     00:00
(8/23): nfs-utils-2.5.4-27.el9.x86_64.rpm        385 kB/s | 431 kB     00:01
(9/23): sssd-krb5-common-2.9.5-4.el9_5.4.x86_64. 308 kB/s |  94 kB     00:00
(10/23): sssd-krb5-2.9.5-4.el9_5.4.x86_64.rpm    245 kB/s |  72 kB     00:00
(11/23): sssd-ldap-2.9.5-4.el9_5.4.x86_64.rpm    272 kB/s | 159 kB     00:00
(12/23): sssd-common-pac-2.9.5-4.el9_5.4.x86_64. 488 kB/s |  96 kB     00:00
(13/23): sssd-kcm-2.9.5-4.el9_5.4.x86_64.rpm     140 kB/s | 109 kB     00:00
(14/23): sssd-ipa-2.9.5-4.el9_5.4.x86_64.rpm     284 kB/s | 281 kB     00:00
(15/23): sssd-ad-2.9.5-4.el9_5.4.x86_64.rpm      591 kB/s | 215 kB     00:00
(16/23): sssd-2.9.5-4.el9_5.4.x86_64.rpm         121 kB/s |  27 kB     00:00
(17/23): sssd-client-2.9.5-4.el9_5.4.x86_64.rpm  186 kB/s | 161 kB     00:00
(18/23): libsss_sudo-2.9.5-4.el9_5.4.x86_64.rpm   33 kB/s |  35 kB     00:01
(19/23): libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64  43 kB/s |  45 kB     00:01
(20/23): libsss_idmap-2.9.5-4.el9_5.4.x86_64.rpm  69 kB/s |  41 kB     00:00
(21/23): libsss_certmap-2.9.5-4.el9_5.4.x86_64.r 142 kB/s |  90 kB     00:00
(22/23): libipa_hbac-2.9.5-4.el9_5.4.x86_64.rpm   98 kB/s |  35 kB     00:00
(23/23): sssd-common-2.9.5-4.el9_5.4.x86_64.rpm  338 kB/s | 1.6 MB     00:04
---------------------------------------------------------------------------------
Total                                            503 kB/s | 3.8 MB     00:07
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                         1/1
  Upgrading        : libsss_idmap-2.9.5-4.el9_5.4.x86_64                    1/39
  Upgrading        : libsss_certmap-2.9.5-4.el9_5.4.x86_64                  2/39
  Installing       : libnfsidmap-1:2.5.4-27.el9.x86_64                      3/39
  Installing       : sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64                  4/39
  Upgrading        : libipa_hbac-2.9.5-4.el9_5.4.x86_64                     5/39
  Upgrading        : libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64                6/39
  Upgrading        : sssd-client-2.9.5-4.el9_5.4.x86_64                     7/39
  Running scriptlet: sssd-client-2.9.5-4.el9_5.4.x86_64                     7/39
  Upgrading        : libsss_sudo-2.9.5-4.el9_5.4.x86_64                     8/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.4.x86_64                     9/39
  Upgrading        : sssd-common-2.9.5-4.el9_5.4.x86_64                     9/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.4.x86_64                     9/39
  Upgrading        : sssd-krb5-common-2.9.5-4.el9_5.4.x86_64               10/39
  Upgrading        : sssd-common-pac-2.9.5-4.el9_5.4.x86_64                11/39
  Upgrading        : sssd-ipa-2.9.5-4.el9_5.4.x86_64                       12/39
  Upgrading        : sssd-ad-2.9.5-4.el9_5.4.x86_64                        13/39
  Upgrading        : sssd-ldap-2.9.5-4.el9_5.4.x86_64                      14/39
  Upgrading        : sssd-krb5-2.9.5-4.el9_5.4.x86_64                      15/39
  Upgrading        : sssd-proxy-2.9.5-4.el9_5.4.x86_64                     16/39
  Installing       : libev-4.33-5.el9.0.1.x86_64                           17/39
  Installing       : libverto-libev-0.3.2-3.el9.x86_64                     18/39
  Installing       : gssproxy-0.8.4-7.el9.x86_64                           19/39
  Running scriptlet: gssproxy-0.8.4-7.el9.x86_64                           19/39
  Running scriptlet: rpcbind-1.2.6-7.el9.x86_64                            20/39
  Installing       : rpcbind-1.2.6-7.el9.x86_64                            20/39
  Running scriptlet: rpcbind-1.2.6-7.el9.x86_64                            20/39
Created symlink /etc/systemd/system/multi-user.target.wants/rpcbind.service → /usr/lib/systemd/system/rpcbind.service.
Created symlink /etc/systemd/system/sockets.target.wants/rpcbind.socket → /usr/lib/systemd/system/rpcbind.socket.

  Running scriptlet: nfs-utils-1:2.5.4-27.el9.x86_64                       21/39
  Installing       : nfs-utils-1:2.5.4-27.el9.x86_64                       21/39
  Running scriptlet: nfs-utils-1:2.5.4-27.el9.x86_64                       21/39
  Upgrading        : sssd-2.9.5-4.el9_5.4.x86_64                           22/39
  Upgrading        : sssd-kcm-2.9.5-4.el9_5.4.x86_64                       23/39
  Running scriptlet: sssd-kcm-2.9.5-4.el9_5.4.x86_64                       23/39
  Cleanup          : sssd-2.9.5-4.el9_5.1.x86_64                           24/39
  Cleanup          : sssd-ipa-2.9.5-4.el9_5.1.x86_64                       25/39
  Cleanup          : sssd-ad-2.9.5-4.el9_5.1.x86_64                        26/39
  Cleanup          : sssd-ldap-2.9.5-4.el9_5.1.x86_64                      27/39
  Cleanup          : sssd-proxy-2.9.5-4.el9_5.1.x86_64                     28/39
  Cleanup          : sssd-common-pac-2.9.5-4.el9_5.1.x86_64                29/39
  Cleanup          : sssd-krb5-2.9.5-4.el9_5.1.x86_64                      30/39
  Running scriptlet: sssd-kcm-2.9.5-4.el9_5.1.x86_64                       31/39
  Cleanup          : sssd-kcm-2.9.5-4.el9_5.1.x86_64                       31/39
  Running scriptlet: sssd-kcm-2.9.5-4.el9_5.1.x86_64                       31/39
  Cleanup          : sssd-krb5-common-2.9.5-4.el9_5.1.x86_64               32/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.1.x86_64                    33/39
  Cleanup          : sssd-common-2.9.5-4.el9_5.1.x86_64                    33/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.1.x86_64                    33/39
  Running scriptlet: sssd-client-2.9.5-4.el9_5.1.x86_64                    34/39
  Cleanup          : sssd-client-2.9.5-4.el9_5.1.x86_64                    34/39
  Cleanup          : libsss_idmap-2.9.5-4.el9_5.1.x86_64                   35/39
  Cleanup          : libsss_nss_idmap-2.9.5-4.el9_5.1.x86_64               36/39
  Cleanup          : libsss_sudo-2.9.5-4.el9_5.1.x86_64                    37/39
  Cleanup          : libsss_certmap-2.9.5-4.el9_5.1.x86_64                 38/39
  Cleanup          : libipa_hbac-2.9.5-4.el9_5.1.x86_64                    39/39
  Running scriptlet: sssd-common-2.9.5-4.el9_5.4.x86_64                    39/39
  Running scriptlet: libipa_hbac-2.9.5-4.el9_5.1.x86_64                    39/39
  Verifying        : libverto-libev-0.3.2-3.el9.x86_64                      1/39
  Verifying        : rpcbind-1.2.6-7.el9.x86_64                             2/39
  Verifying        : libev-4.33-5.el9.0.1.x86_64                            3/39
  Verifying        : sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64                  4/39
  Verifying        : gssproxy-0.8.4-7.el9.x86_64                            5/39
  Verifying        : nfs-utils-1:2.5.4-27.el9.x86_64                        6/39
  Verifying        : libnfsidmap-1:2.5.4-27.el9.x86_64                      7/39
  Verifying        : sssd-proxy-2.9.5-4.el9_5.4.x86_64                      8/39
  Verifying        : sssd-proxy-2.9.5-4.el9_5.1.x86_64                      9/39
  Verifying        : sssd-ldap-2.9.5-4.el9_5.4.x86_64                      10/39
  Verifying        : sssd-ldap-2.9.5-4.el9_5.1.x86_64                      11/39
  Verifying        : sssd-krb5-common-2.9.5-4.el9_5.4.x86_64               12/39
  Verifying        : sssd-krb5-common-2.9.5-4.el9_5.1.x86_64               13/39
  Verifying        : sssd-krb5-2.9.5-4.el9_5.4.x86_64                      14/39
  Verifying        : sssd-krb5-2.9.5-4.el9_5.1.x86_64                      15/39
  Verifying        : sssd-kcm-2.9.5-4.el9_5.4.x86_64                       16/39
  Verifying        : sssd-kcm-2.9.5-4.el9_5.1.x86_64                       17/39
  Verifying        : sssd-ipa-2.9.5-4.el9_5.4.x86_64                       18/39
  Verifying        : sssd-ipa-2.9.5-4.el9_5.1.x86_64                       19/39
  Verifying        : sssd-common-pac-2.9.5-4.el9_5.4.x86_64                20/39
  Verifying        : sssd-common-pac-2.9.5-4.el9_5.1.x86_64                21/39
  Verifying        : sssd-common-2.9.5-4.el9_5.4.x86_64                    22/39
  Verifying        : sssd-common-2.9.5-4.el9_5.1.x86_64                    23/39
  Verifying        : sssd-client-2.9.5-4.el9_5.4.x86_64                    24/39
  Verifying        : sssd-client-2.9.5-4.el9_5.1.x86_64                    25/39
  Verifying        : sssd-ad-2.9.5-4.el9_5.4.x86_64                        26/39
  Verifying        : sssd-ad-2.9.5-4.el9_5.1.x86_64                        27/39
  Verifying        : sssd-2.9.5-4.el9_5.4.x86_64                           28/39
  Verifying        : sssd-2.9.5-4.el9_5.1.x86_64                           29/39
  Verifying        : libsss_sudo-2.9.5-4.el9_5.4.x86_64                    30/39
  Verifying        : libsss_sudo-2.9.5-4.el9_5.1.x86_64                    31/39
  Verifying        : libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64               32/39
  Verifying        : libsss_nss_idmap-2.9.5-4.el9_5.1.x86_64               33/39
  Verifying        : libsss_idmap-2.9.5-4.el9_5.4.x86_64                   34/39
  Verifying        : libsss_idmap-2.9.5-4.el9_5.1.x86_64                   35/39
  Verifying        : libsss_certmap-2.9.5-4.el9_5.4.x86_64                 36/39
  Verifying        : libsss_certmap-2.9.5-4.el9_5.1.x86_64                 37/39
  Verifying        : libipa_hbac-2.9.5-4.el9_5.4.x86_64                    38/39
  Verifying        : libipa_hbac-2.9.5-4.el9_5.1.x86_64                    39/39

Upgraded:
  libipa_hbac-2.9.5-4.el9_5.4.x86_64    libsss_certmap-2.9.5-4.el9_5.4.x86_64
  libsss_idmap-2.9.5-4.el9_5.4.x86_64   libsss_nss_idmap-2.9.5-4.el9_5.4.x86_64
  libsss_sudo-2.9.5-4.el9_5.4.x86_64    sssd-2.9.5-4.el9_5.4.x86_64
  sssd-ad-2.9.5-4.el9_5.4.x86_64        sssd-client-2.9.5-4.el9_5.4.x86_64
  sssd-common-2.9.5-4.el9_5.4.x86_64    sssd-common-pac-2.9.5-4.el9_5.4.x86_64
  sssd-ipa-2.9.5-4.el9_5.4.x86_64       sssd-kcm-2.9.5-4.el9_5.4.x86_64
  sssd-krb5-2.9.5-4.el9_5.4.x86_64      sssd-krb5-common-2.9.5-4.el9_5.4.x86_64
  sssd-ldap-2.9.5-4.el9_5.4.x86_64      sssd-proxy-2.9.5-4.el9_5.4.x86_64
Installed:
  gssproxy-0.8.4-7.el9.x86_64               libev-4.33-5.el9.0.1.x86_64
  libnfsidmap-1:2.5.4-27.el9.x86_64         libverto-libev-0.3.2-3.el9.x86_64
  nfs-utils-1:2.5.4-27.el9.x86_64           rpcbind-1.2.6-7.el9.x86_64
  sssd-nfs-idmap-2.9.5-4.el9_5.4.x86_64

Complete!
[root@k8s-node2 ~]#

[root@k8s-node2 ~]# ls -l /mnt
total 0
drwxr-xr-x  2 root root 24 Feb  4 15:12 data
drwxr-xr-x. 2 root root  6 Dec 30 11:22 hgfs
[root@k8s-node2 ~]#
[root@k8s-node2 ~]# mkdir -p /mnt/nfs
[root@k8s-node2 ~]#
[root@k8s-node2 ~]# mount -t nfs k8s-master1:/data /mnt/nfs
[root@k8s-node2 ~]#
[root@k8s-node2 ~]# df -Th | grep nfs
k8s-master1:/data   nfs4       70G  7.4G   63G  11% /mnt/nfs
[root@k8s-node2 ~]#
[root@k8s-node2 ~]# ls -l /mnt/nfs
total 4
-rw-r--r-- 1 root root 13 Feb  4 15:25 index.html
[root@k8s-node2 ~]#
[root@k8s-node2 ~]# cat /mnt/nfs/index.html
master...CCC
[root@k8s-node2 ~]#
[root@k8s-node2 ~]# umount /mnt/nfs
[root@k8s-node2 ~]#

[root@k8s-master1 ~]# wget http://10.0.1.248/k8s/yaml/pv2-nfs.yaml
--2025-02-04 15:32:42--  http://192.168.66.248/k8s/yaml/pv2-nfs.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 314
Saving to: ‘pv2-nfs.yaml’

pv2-nfs.yaml         100%[===================>]     314  --.-KB/s    in 0s

2025-02-04 15:32:42 (39.6 MB/s) - ‘pv2-nfs.yaml’ saved [314/314]

[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv1-local   10Gi       RWO            Retain           Bound    default/pvc1-local   manual         <unset>                          19m
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl apply -f pv2-nfs.yaml
persistentvolume/pv2-nfs created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv1-local   10Gi       RWO            Retain           Bound       default/pvc1-local   manual         <unset>                          19m
pv2-nfs     10Gi       RWO            Retain           Available                        manual         <unset>                          3s
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# wget http://10.0.1.248/k8s/yaml/pvc2-nfs.yaml
--2025-02-04 15:34:09--  http://192.168.66.248/k8s/yaml/pvc2-nfs.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 184
Saving to: ‘pvc2-nfs.yaml’

pvc2-nfs.yaml        100%[===================>]     184  --.-KB/s    in 0s

2025-02-04 15:34:09 (9.99 MB/s) - ‘pvc2-nfs.yaml’ saved [184/184]

[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv1-local   10Gi       RWO            Retain           Bound       default/pvc1-local   manual         <unset>                          20m
pv2-nfs     10Gi       RWO            Retain           Available                        manual         <unset>                          78s
[root@k8s-master1 ~]# kubectl get pvc
NAME         STATUS   VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
pvc1-local   Bound    pv1-local   10Gi       RWO            manual         <unset>                 19m
[root@k8s-master1 ~]# kubectl apply -f pvc2-nfs.yaml
persistentvolumeclaim/pvc2-nfs created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pv1-local   10Gi       RWO            Retain           Bound    default/pvc1-local   manual         <unset>                          20m
pv2-nfs     10Gi       RWO            Retain           Bound    default/pvc2-nfs     manual         <unset>                          91s
[root@k8s-master1 ~]# kubectl get pvc
NAME         STATUS   VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
pvc1-local   Bound    pv1-local   10Gi       RWO            manual         <unset>                 19m
pvc2-nfs     Bound    pv2-nfs     10Gi       RWO            manual         <unset>                 5s
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# wget http://10.0.1.248/k8s/yaml/pv2-pod-nfs.yaml
--2025-02-04 15:35:32--  http://192.168.66.248/k8s/yaml/pv2-pod-nfs.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 434
Saving to: ‘pv2-pod-nfs.yaml’

pv2-pod-nfs.yaml     100%[===================>]     434  --.-KB/s    in 0s

2025-02-04 15:35:32 (48.8 MB/s) - ‘pv2-pod-nfs.yaml’ saved [434/434]

[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl apply -f pv2-pod-nfs.yaml
pod/pv2-pod-nfs created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pods
NAME            READY   STATUS    RESTARTS   AGE
pv1-pod-local   1/1     Running   0          19m
pv2-pod-nfs     1/1     Running   0          13s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pods -o wide
NAME            READY   STATUS    RESTARTS   AGE   IP            NODE                     NOMINATED NODE   READINESS GATES
pv1-pod-local   1/1     Running   0          19m   10.128.1.17   k8s-node1.training.lab   <none>           <none>
pv2-pod-nfs     1/1     Running   0          18s   10.128.1.18   k8s-node1.training.lab   <none>           <none>
[root@k8s-master1 ~]# curl 10.128.1.18
master...CCC
[root@k8s-master1 ~]#

##########################
# secret
##########################

[root@k8s-master1 ~]# echo -n "root" > ./username.txt
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# echo -n "pass1234" > ./password.txt
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# ls -l username.txt
-rw-r--r-- 1 root root 4 Feb  4 15:38 username.txt
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# ls -l password.txt
-rw-r--r-- 1 root root 8 Feb  4 15:38 password.txt
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# cat username.txt
root[root@k8s-master1 ~]#
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# cat password.txt
pass1234[root@k8s-master1 ~]#
[root@k8s-master1 ~]#
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl create secret generic demo-secret-from-file \
--from-file=./username.txt \
--from-file=./password.txt
secret/demo-secret-from-file created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get secrets
NAME                    TYPE     DATA   AGE
demo-secret-from-file   Opaque   2      7s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl describe secrets demo-secret-from-file
Name:         demo-secret-from-file
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
password.txt:  8 bytes
username.txt:  4 bytes
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl create secret generic demo-secret-from-literal \
--from-literal=username=root \
--from-literal=password=pass1234
secret/demo-secret-from-literal created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get secrets
NAME                       TYPE     DATA   AGE
demo-secret-from-file      Opaque   2      84s
demo-secret-from-literal   Opaque   2      5s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl describe secrets demo-secret-from-literal
Name:         demo-secret-from-literal
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
password:  8 bytes
username:  4 bytes
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# echo -n "root" | base64
cm9vdA==
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# echo -n "pass1234" | base64
cGFzczEyMzQ=
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# wget http://10.0.1.248/k8s/yaml/my-secret.yaml
--2025-02-04 15:42:03--  http://10.0.1.248/k8s/yaml/my-secret.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 133
Saving to: ‘my-secret.yaml’

my-secret.yaml       100%[===================>]     133  --.-KB/s    in 0s

2025-02-04 15:42:03 (11.6 MB/s) - ‘my-secret.yaml’ saved [133/133]

[root@k8s-master1 ~]# cat my-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: demo-secret-from-yaml
type: Opaque
data:
  username: cm9vdA==
  password: cGFzczEyMzQ=
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl apply -f my-secret.yaml
secret/demo-secret-from-yaml created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get secrets
NAME                       TYPE     DATA   AGE
demo-secret-from-file      Opaque   2      3m32s
demo-secret-from-literal   Opaque   2      2m13s
demo-secret-from-yaml      Opaque   2      5s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl describe secrets demo-secret-from-yaml
Name:         demo-secret-from-yaml
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
username:  4 bytes
password:  8 bytes
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# wget http://10.0.1.248/k8s/yaml/my-pod.yaml
--2025-02-04 15:43:51--  http://10.0.1.248/k8s/yaml/my-pod.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 481
Saving to: ‘my-pod.yaml’

my-pod.yaml          100%[===================>]     481  --.-KB/s    in 0s

2025-02-04 15:43:51 (33.6 MB/s) - ‘my-pod.yaml’ saved [481/481]

[root@k8s-master1 ~]#
[root@k8s-master1 ~]# ls -l my-pod.yaml
-rw-r--r-- 1 root root 481 Jan 23 15:42 my-pod.yaml
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl apply -f my-pod.yaml
pod/my-pod created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pods
NAME     READY   STATUS    RESTARTS   AGE
my-pod   1/1     Running   0          16s
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl exec my-pod -it -- bash
root@my-pod:/#
root@my-pod:/# env | grep SEC
SECRET_USERNAME=root
SECRET_PASSWORD=pass1234
root@my-pod:/#
root@my-pod:/# exit
exit
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# wget http://192.168.66.248/k8s/yaml/my-pod-with-mounting-secret.yaml
--2025-02-04 16:06:29--  http://192.168.66.248/k8s/yaml/my-pod-with-mounting-secret.yaml
Connecting to 192.168.66.248:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 421
Saving to: ‘my-pod-with-mounting-secret.yaml’

my-pod-with-mounting 100%[===================>]     421  --.-KB/s    in 0s

2025-02-04 16:06:29 (32.5 MB/s) - ‘my-pod-with-mounting-secret.yaml’ saved [421/421]

[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl apply -f my-pod-with-mounting-secret.yaml
pod/my-pod-with-mounting-secret created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pods
NAME                          READY   STATUS    RESTARTS   AGE
my-pod                        1/1     Running   0          22m
my-pod-with-mounting-secret   1/1     Running   0          7s
[root@k8s-master1 ~]#

[root@k8s-master1 ~]# kubectl exec my-pod-with-mounting-secret -it -- bash
root@my-pod-with-mounting-secret:/#
root@my-pod-with-mounting-secret:/# env | grep SEC
root@my-pod-with-mounting-secret:/#
root@my-pod-with-mounting-secret:/# ls -l /etc/creds
total 0
lrwxrwxrwx 1 root root 15 Feb  4 08:06 password -> ..data/password
lrwxrwxrwx 1 root root 15 Feb  4 08:06 username -> ..data/username
root@my-pod-with-mounting-secret:/#
root@my-pod-with-mounting-secret:/# cat /etc/creds/username
rootroot@my-pod-with-mounting-secret:/#
root@my-pod-with-mounting-secret:/#
root@my-pod-with-mounting-secret:/# cat /etc/creds/password
pass1234root@my-pod-with-mounting-secret:/#
root@my-pod-with-mounting-secret:/#
root@my-pod-with-mounting-secret:/# exit
exit
[root@k8s-master1 ~]#

##########################
# RBAC - Role Base Access Control
##########################

[root@k8s-master1 ~]# kubectl apply -f http://192.168.66.248/k8s/yaml/rbac3.yaml
clusterrolebinding.rbac.authorization.k8s.io/my-global-access created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get clusterrolebindings.rbac.authorization.k8s.io | grep my-global
my-global-access                                                ClusterRole/view                                                                   21s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl delete -f http://192.168.66.248/k8s/yaml/rbac3.yamlclusterrolebinding.rbac.authorization.k8s.io "my-global-access" deleted
[root@k8s-master1 ~]#

##########################
# event/log
##########################

[root@k8s-master1 ~]# kubectl apply -f http://192.168.66.248/k8s/yaml/log1.yaml
pod/log1 created
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get pods
NAME   READY   STATUS    RESTARTS   AGE
log1   1/1     Running   0          5s
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl get events
LAST SEEN   TYPE     REASON      OBJECT                            MESSAGE
13s         Normal   Scheduled   pod/log1                          Successfully assigned default/log1 to k8s-node1.training.lab
13s         Normal   Pulling     pod/log1                          Pulling image "docker1.training.lab:5000/nginx"
13s         Normal   Pulled      pod/log1                          Successfully pulled image "docker1.training.lab:5000/nginx" in 177ms (177ms including waiting). Image size: 137329783 bytes.
13s         Normal   Created     pod/log1                          Created container: count
13s         Normal   Started     pod/log1                          Started container count
11m         Normal   Scheduled   pod/my-pod-with-mounting-secret   Successfully assigned default/my-pod-with-mounting-secret to k8s-node1.training.lab
11m         Normal   Pulling     pod/my-pod-with-mounting-secret   Pulling image "docker1.training.lab:5000/nginx"
11m         Normal   Pulled      pod/my-pod-with-mounting-secret   Successfully pulled image "docker1.training.lab:5000/nginx" in 127ms (127ms including waiting). Image size: 137329783 bytes.
11m         Normal   Created     pod/my-pod-with-mounting-secret   Created container: demo-pod
11m         Normal   Started     pod/my-pod-with-mounting-secret   Started container demo-pod
37s         Normal   Killing     pod/my-pod-with-mounting-secret   Stopping container demo-pod
33m         Normal   Scheduled   pod/my-pod                        Successfully assigned default/my-pod to k8s-node1.training.lab
33m         Normal   Pulling     pod/my-pod                        Pulling image "docker1.training.lab:5000/nginx"
33m         Normal   Pulled      pod/my-pod                        Successfully pulled image "docker1.training.lab:5000/nginx" in 114ms (114ms including waiting). Image size: 137329783 bytes.
33m         Normal   Created     pod/my-pod                        Created container: demo-pod
33m         Normal   Started     pod/my-pod                        Started container demo-pod
37s         Normal   Killing     pod/my-pod                        Stopping container demo-pod
40m         Normal   Killing     pod/pv1-pod-local                 Stopping container task-pv-container
42m         Normal   Scheduled   pod/pv2-pod-nfs                   Successfully assigned default/pv2-pod-nfs to k8s-node1.training.lab
41m         Normal   Pulling     pod/pv2-pod-nfs                   Pulling image "docker1.training.lab:5000/nginx"
41m         Normal   Pulled      pod/pv2-pod-nfs                   Successfully pulled image "docker1.training.lab:5000/nginx" in 92ms (92ms including waiting). Image size: 137329783 bytes.
41m         Normal   Created     pod/pv2-pod-nfs                   Created container: pv2-nfs-container
41m         Normal   Started     pod/pv2-pod-nfs                   Started container pv2-nfs-container
40m         Normal   Killing     pod/pv2-pod-nfs                   Stopping container pv2-nfs-container
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl logs pod/log1
0: Tue Feb  4 08:17:29 UTC 2025
1: Tue Feb  4 08:17:30 UTC 2025
2: Tue Feb  4 08:17:31 UTC 2025
3: Tue Feb  4 08:17:32 UTC 2025
4: Tue Feb  4 08:17:33 UTC 2025
5: Tue Feb  4 08:17:34 UTC 2025
6: Tue Feb  4 08:17:35 UTC 2025
7: Tue Feb  4 08:17:36 UTC 2025
8: Tue Feb  4 08:17:37 UTC 2025
9: Tue Feb  4 08:17:38 UTC 2025
10: Tue Feb  4 08:17:39 UTC 2025
11: Tue Feb  4 08:17:40 UTC 2025
12: Tue Feb  4 08:17:41 UTC 2025
13: Tue Feb  4 08:17:42 UTC 2025
14: Tue Feb  4 08:17:43 UTC 2025
15: Tue Feb  4 08:17:44 UTC 2025
16: Tue Feb  4 08:17:45 UTC 2025
17: Tue Feb  4 08:17:46 UTC 2025
18: Tue Feb  4 08:17:47 UTC 2025
19: Tue Feb  4 08:17:48 UTC 2025
20: Tue Feb  4 08:17:49 UTC 2025
21: Tue Feb  4 08:17:50 UTC 2025
22: Tue Feb  4 08:17:51 UTC 2025
23: Tue Feb  4 08:17:52 UTC 2025
[root@k8s-master1 ~]#
[root@k8s-master1 ~]# kubectl delete -f http://192.168.66.248/k8s/yaml/log1.yaml
pod "log1" deleted
[root@k8s-master1 ~]#



##############################
#
# 以下為 CentOS 7 版本
#
##############################

[root@minikube ~]# crontab -e
no crontab for root - using an empty one
crontab: installing new crontab
[root@minikube ~]# crontab -l
* * * * * /usr/sbin/ntpdate -b -u time.stdtime.gov.tw > /dev/null 2>&1

[root@minikube ~]# vi /etc/docker/daemon.json
[root@minikube ~]# cat /etc/docker/daemon.json
{
  "live-restore": true,
  "group": "dockerroot",
  "insecure-registries": ["10.0.1.249:5000","192.168.66.21:5000","docker.training.lab:5000"]
}
[root@minikube ~]# systemctl restart docker


[root@minikube ~]# ls -l /etc/containers/registries.conf
-rw-r--r-- 1 root root 5866 Jul  1  2020 /etc/containers/registries.conf
[root@minikube ~]# vi /etc/containers/registries.conf
[root@minikube ~]# grep -n '^regis' /etc/containers/registries.conf
35:registries = ['registry.access.redhat.com', 'registry.redhat.io', 'docker.io']
49:registries = ['192.168.66.21:5000', 'docker.training.lab:5000', '10.0.1.249:5000']
59:registries = []
[root@minikube ~]# systemctl restart crio


[root@minikube ~]# kubectl create deployment test2 --image=docker.training.lab:5000/httpd
deployment.apps/test2 created
[root@minikube ~]#
[root@minikube ~]# kubectl get deployments.apps test2
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
test2   0/1     1            0           12s
[root@minikube ~]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
test2-5c98b849c4-7mlpb   1/1     Running   0          21s
[root@minikube ~]# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP          NODE                    NOMINATED NODE   READINESS GATES
test2-5c98b849c4-7mlpb   1/1     Running   0          26s   10.85.0.3   minikube.training.lab   <none>           <none>
[root@minikube ~]# curl 10.85.0.3
<html><body><h1>It works!</h1></body></html>




docker run -itd --name mysql-2 -e MYSQL_ROOT_PASSWORD=container mysql

docker inspect -f '{{ .NetworkSettings.IPAddress }}' mysql-2

docker run -it --name mysql-3 -e MYSQL_ROOT_PASSWORD=container mysql /bin/bash

docker run -itd --name db1 -p 3306:3306 -v /docker_data/db1:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=container 192.168.66.21:5000/mariadb:v1

docker run -it --name wordpress -p 80:80 --link db1:mysql -v /docker_data/wordpress:/var/www/html -e WORDPRESS_DB_NAME=wp -e WORDPRESS_DB_USER=root -e WORDPRESS_DB_PASSWORD=container -e ServerName=localhost -d 192.168.66.21:5000/wordpress:v1

cat dockerfile

FROM 192.168.66.21:5000/alpine:v1
RUN apk add --no-cache --update-cache bash
CMD ["/bin/bash"]



[root@minikube ~]# cat <<EOF > /etc/yum.repos.d/kubernetes.repo
> [kubernetes]
> name=Kubernetes
> baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
> enabled=1
> gpgcheck=1
> repo_gpgcheck=1
> gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
> https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
> EOF


echo "source <(kubectl completion bash)" >> ~/.bashrc


###wget http://rh7lab.uuu.com.tw/download/Docker/docker-machine-driver-kvm2
wget https://rh8ex294.uuu.com.tw/download/Docker/docker-machine-driver-kvm2


###wget http://rh7lab.uuu.com.tw/download/Docker/minikube-linux-amd64
wget https://rh8ex294.uuu.com.tw/download/Docker/minikube-linux-amd64


[root@minikube ~]# kubectl run hello-minikube \
> --image=gcr.io/google_containers/echoserver:1.4 --port=8080


curl $(minikube service hello-minikube --url)


sed -i 's/^\/dev\/mapper\/centos-swap/#&/g' /etc/fstab


sshpass -p container ssh -p 22 root@node1 "sed -i 's/^\/dev\/mapper\/centos-swap/#&/g' /etc/fstab"


[root@master ~]# cat <<EOF > /etc/sysctl.d/k8s.conf
> net.bridge.bridge-nf-call-ip6tables = 1
> net.bridge.bridge-nf-call-iptables = 1
> EOF



[root@master ~]# cat <<EOF > /etc/yum.repos.d/kubernetes.repo
> [kubernetes]
> name=Kubernetes
> baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
> enabled=1
> gpgcheck=1
> repo_gpgcheck=1
> gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
> https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
> exclude=kube*
> EOF



[root@master ~]# kubeadm init --service-cidr 10.96.0.0/12 \
> --pod-network-cidr 172.16.0.0/16 \
> --apiserver-advertise-address 0.0.0.0


[root@master ~]# SHA256=$(openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt |
openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | awk
'{ print $2}')


TOKEN=$(kubeadm token list | tail -n +2 | awk '{ print $1 }')


[root@master ~]# sshpass -p container ssh -p 22 root@node2 "kubeadm join
192.168.66.10:6443 --token $TOKEN --discovery-token-ca-cert-hash
sha256:$SHA256"



#### [root@master ~]# wget http://rh7lab.uuu.com.tw/download/Docker/kubeflannel.yml
[root@master ~]# wget https://rh8ex294.uuu.com.tw/download/Docker/kubeflannel.yml




kubectl run nginx --image=nginx --replicas=3





while true; do for i in $(kubectl get pods | tail -n +2 | awk '{ print $1 }'); do kubectl get pod ${i} -o yaml | grep "image: nginx"; done; echo; kubectl get deployments -o wide; echo; sleep 1; done


kubectl set image deployment nginx nginx=nginx:1.9.1 --record


source <(kubectl completion bash)



https://kubernetes.io/docs/concepts/workloads/controllers/deployment/



wget https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/controllers/nginx-deployment.yaml



[root@master ~]# cat rbac3.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: my-global-access
subjects:
- kind: User
  name: qoo
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: view
  apiGroup: rbac.authorization.k8s.io




[root@master ~]# cat log1.yaml
apiVersion: v1
kind: Pod
metadata:
  name: log1
spec:
  containers:
  - name: count
    image: busybox
    args: [/bin/sh, -c,
      'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done']



kubectl create configmap mydb-env --from-literal=MYSQL_ROOT_PASSWORD=container --from-literal=TZ="Asia/Taipei"


kubectl create secret generic mysql-pass --from-literal=password=container


http://10.0.1.99/FTPRoot/Docker/yaml/volumes.yaml


http://10.0.1.99/FTPRoot/Docker/yaml/mysql-deployment.yaml


http://10.0.1.99/FTPRoot/Docker/yaml/wordpress-deployment.yaml




kubectl run docker-python-flask-demo --image=docker.io/kdchang/docker-python-flask-demo:v1 --port 3000


docker pull kdchang/docker-python-flask-demo:v1


kubectl expose deployment/docker-python-flask-demo --type="NodePort" --port 3000




wget https://s3.eu-central-1.amazonaws.com/heptio-edustatic/foundations/gowebapp.tar.gz



docker run --name gowebapp-mysql --hostname gowebapp-mysql -d -e MYSQL_ROOT_PASSWORD=container gowebapp-mysql:v1


docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry --restart=always --name registry registry



firefox http://localhost:8001/api/v1/namespaces/kubernetesdashboard/services/https:kubernetes-dashboard:/proxy/


kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath="{.secrets[0].name}") -o go-template="{{.data.token | base64decode}}"



kubectl taint node master.training.lab node-role.kubernetes.io/master:NoSchedule-

kubectl taint node master.training.lab node-role.kubernetes.io/master:NoSchedule

kubectl apply -f https://github.com/antrea-io/antrea/releases/download/v1.1.0/antrea.yml

kubectl taint node minikube.training.lab node-role.kubernetes.io/control-plane:NoSchedule-

kubectl taint node minikube.training.lab node-role.kubernetes.io/master:NoSchedule-


docker-ce
systemctl stop docker

yum remove docker* -y

yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

[root@docker ~]# cat /etc/yum.repos.d/docker-ce.repo
[docker-ce-stable]
name=Docker CE Stable - $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/stable
enabled=1
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-stable-debuginfo]
name=Docker CE Stable - Debuginfo $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/stable
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-stable-source]
name=Docker CE Stable - Sources
baseurl=https://download.docker.com/linux/centos/$releasever/source/stable
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-test]
name=Docker CE Test - $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/test
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-test-debuginfo]
name=Docker CE Test - Debuginfo $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/test
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-test-source]
name=Docker CE Test - Sources
baseurl=https://download.docker.com/linux/centos/$releasever/source/test
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-nightly]
name=Docker CE Nightly - $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/nightly
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-nightly-debuginfo]
name=Docker CE Nightly - Debuginfo $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/nightly
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-nightly-source]
name=Docker CE Nightly - Sources
baseurl=https://download.docker.com/linux/centos/$releasever/source/nightly
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg


yum install docker-ce -y

systemctl start docker

systemctl enable docker

[root@docker ~]# docker --version
Docker version 26.1.4, build 5650f9b


[root@docker ~]# docker pull mysql
Using default tag: latest
latest: Pulling from library/mysql
07bc88e18c4a: Pull complete
1a9c1668bf49: Pull complete
1021dda8eecf: Pull complete
fb61b56acac1: Pull complete
0bca83908a5b: Pull complete
165e8b3d37ca: Pull complete
3e1b086f1295: Pull complete
dba651668484: Pull complete
ed90f5355e12: Pull complete
0412f59ab2b5: Pull complete
Digest: sha256:aa021e164da6aacbefc59ed0b933427e4835636be380f3b6523f4a6c9564e1f0
Status: Downloaded newer image for mysql:latest
docker.io/library/mysql:latest




cat <<EOF > /etc/yum.repos.d/10.0.1.249.repo
[NAT249]
name=10.0.1.149 - Base
baseurl=http://10.0.1.249/kubernetes/container/
gpgcheck=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7
EOF



# 切換到 CentOS mirror
# 【k8s-docker】【k8s-minikube】【k8s-master】【k8s-node1】【k8s-node2】
curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.vpnforgame.net/centos/7/CentOS-Base.repo

curl -o /etc/yum.repos.d/epel.repo http://mirrors.vpnforgame.net/epel/7/epel.repo

yum clean all

yum makecache

【k8s-master】
wget http://10.0.1.249/kubernetes/scripts/install_k8s-latest.sh
wget http://10.0.1.249/kubernetes/scripts/ntp_all.sh

chmod 755 *.sh

./install_k8s-latest.sh -full

# 切換到 10.0.1.249 CentOS mirrir
# 【k8s-docker】【k8s-minikube】【k8s-master】【k8s-node1】【k8s-node2】
curl -o /etc/yum.repos.d/CentOS-Base.repo http://10.0.1.249/kubernetes/centos/7/CentOS-Base-10.0.1.249.repo

curl -o /etc/yum.repos.d/epel.repo http://10.0.1.249/kubernetes/epel/7/epel-10.0.1.249.repo

yum clean all

yum makecache
